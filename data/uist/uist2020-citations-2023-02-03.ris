
TY  - JOUR
AU  - Masiero, Federico; Sinibaldi, Edoardo; Clemente, Francesco; Cipriani, Christian
TI  - Effects of Sensor Resolution and Localization Rate on the Performance of a Myokinetic Control Interface
PY  - 2021
AB  - Magnetic tracking systems have been widely investigated in biomedical engineering due to the transparency of the human body to static magnetic fields. We recently proposed a novel human-machine interface for prosthetic application, namely the myokinetic interface. This controls multi-articulated prostheses by tracking magnets implanted in the residual muscles of individuals with amputation. Previous studies in this area focused solely on the choice and tuning of the localization algorithm. Here, we addressed the role of the intrinsic properties of the sensors, by analysing their effects on the tracking accuracy and on the computation time of the localization algorithm, through experimentally-verified computer simulations. We observed that the tracking accuracy is primarily affected by the localization rate, which is directly related to the sampling frequency of the sensors, and less significantly affected by the sensor resolution. The computation time, instead, proved positively correlated to the number of MMs, and negatively correlated with the localization rate. Our results may contribute to the development of novel human-machine interfaces for prosthetic limbs and could be extended to a broad range of applications involving magnetic tracking.
SP  - 22603
EP  - 22611
JF  - IEEE Sensors Journal
VL  - 21
IS  - 20
PB  - 
DO  - 10.1109/jsen.2021.3109870
ER  - 

TY  - NA
AU  - Zhang, Tianyi; Chen, Zhiyang; Zhu, Yuanli; Vaithilingam, Priyan; Wang, Xinyu; Glassman, Elena L.
TI  - CHI - Interpretable Program Synthesis
PY  - 2021
AB  - Program synthesis, which generates programs based on user-provided specifications, can be obscure and brittle: users have few ways to understand and recover from synthesis failures. We propose interpretable program synthesis, a novel approach that unveils the synthesis process and enables users to monitor and guide a synthesizer. We designed three representations that explain the underlying synthesis process with different levels of fidelity. We implemented an interpretable synthesizer for regular expressions and conducted a within-subjects study with eighteen participants on three challenging regex tasks. With interpretable synthesis, participants were able to reason about synthesis failures and provide strategic feedback, achieving a significantly higher success rate compared with a state-of-the-art synthesizer. In particular, participants with a high engagement tendency (as measured by NCS-6) preferred a deductive representation that shows the synthesis process in a search tree, while participants with a relatively low engagement tendency preferred an inductive representation that renders representative samples of programs enumerated during synthesis.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445646
ER  - 

TY  - NA
AU  - Suzuki, Ryo; Ofek, Eyal; Sinclair, Mike; Leithinger, Daniel; Gonzalez-Franco, Mar
TI  - HapticBots: Distributed Encountered-type Haptics for VR with Multiple Shape-changing Mobile Robots.
PY  - 2021
AB  - HapticBots introduces a novel encountered-type haptic approach for Virtual Reality (VR) based on multiple tabletop-size shape-changing robots. These robots move on a tabletop and change their height and orientation to haptically render various surfaces and objects on-demand. Compared to previous encountered-type haptic approaches like shape displays or robotic arms, our proposed approach has an advantage in deployability, scalability, and generalizability -- these robots can be easily deployed due to their compact form factor. They can support multiple concurrent touch points in a large area thanks to the distributed nature of the robots. We propose and evaluate a novel set of interactions enabled by these robots which include: 1) rendering haptics for VR objects by providing just-in-time touch-points on the user's hand, 2) simulating continuous surfaces with the concurrent height and position change, and 3) enabling the user to pick up and move VR objects through graspable proxy objects. Finally, we demonstrate HapticBots with various applications, including remote collaboration, education and training, design and 3D modeling, and gaming and entertainment.
SP  - 1269
EP  - 1281
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474821
ER  - 

TY  - NA
AU  - Cools, Robbe; Han, Jihae; Simeone, Adalberto L.
TI  - SelectVisAR: Selective Visualisation of Virtual Environments in Augmented Reality
PY  - 2021
AB  - When establishing a visual connection between a virtual reality user and an augmented reality user, it is important to consider whether the augmented reality user faces a surplus of information. Augmented reality, compared to virtual reality, involves two, not one, planes of information: the physical and the virtual. We propose SelectVisAR, a selective visualisation system of virtual environments in augmented reality. Our system enables an augmented reality spectator to perceive a co-located virtual reality user in the context of four distinct visualisation conditions: Interactive, Proximity, Everything, and Dollhouse. We explore an additional two conditions, Context and Spotlight, in a follow-up study. Our design uses a human-centric approach to information filtering, selectively visualising only parts of the virtual environment related to the interactive possibilities of a virtual reality user. The research investigates how selective visualisations can be helpful or trivial for the augmented reality user when observing a virtual reality user.
SP  - 275
EP  - 282
JF  - Designing Interactive Systems Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3461778.3462096
ER  - 

TY  - NA
AU  - Langerak, Thomas; Zarate, Juan Jose; Vechev, Velko; Lindlbauer, David; Panozzo, Daniele; Hilliges, Otmar
TI  - UIST - Optimal Control for Electromagnetic Haptic Guidance Systems
PY  - 2020
AB  - We introduce an optimal control method for electromagnetic haptic guidance systems. Our real-time approach assists users in pen-based tasks such as drawing, sketching or designing. The key to our control method is that it guides users, yet does not take away agency. Existing approaches force the stylus to a continuously advancing setpoint on a target trajectory, leading to undesirable behavior such as loss of haptic guidance or unintended snapping. Our control approach, in contrast, gently pulls users towards the target trajectory, allowing them to always easily override the system to adapt their input spontaneously and draw at their own speed. To achieve this flexible guidance, our optimization iteratively predicts the motion of an input device such as a pen, and adjusts the position and strength of an underlying dynamic electromagnetic actuator accordingly. To enable real-time computation, we additionally introduce a novel and fast approximate model of an electromagnet. We demonstrate the applicability of our approach by implementing it on a prototypical hardware platform based on an electromagnet moving on a bi-axial linear stage, as well as a set of applications. Experimental results show that our approach is more accurate and preferred by users compared to open-loop and time-dependent closed-loop approaches.
SP  - 951
EP  - 965
JF  - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3379337.3415593
ER  - 

TY  - NA
AU  - Ji, Xinya; Zhou, Hang; Wang, Kaisiyuan; Wu, Qianyi; Wu, Wayne; Xu, Feng; Cao, Xun
TI  - EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model
PY  - 2022
AB  - Although significant progress has been made to audio-driven talking face generation, existing methods either neglect facial emotion or cannot be applied to arbitrary subjects. In this paper, we propose the Emotion-Aware Motion Model (EAMM) to generate one-shot emotional talking faces by involving an emotion source video. Specifically, we first propose an Audio2Facial-Dynamics module, which renders talking faces from audio-driven unsupervised zero- and first-order key-points motion. Then through exploring the motion model's properties, we further propose an Implicit Emotion Displacement Learner to represent emotion-related facial dynamics as linearly additive displacements to the previously acquired motion representations. Comprehensive experiments demonstrate that by incorporating the results from both modules, our method can generate satisfactory talking face results on arbitrary subjects with realistic emotion patterns.
SP  - NA
EP  - NA
JF  - Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3528233.3530745
ER  - 

TY  - NA
AU  - Britain, Gabriel Wade; Martin, David; Kwok, Tyler; Sumilong, Adam; Starner, Thad
TI  - Preferences for Captioning on Emulated Head Worn Displays While in Group Conversation
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 2022 ACM International Symposium on Wearable Computers
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3544794.3558468
ER  - 

TY  - NA
AU  - Satriadi, Kadek Ananta; Smiley, Jim; Ens, Barrett; Cordeil, Maxime; Czauderna, Tobias; Lee, Benjamin; Yang, Ying; Dwyer, Tim; Jenny, Bernhard
TI  - Tangible Globes for Data Visualisation in Augmented Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517715
ER  - 

TY  - NA
AU  - Onishi, Yuki; Takashima, Kazuki; Fujita, Kazuyuki; Kitamura, Yoshifumi
TI  - CHI Extended Abstracts - Self-actuated Stretchable Partitions for Dynamically Creating Secure Workplaces
PY  - 2021
AB  - The configuration of office environments is related to worker satisfaction and can improve work efficiency. Although open offices promote communication among co-workers, privacy issues surface as well as increased risks from such health concerns as viral infections and pandemics. On the other hand, territorial offices protect worker privacy and reduce infection risks. Unfortunately, such arrangements often hinder communication among co-workers. Although a physical office must satisfy different needs under various scenarios with limited space, the lack of flexibility in furniture designs prevents dynamic space management. In this paper, we propose a self-actuated stretchable partition whose physical height, width, and position can dynamically change to create secure workplaces (e.g., against privacy and infectious risks) without inhibiting group collaboration. To support secure workplace layouts and space reconfigurations, the partitions’ height, length, and position are adapted automatically and dynamically. First, we consider the design space of a self-actuated stretchable partition and implement a proof-of concept prototype with a height-adjustable stand, a roll-up screen, and a mobile robot. We then show some example application scenarios to discuss potential future actuated-territorial offices.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451607
ER  - 

TY  - JOUR
AU  - Tan, Jeanne; Shao, Li; Lam, Ngan Yi Kitty; Toomey, Anne; Ge, Lan
TI  - Intelligent textiles : designing a gesture-controlled illuminated textile based on computer vision
PY  - 2021
AB  - Artificial intelligence (AI) offers the potential for the development of e-textiles that give wearers a smart and intuitive experience. An emerging challenge in intelligent materials design is hand...
SP  - 004051752110342
EP  - 3048
JF  - Textile Research Journal
VL  - 92
IS  - 17-18
PB  - 
DO  - 10.1177/00405175211034245
ER  - 

TY  - NA
AU  - Drey, Tobias; Albus, Patrick; der Kinderen, Simon; Milo, Maximilian; Segschneider, Thilo; Chanzab, Linda; Rietzler, Michael; Seufert, Tina; Rukzio, Enrico
TI  - Towards Collaborative Learning in Virtual Reality: A Comparison of Co-Located Symmetric and Asymmetric Pair-Learning
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517641
ER  - 

TY  - NA
AU  - Brackenbury, Will; McNutt, Andrew; Chard, Kyle; Elmore, Aaron J.; Ur, Blase
TI  - UIST - KondoCloud: Improving Information Management in Cloud Storage via Recommendations Based on File Similarity
PY  - 2021
AB  - Users face many challenges in keeping their personal file collections organized. While current file-management interfaces help users retrieve files in disorganized repositories, they do not aid in organization. Pertinent files can be difficult to find, and files that should have been deleted may remain. To help, we designed KondoCloud, a file-browser interface for personal cloud storage. KondoCloud makes machine learning-based recommendations of files users may want to retrieve, move, or delete. These recommendations leverage the intuition that similar files should be managed similarly. We developed and evaluated KondoCloud through two complementary online user studies. In our Observation Study, we logged the actions of 69 participants who spent 30 minutes manually organizing their own Google Drive repositories. We identified high-level organizational strategies, including moving related files to newly created sub-folders and extensively deleting files. To train the classifiers that underpin KondoCloud’s recommendations, we had participants label whether pairs of files were similar and whether they should be managed similarly. In addition, we extracted ten metadata and content features from all files in participants’ repositories. Our logistic regression classifiers all achieved F1 scores of 0.72 or higher. In our Evaluation Study, 62 participants used KondoCloud either with or without recommendations. Roughly half of participants accepted a non-trivial fraction of recommendations, and some participants accepted nearly all of them. Participants who were shown the recommendations were more likely to delete related files located in different directories. They also generally felt the recommendations improved efficiency. Participants who were not shown recommendations nonetheless manually performed about a third of the actions that would have been recommended.
SP  - 69
EP  - 83
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474736
ER  - 

TY  - NA
AU  - Liu, Michael Xieyang; Kuznetsov, Andrew; Kim, Yongsung; Chang, Joseph Chee; Kittur, Aniket; Myers, Brad A.
TI  - Wigglite: Low-cost Information Collection and Triage
PY  - 2022
AB  - Consumers conducting comparison shopping, researchers making sense of competitive space, and developers looking for code snippets online all face the challenge of capturing the information they find for later use without interrupting their current flow. In addition, during many learning and exploration tasks, people need to externalize their mental context, such as estimating how urgent a topic is to follow up on, or rating a piece of evidence as a "pro" or "con," which helps scaffold subsequent deeper exploration. However, current approaches incur a high cost, often requiring users to select, copy, context switch, paste, and annotate information in a separate document without offering specific affordances that capture their mental context. In this work, we explore a new interaction technique called "wiggling," which can be used to fluidly collect, organize, and rate information during early sensemaking stages with a single gesture. Wiggling involves rapid back-and-forth movements of a pointer or up-and-down scrolling on a smartphone, which can indicate the information to be collected and its valence, using a single, light-weight gesture that does not interfere with other interactions that are already available. Through implementation and user evaluation, we found that wiggling helped participants accurately collect information and encode their mental context with a 58% reduction in operational cost while being 24% faster compared to a common baseline.
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545661
ER  - 

TY  - NA
AU  - Kim, Kevin Gonyop; Davis, Richard Lee; Coppi, Alessia Eletta; Cattaneo, Alberto; Dillenbourg, Pierre
TI  - Mixplorer: Scaffolding Design Space Exploration through Genetic Recombination of Multiple Peoples' Designs to Support Novices' Creativity
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501854
ER  - 

TY  - NA
AU  - Dobinson, Rhett; Teyssier, Marc; Steimle, Jürgen; Fruchard, Bruno
TI  - MicroPress: Detecting Pressure and Hover Distance in Thumb-to-Finger Interactions
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 2022 ACM Symposium on Spatial User Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3565970.3567698
ER  - 

TY  - NA
AU  - Chung, John Joon Young; He, Shiqing; Adar, Eytan
TI  - Conference on Designing Interactive Systems - The Intersection of Users, Roles, Interactions, and Technologies in Creativity Support Tools
PY  - 2021
AB  - Creativity Support Tools (CSTs) have become an integral part of artistic creation. The range of CST technologies is broad—from fabricators to generative algorithms to robots. The interaction approaches for CSTs are accordingly broad. CSTs combine specific technologies and interaction types to serve a spectrum of roles and users. In this work, we tackle a comprehensive understanding of how the intersections of users, roles, interactions, and technologies form a design space for CSTs. We accomplish this by reviewing 111 art-creation CSTs from HCI and computing research and analyzing how diverse aspects of CSTs relate to each other. Our findings identify patterns for designing CSTs, which can give guidance to future CST designers. We also highlight under-explored types of CSTs within the HCI community, providing future directions that CST researchers can pursue given the current trajectory of technological advancement. This work contributes an integrating perspective to understand the landscape of art-creation CSTs.
SP  - 1817
EP  - 1833
JF  - Designing Interactive Systems Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3461778.3462050
ER  - 

TY  - JOUR
AU  - Epstein, Daniel A.; Liu, Fannie; Monroy-Hernández, Andrés; Wang, Dennis
TI  - Revisiting Piggyback Prototyping: Examining Benefits and Tradeoffs in Extending Existing Social Computing Systems
PY  - 2022
AB  - <jats:p>The CSCW community has a history of designing, implementing, and evaluating novel social interactions in technology, but the process requires significant technical effort for uncertain value. We discuss the opportunities and applications of "piggyback prototyping", building and evaluating new ideas for social computing on top of existing ones, expanding on its potential to contribute design recommendations. Drawing on about 50 papers which use the method, we critically examine the intellectual and technical benefits it provides, such as ecological validity and leveraging well-tested features, as well as research-product and ethical tensions it imposes, such as limits to customization and violation of participant privacy. We discuss considerations for future researchers deciding whether to use piggyback prototyping and point to new research agendas which can reduce the burden of implementing the method.</jats:p>
SP  - 1
EP  - 28
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - CSCW2
PB  - 
DO  - 10.1145/3555557
ER  - 

TY  - NA
AU  - Alaboudi, Abdulaziz; LaToza, Thomas D.
TI  - VL/HCC - Edit - Run Behavior in Programming and Debugging
PY  - 2021
AB  - As developers program and debug, they continuously edit and run their code, a behavior known as edit-run cycles. While techniques such as live programming are intended to support this behavior, little is known about the characteristics of edit-run cycles themselves. To bridge this gap, we analyzed 28 hours of programming and debugging work from 11 professional developers which encompassed over three thousand development activities. We mapped activities to edit or run steps, constructing 581 debugging and 207 programming edit-run cycles. We found that edit-run cycles are frequent. Developers edit and run the program, on average, 7 times before fixing a defect and twice before introducing a defect. Developers waited longer before again running the program when programming than debugging, with a mean cycle length of 3 minutes for programming and 1 minute for debugging. Most cycles involved an edit to a single file after which a developer ran the program to observe the impact on the final output. Edit-run cycles which included activities beyond edit and run, such as navigating between files, consulting resources, or interacting with other IDE features, were much longer, with a mean length of 5 minutes, rather than 1.5 minutes. We conclude with a discussion of design recommendations for tools to enable more fluidity in edit-run cycles.
SP  - 1
EP  - 10
JF  - 2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vl/hcc51201.2021.9576170
ER  - 

TY  - NA
AU  - Logas, Jacob; Lin, Georgianna; Belan, Kelsie; Gogate, Advait; Starner, Thad
TI  - AHs - Conversational Partner’s Perception of Subtle Display Use for Monitoring Notifications
PY  - 2021
AB  - We examine whether the gaze direction of a user reveals the use of a subtle display during a face-to-face conversation with a partner who is not initially aware of the display. We measure twelve participants’ perceptions of a casual conversational partner’s engagement between a control condition of no notification and notifications displayed behind the participant’s head at 0, 10, and 20 degrees to the right of the conversational partner’s line of sight. No differences in reported conversational engagement were found. However, once the presence of the display was revealed, engagement scores went down over all conditions compared to the prior uninformed variant of the experiment. Still, no difference was found between the control and the subtle display conditions, and informed participants were only 40% accurate on average in detecting the use of the display. In a second study comparing subtle display user engagement with smartwatch user engagement, six participants rated a conversational partner more distracted when the partner used a smartwatch to monitor notifications than when the partner used a display secretly mounted behind the participant’s head. Participants in both studies did not realize the presence of the display until it was revealed. These results suggest that eye movement when using a subtle display detracts less from the conversational experience than the use of a smartwatch.
SP  - 101
EP  - 110
JF  - Augmented Humans Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3458709.3458942
ER  - 

TY  - NA
AU  - Yu, Difeng; Desai, Ruta; Zhang, Ting; Benko, Hrvoje; Jonker, Tanya R.; Gupta, Aakar
TI  - Optimizing the Timing of Intelligent Suggestion in Virtual Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545632
ER  - 

TY  - BOOK
AU  - Wang, Liwen; Sandor, Christian
TI  - EuroXR - Can You Perceive the Size Change? Discrimination Thresholds for Size Changes in Augmented Reality.
PY  - 2021
AB  - NA
SP  - 25
EP  - 36
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - van Deurzen, Bram; Goorts, Patrik; De Weyer, Tom; Vanacken, Davy; Luyten, Kris
TI  - HapticPanel: An Open System to Render Haptic Interfaces in Virtual Reality for Manufacturing Industry
PY  - 2021
AB  - Virtual Reality (VR) allows simulation of machine control panels without physical access to the machine, enabling easier and faster initial exploration, testing, and validation of machine panel designs. However, haptic feedback is indispensable if we want to interact with these simulated panels in a realistic manner. We present HapticPanel, an encountered-type haptic system that provides realistic haptic feedback for machine control panels in VR. To ensure a realistic manipulation of input elements, the user’s hand is continuously tracked during interaction with the virtual interface. Based on which virtual element the user intends to manipulate, a motorized panel with stepper motors moves a corresponding physical input element in front of the user’s hand, enabling realistic physical interaction.
SP  - NA
EP  - NA
JF  - Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3489849.3489901
ER  - 

TY  - NA
AU  - Grubert, Jens
TI  - Mixed Reality Interaction Techniques.
PY  - 2021
AB  - This chapter gives an overview of interaction techniques for mixed reality including augmented and virtual reality (AR/VR). Various modalities for input and output are discussed. Specifically, techniques for tangible and surface-based interaction, gesture-based, pen-based, gaze-based, keyboard and mouse-based, as well as haptic interaction are discussed. Furthermore, the combination of multiple modalities in multisensory and multimodal interaction, as well as interaction using multiple physical or virtual displays, are presented. Finally, interaction with intelligent virtual agents is considered.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Ye, Hui; Fu, Hongbo
TI  - ProGesAR: Mobile AR Prototyping for Proxemic and Gestural Interactions with Real-world IoT Enhanced Spaces
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517689
ER  - 

TY  - NA
AU  - Elahi, Ehsan; Iglesias, Ana; Morato, Jorge
TI  - Web Images Relevance and Quality: User Evaluation
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 5th International Conference on Computer Science and Software Engineering (CSSE 2022)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3569966.3569984
ER  - 

TY  - JOUR
AU  - Zhou, Zhibin; Li, Zhuoshu; Zhang, Yuyang; Sun, Lingyun
TI  - Transparent-AI Blueprint: Developing a Conceptual Tool to Support the Design of Transparent AI Agents
PY  - 2022
AB  - NA
SP  - 1846
EP  - 1873
JF  - International Journal of Human–Computer Interaction
VL  - 38
IS  - 18-20
PB  - 
DO  - 10.1080/10447318.2022.2093773
ER  - 

TY  - NA
AU  - DeLine, Robert
TI  - CHI - Glinda: Supporting Data Science with Live Programming, GUIs and a Domain-specific Language
PY  - 2021
AB  - Researchers have explored several avenues to mitigate data scientists’ frustrations with computational notebooks, including: (1) live programming, to keep notebook results consistent and up to date; (2) supplementing scripting with graphical user interfaces (GUIs), to improve ease of use; and (3) providing domain-specific languages (DSLs), to raise a script’s level of abstraction. This paper introduces Glinda, which combines these three approaches by providing a live programming experience, with interactive results, for a domain-specific language for data science. The language’s compiler uses an open-ended set of “recipes” to execute steps in the user’s data science workflow. Each recipe is intended to combine the expressiveness of a written notation with the ease-of-use of a GUI. Live programming provides immediate feedback to a user’s input, whether in the form of program edits or GUI gestures. In a qualitative evaluation with 12 professional data scientists, participants highly rated the live programming and interactive results. They found the language productive and sufficiently expressive and suggested opportunities to extend it.
SP  - 1
EP  - 11
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445267
ER  - 

TY  - NA
AU  - Sun, Lingyun; Li, Jiaji; Ji, Junzhe; Pan, Deying; Li, Mingming; Zhu, Kuangqi; Fan, Yitao; Yang, Yue; Tao, Ye; Wang, Guanyun
TI  - X-Bridges: Designing Tunable Bridges to Enrich 3D Printed Objects' Deformation and Stiffness
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545710
ER  - 

TY  - NA
AU  - Kim, Tae Soo; Choi, DaEun; Choi, Yoonseo; Kim, Juho
TI  - Stylette: Styling the Web with Natural Language
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501931
ER  - 

TY  - JOUR
AU  - Liu, Michael Xieyang; Kittur, Aniket; Myers, Brad A.
TI  - To Reuse or Not To Reuse? A Framework and System for Evaluating Summarized Knowledge
PY  - 2021
AB  - As the amount of information online continues to grow, a correspondingly important opportunity is for individuals to reuse knowledge which has been summarized by others rather than starting from scratch. However, appropriate reuse requires judging the relevance, trustworthiness, and thoroughness of others' knowledge in relation to an individual's goals and context. In this work, we explore augmenting judgements of the appropriateness of reusing knowledge in the domain of programming, specifically of reusing artifacts that result from other developers' searching and decision making. Through an analysis of prior research on sensemaking and trust, along with new interviews with developers, we synthesized a framework for reuse judgements. The interviews also validated that developers express a desire for help with judging whether to reuse an existing decision. From this framework, we developed a set of techniques for capturing the initial decision maker's behavior and visualizing signals calculated based on the behavior, to facilitate subsequent consumers' reuse decisions, instantiated in a prototype system called Strata. Results of a user study suggest that the system significantly improves the accuracy, depth, and speed of reusing decisions. These results have implications for systems involving user-generated content in which other users need to evaluate the relevance and trustworthiness of that content.
SP  - 1
EP  - 35
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 5
IS  - CSCW1
PB  - 
DO  - 10.1145/3449240
ER  - 

TY  - JOUR
AU  - Hung, Ching-Wen; Tsai, Hsin-Ruey; Su, Chi-Chun; Chiu, Jui-Cheng; Chen, Bing-Yu
TI  - OsciHead
PY  - 2022
AB  - <jats:p>Current haptic devices are usually designed to provide one type of force feedback; however, most VR scenarios require versatile force feedback, which may require the integration of different devices to provide various types of forces. In addition, besides the main haptic effects caused by the forces, multiple types of oscillation may also commonly accompany them, which are crucial for improving VR realism and immersion. Therefore, we simulate versatile force feedback by rendering the corresponding types of oscillation as the effects caused by those forces. We take inertia and impact forces as examples in this paper, and achieve versatility using the proposed device, OsciHead, on a head-mounted display (HMD), instead of integrating different devices. By controlling elastic bands' elasticity and stored power, OsciHead uses two rotatable oscillators on both sides of the HMD, in order to render various multilevel and multidimensional oscillation feedback in 2D translation and 2D rotation directions on a head. In an exploratory study, we explored different scenarios in which multiple types of oscillation could be simulated by OsciHead. We then observed oscillation level distinguishability in two just-noticeable difference (JND) studies, and evaluated the oscillation type recognition rates in a recognition study. Based on the results, we performed a VR study, which verified that the inertia and impact feedback simulated by OsciHead enhances realism and achieves versatility.</jats:p>
SP  - 1
EP  - 23
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - MHCI
PB  - 
DO  - 10.1145/3546715
ER  - 

TY  - NA
AU  - Jones, Lee; Girouard, Audrey
TI  - Creativity &amp; Cognition - Patching Textiles: Insights from Visible Mending Educators on Wearability, Extending the Life of Our Clothes, and Teaching Tangible Crafts
PY  - 2021
AB  - Textiles have several characteristics that make them well suited for updates, sometimes called patching or mending, but textile repair is underexplored in the context of personal fabrication. This exploration is an urgent sustainability issue so we can extend the life of textiles and avoid producing more materials. In this paper we take a craft ethnography approach by interviewing 15 visible mending educators for insights into how they teach the techniques of repair and re-use so individuals can upcycle the textiles they already own. We discuss the values that menders bring to the practice, the teaching strategies they employ, the tangible teaching materials and tools of the practice, and introduce three types of teaching samplers: wearable samplers, sampler swatches, and practice samplers. Overall, these interviews provide insights for textile maker toolkits, textile personal fabrication, and how we can teach tangible hybrid crafts and sustainable making practices.
SP  - NA
EP  - NA
JF  - Creativity and Cognition
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3450741.3465265
ER  - 

TY  - NA
AU  - Chung, John Joon Young; Shin, Hijung Valentina; Xia, Haijun; Wei, Li-Yi; Kazi, Rubaiat Habib
TI  - CHI - Beyond Show of Hands: Engaging Viewers via Expressive and Scalable Visual Communication in Live Streaming
PY  - 2021
AB  - Live streaming is gaining popularity across diverse application domains in recent years. A core part of the experience is streamer-viewer interaction, which has been mainly text-based. Recent systems explored extending viewer interaction to include visual elements with richer expression and increased engagement. However, understanding expressive visual inputs becomes challenging with many viewers, primarily due to the relative lack of structure in visual input. On the other hand, adding rigid structures can limit viewer interactions to narrow use cases or decrease the expressiveness of viewer inputs. To facilitate the sensemaking of many visual inputs while retaining the expressiveness or versatility of viewer interactions, we introduce a visual input management framework (VIMF) and a system, VisPoll, that help streamers specify, aggregate, and visualize many visual inputs. A pilot evaluation indicated that VisPoll can expand the types of viewer interactions. Our framework provides insights for designing scalable and expressive visual communication for live streaming.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445419
ER  - 

TY  - NA
AU  - Horie, Arata; Saraiji, Mhd Yamen; Kashino, Zendai; Inami, Masahiko
TI  - VR - EncounteredLimbs: A Room-scale Encountered-type Haptic Presentation using Wearable Robotic Arms
PY  - 2021
AB  - Haptic information significantly improves human awareness of objects in virtual reality. One way of presenting this information is via encountered-type haptic feedback. An advantage of encounter type feedback is that it enables physical interaction with virtual environments without the need for specialized haptic devices on the hand. Additionally, encountered-type haptics are known for being able to provide high quality contact feedback to the user. However, such systems are typically designed to be grounded (i.e., fixed to the floor). As such, they typically have bounded workspace and a limited range of possible applications. In this work, we present a novel, wearable approach to presenting a user with encountered-type haptic feedback. We realize this feedback using a wearable robotic limb that holds a plate where the user might interact with their environment. An appropriate location for the plate is determined by a novel haptic solver while control of the arm is made possible using motion trackers. The system was designed to be stable, for presenting consistent haptic feedback, while also being safe and lightweight for wearability. By making the feedback system wearable, we enable the presentation of stiff feedback while maintaining the spatial freedom and unbounded workspace of natural hand interaction. Herein, we present the design of the novel system, mechanical and safety considerations when designing a wearable encountered-type system, and an evaluation of the system. A technical evaluation of the implemented system showed that the system provides a stiffness over 25 N/m and slant angle errors under 3°. Three user studies show the limitations of haptic slant perception in humans and the quantitative and qualitative effectiveness of the current prototype system. We conclude the paper by discussing various potentialapplications and possible improvements that could be made to the system.
SP  - 260
EP  - 269
JF  - 2021 IEEE Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr50410.2021.00048
ER  - 

TY  - NA
AU  - Liu, Han; North, Chris
TI  - Case Study Comparison of Computational Notebook Platforms for Interactive Visual Analytics
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE Visualization in Data Science (VDS)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vds57266.2022.00005
ER  - 

TY  - NA
AU  - Feick, Martin; Kleer, Niko; Zenner, André; Tang, Anthony; Krüger, Antonio
TI  - CHI - Visuo-haptic Illusions for Linear Translation and Stretching using Physical Proxies in Virtual Reality
PY  - 2021
AB  - Providing haptic feedback when manipulating virtual objects is an essential part of immersive virtual reality experiences; however, it is challenging to replicate all of an object's properties and characteristics. We propose the use of visuo-haptic illusions alongside physical proxies to enhance the scope of proxy-based interactions with virtual objects. In this work, we focus on two manipulation techniques, linear translation and stretching across different distances, and investigate how much discrepancy between the physical proxy and the virtual object may be introduced without participants noticing. In a study with 24 participants, we found that manipulation technique and travel distance significantly affect the detection thresholds, and that visuo-haptic illusions impact performance and accuracy. We show that this technique can be used to enable functional proxy objects that act as stand-ins for multiple virtual objects, illustrating the technique through a showcase VR-DJ application.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445456
ER  - 

TY  - JOUR
AU  - Mugisha, Stanley; Guda, Vamsi Krisha; Chevallereau, Christine; Zoppi, Matteo; Molfino, Rezia; Chablat, Damien
TI  - Improving Haptic Response for Contextual Human Robot Interaction.
PY  - 2022
AB  - For haptic interaction, a user in a virtual environment needs to interact with proxies attached to a robot. The device must be at the exact location defined in the virtual environment in time. However, due to device limitations, delays are always unavoidable. One of the solutions to improve the device response is to infer human intended motion and move the robot at the earliest time possible to the desired goal. This paper presents an experimental study to improve the prediction time and reduce the robot time taken to reach the desired position. We developed motion strategies based on the hand motion and eye-gaze direction to determine the point of user interaction in a virtual environment. To assess the performance of the strategies, we conducted a subject-based experiment using an exergame for reach and grab tasks designed for upper limb rehabilitation training. The experimental results in this study revealed that eye-gaze-based prediction significantly improved the detection time by 37% and the robot time taken to reach the target by 27%. Further analysis provided more insight on the effect of the eye-gaze window and the hand threshold on the device response for the experimental task.
SP  - 2040
EP  - 2040
JF  - Sensors (Basel, Switzerland)
VL  - 22
IS  - 5
PB  - 
DO  - 10.3390/s22052040
ER  - 

TY  - NA
AU  - Gong, Hebo; Cui, Zhitong; Wang, Yanan; Shen, Chengyi; Zhang, Deyin; Luo, Shijian
TI  - CHI Extended Abstracts - eGlove: Designing Interactive Fabric Sensor for Enhancing Contact-Based Interactions
PY  - 2021
AB  - We present eGlove, a wearable and low-cost fabric sensor for recognizing a rich context of objects by touching them, including daily necessities, fruits, plants, as well as different body parts. Our sensing approach utilizes Swept frequency Capacitive Sensing (SFCS) to provide consistent sensor readings even when the fabric electrode is under varying deformation and stretching degrees. Our work proposes an easy fabrication method and hardware configuration for prototyping the interactive fabric sensor. We evaluated our system’s classification accuracy through per-user training and found a real-time classification of 96.3%. We also demonstrated novel contextual interactions enabled by our technical approach with several applications.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451824
ER  - 

TY  - NA
AU  - Ahuja, Karan; Streli, Paul; Holz, Christian
TI  - UIST - TouchPose: Hand Pose Prediction, Depth Estimation, and Touch Classification from Capacitive Images
PY  - 2021
AB  - Today’s touchscreen devices commonly detect the coordinates of user input through capacitive sensing. Yet, these coordinates are the mere 2D manifestations of the more complex 3D configuration of the whole hand—a sensation that touchscreen devices so far remain oblivious to. In this work, we introduce the problem of reconstructing a 3D hand skeleton from capacitive images, which encode the sparse observations captured by touch sensors. These low-resolution images represent intensity mappings that are proportional to the distance to the user’s fingers and hands. We present the first dataset of capacitive images with corresponding depth maps and 3D hand pose coordinates, comprising 65,374 aligned records from 10 participants. We introduce our supervised method TouchPose, which learns a 3D hand model and a corresponding depth map using a cross-modal trained embedding from capacitive images in our dataset. We quantitatively evaluate TouchPose’s accuracy in touch classification, depth estimation, and 3D joint reconstruction, showing that our model generalizes to hand poses it has never seen during training and can infer joints that lie outside the touch sensor’s volume. Enabled by TouchPose, we demonstrate a series of interactive apps and novel interactions on multitouch devices. These applications show TouchPose’s versatile capability to serve as a general-purpose model, operating independent of use-case, and establishing 3D hand pose as an integral part of the input dictionary for application designers and developers. We also release our dataset, code, and model to enable future work in this domain.
SP  - 997
EP  - 1009
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474801
ER  - 

TY  - NA
AU  - Wentzel, Johann; Junuzovic, Sasa; Devine, James; Porter, John; Mott, Martez
TI  - Understanding How People with Limited Mobility Use Multi-Modal Input
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517458
ER  - 

TY  - JOUR
AU  - Zhou, Hao; Lu, Taiting; Liu, Yilin; Zhang, Shijia; Gowda, Mahanth
TI  - Learning on the Rings
PY  - 2022
AB  - <jats:p>This paper presents ssLOTR (self-supervised learning on the rings), a system that shows the feasibility of designing self-supervised learning based techniques for 3D finger motion tracking using a custom-designed wearable inertial measurement unit (IMU) sensor with a minimal overhead of labeled training data. Ubiquitous finger motion tracking enables a number of applications in augmented and virtual reality, sign language recognition, rehabilitation healthcare, sports analytics, etc. However, unlike vision, there are no large-scale training datasets for developing robust machine learning (ML) models on wearable devices. ssLOTR designs ML models based on data augmentation and self-supervised learning to first extract efficient representations from raw IMU data without the need for any training labels. The extracted representations are further trained with small-scale labeled training data. In comparison to fully supervised learning, we show that only 15% of labeled training data is sufficient with self-supervised learning to achieve similar accuracy. Our sensor device is designed using a two-layer printed circuit board (PCB) to minimize the footprint and uses a combination of Polylactic acid (PLA) and Thermoplastic polyurethane (TPU) as housing materials for sturdiness and flexibility. It incorporates a system-on-chip (SoC) microcontroller with integrated WiFi/Bluetooth Low Energy (BLE) modules for real-time wireless communication, portability, and ubiquity. In contrast to gloves, our device is worn like rings on fingers, and therefore, does not impede dexterous finger motion. Extensive evaluation with 12 users depicts a 3D joint angle tracking accuracy of 9.07° (joint position accuracy of 6.55mm) with robustness to natural variation in sensor positions, wrist motion, etc, with low overhead in latency and power consumption on embedded platforms.</jats:p>
SP  - 1
EP  - 31
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 2
PB  - 
DO  - 10.1145/3534587
ER  - 

TY  - JOUR
AU  - Tang, Xiao; Li, Ruihui; Fu, Chi-Wing
TI  - CAFI-AR
PY  - 2022
AB  - <jats:p>Freehand interaction enhances user experience, allowing one to use bare hands to manipulate virtual objects in AR. Yet, it remains challenging to accurately and efficiently detect contacts between real hand and virtual object, due to the imprecise captured/estimated hand geometry. This paper presents CAFI-AR, a new approach for Contact-Aware Freehand Interaction with virtual AR objects, enabling us to automatically detect hand-object contacts in real-time with low latency. Specifically, we formulate a compact deep architecture to efficiently learn to predict hand action and contact moment from sequences of captured RGB images relative to the 3D virtual object. To train the architecture for detecting contacts on AR objects, we build a new dataset with 4,008 frame sequences, each with annotated hand-object interaction information. Further, we integrate CAFI-AR into our prototyping AR system and develop various interactive scenarios, demonstrating fine-grained contact-aware interactions on a rich variety of virtual AR objects, which cannot be achieved by existing AR interaction approaches. Lastly, we also evaluate CAFI-AR, quantitatively and qualitatively, through two user studies to demonstrate its effectiveness in terms of accurately detecting the hand-object contacts and promoting fluid freehand interactions</jats:p>
SP  - 1
EP  - 23
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 4
PB  - 
DO  - 10.1145/3569499
ER  - 

TY  - JOUR
AU  - Jin, Yincheng; Gao, Yang; Zhu, Yanjun; Wang, Wei; Li, Jiyang; Choi, Seokmin; Li, Zhangyu; Chauhan, Jagmohan; Dey, Anind K.; Jin, Zhanpeng
TI  - SonicASL: An Acoustic-based Sign Language Gesture Recognizer Using Earphones
PY  - 2021
AB  - We propose SonicASL, a real-time gesture recognition system that can recognize sign language gestures on the fly, leveraging front-facing microphones and speakers added to commodity earphones worn by someone facing the person making the gestures. In a user study (N=8), we evaluate the recognition performance of various sign language gestures at both the word and sentence levels. Given 42 frequently used individual words and 30 meaningful sentences, SonicASL can achieve an accuracy of 93.8% and 90.6% for word-level and sentence-level recognition, respectively. The proposed system is tested in two real-world scenarios: indoor (apartment, office, and corridor) and outdoor (sidewalk) environments with pedestrians walking nearby. The results show that our system can provide users with an effective gesture recognition tool with high reliability against environmental factors such as ambient noises and nearby pedestrians.
SP  - 1
EP  - 30
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 2
PB  - 
DO  - 10.1145/3463519
ER  - 

TY  - JOUR
AU  - Yamanaka, Shota
TI  - Utility of Crowdsourced User Experiments for Measuring the Central Tendency of User Performance: A Case of Error-Rate Model Evaluation in a Pointing Task.
PY  - 2022
AB  - The usage of crowdsourcing to recruit numerous participants has been recognized as beneficial in the human-computer interaction (HCI) field, such as for designing user interfaces and validating user performance models. In this work, we investigate its effectiveness for evaluating an error-rate prediction model in target pointing tasks. In contrast to models for operational times, a clicking error (i.e., missing a target) occurs by chance at a certain probability, e.g., 5%. Therefore, in traditional laboratory-based experiments, a lot of repetitions are needed to measure the central tendency of error rates. We hypothesize that recruiting many workers would enable us to keep the number of repetitions per worker much smaller. We collected data from 384 workers and found that existing models on operational time and error rate showed good fits (both <i>R</i> <sup>2</sup> > 0.95). A simulation where we changed the number of participants <i>N</i> <sub><i>P</i></sub> and the number of repetitions <i>N</i> <sub>repeat</sub> showed that the time prediction model was robust against small <i>N</i> <sub><i>P</i></sub> and <i>N</i> <sub>repeat</sub>, although the error-rate model fitness was considerably degraded. These findings empirically demonstrate a new utility of crowdsourced user experiments for collecting numerous participants, which should be of great use to HCI researchers for their evaluation studies.
SP  - 798892
EP  - NA
JF  - Frontiers in artificial intelligence
VL  - 5
IS  - NA
PB  - 
DO  - 10.3389/frai.2022.798892
ER  - 

TY  - CHAP
AU  - Yang, Wan-Chen; Lee, I.-Jui
TI  - Applying Asymmetrical VR Collaborative Games to the Enhancement of Peer Collaboration and Oral Communication in Children with Autism
PY  - 2022
AB  - NA
SP  - 413
EP  - 426
JF  - Human Aspects of IT for the Aged Population. Technology in Everyday Living
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-05654-3_29
ER  - 

TY  - NA
AU  - Hong, Freddie; Myant, Connor; Boyle, David
TI  - Thermoformed Circuit Boards: Fabrication of highly conductive freeform 3D printed circuit boards with heat bending
PY  - 2021
AB  - Fabricating 3D printed electronics using desktop printers has become more accessible with recent developments in conductive thermoplastic filaments. Because of their high resistance and difficulties in printing traces in vertical directions, most applications are restricted to capacitive sensing. In this paper, we introduce Thermoformed Circuit Board (TCB), a novel approach that employs the thermoformability of the 3D printed plastics to construct various double-sided, rigid and highly conductive freeform circuit boards that can withstand high current applications through copper electroplating. To illustrate the capability of the TCB, we showcase a range of examples with various shapes, electrical characteristics and interaction mechanisms. We also demonstrate a new design tool extension to an existing CAD environment that allows users to parametrically draw the substrate and conductive trace, and export 3D printable files. TCB is an inexpensive and highly accessible fabrication technique intended to broaden HCI researcher participation.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445469
ER  - 

TY  - NA
AU  - Marquardt, Nicolai; Riche, Nathalie Henry; Holz, Christian; Romat, Hugo; Pahud, Michel; Brudy, Frederik; Ledo, David; Park, Chunjong; Nicholas, Molly Jane; Seyed, Teddy; Ofek, Eyal; Lee, Bongshin; Buxton, William A. S.; Hinckley, Ken
TI  - UIST - AirConstellations: In-Air Device Formations for Cross-Device Interaction via Multiple Spatially-Aware Armatures
PY  - 2021
AB  - AirConstellations supports a unique semi-fixed style of cross-device interactions via multiple self-spatially-aware armatures to which users can easily attach (or detach) tablets and other devices. In particular, AirConstellations affords highly flexible and dynamic device formations where the users can bring multiple devices together in-air — with 2–5 armatures poseable in 7DoF within the same workspace — to suit the demands of their current task, social situation, app scenario, or mobility needs. This affords an interaction metaphor where relative orientation, proximity, attaching (or detaching) devices, and continuous movement into and out of ad-hoc ensembles can drive context-sensitive interactions. Yet all devices remain self-stable in useful configurations even when released in mid-air. We explore flexible physical arrangement, feedforward of transition options, and layering of devices in-air across a variety of multi-device app scenarios. These include video conferencing with flexible arrangement of the person-space of multiple remote participants around a shared task-space, layered and tiled device formations with overview+detail and shared-to-personal transitions, and flexible composition of UI panels and tool palettes across devices for productivity applications. A preliminary interview study highlights user reactions to AirConstellations, such as for minimally disruptive device formations, easier physical transitions, and balancing ”seeing and being seen” in remote work.
SP  - 1252
EP  - 1268
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474820
ER  - 

TY  - JOUR
AU  - Stauffert, Jan-Philipp; Niebling, Florian; Latoschik, Marc Erich
TI  - Latency and Cybersickness: Impact, Causes, and Measures. A Review
PY  - 2020
AB  - Latency is a key characteristic inherent to any computer system. Motion-to-Photon (MTP) latency describes the time between the movement of a tracked object and its corresponding movement rendered and depicted by computer-generated images on a graphical output screen. High MTP latency can cause a loss of performance in interactive graphics applications and, even worse, can provoke cybersickness in Virtual Reality (VR) applications. Here, cybersickness can deteriorate VR experiences or it may render the experiences completely unusable. It can confound research findings of an otherwise sound experiment. Latency, as a contributing factor to cybersickness needs to be properly understood. Its effects need to be analyzed, its sources need to be identified, good measurement methods need to be developed, and proper counter measures need to be developed in order to reduce potentially harmful impacts of latency on the usability and safety of VR systems. Research shows that latency can exhibit intricate timing patterns with various spiking and periodic behavior. These timing behaviors may vary, still most are found to provoke cybersickness. Overall, latency can differ drastically between different systems which hinders generalization of measurement results. This review article describes causes and effects of latency with regard to cybersickness. We report on different existing approaches to measure and report latency. Hence, the article provides readers with the knowledge to understand and report latency for their own applications, evaluations, and experiments. It should also help to measure, identify, and finally control and counteract latency and hence gain confidence into the soundness of empirical data collected by VR exposures. Low latency increases the usability and safety of VR systems.
SP  - 582204
EP  - NA
JF  - Frontiers in Virtual Reality
VL  - 1
IS  - NA
PB  - 
DO  - 10.3389/frvir.2020.582204
ER  - 

TY  - NA
AU  - Rahman, Sajjadur; Kandogan, Eser
TI  - Characterizing Practices, Limitations, and Opportunities Related to Text Information Extraction Workflows: A Human-in-the-loop Perspective
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502068
ER  - 

TY  - NA
AU  - He, Liang; Su, Xia; Peng, Huaishu; Lipton, Jeffrey Ian; Froehlich, Jon E.
TI  - Kinergy: Creating 3D Printable Motion using Embedded Kinetic Energy
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545636
ER  - 

TY  - NA
AU  - Wu, Te-Yen; Xu, Zheer; Yang, Xing-Dong; Hodges, Steve; Seyed, Teddy
TI  - CHI - Project Tasca: Enabling Touch and Contextual Interactions with a Pocket-based Textile Sensor
PY  - 2021
AB  - We present Project Tasca, a pocket-based textile sensor that detects user input and recognizes everyday objects that a user carries in the pockets of a pair of pants (e.g., keys, coins, electronic devices, or plastic items). By creating a new fabric-based sensor capable of detecting in-pocket touch and pressure, and recognizing metallic, non-metallic, and tagged objects inside the pocket, we enable a rich variety of subtle, eyes-free, and always-available input, as well as context-driven interactions in wearable scenarios. We developed our prototype by integrating four distinct types of sensing methods, namely: inductive sensing, capacitive sensing, resistive sensing, and NFC in a multi-layer fabric structure into the form factor of a jeans pocket. Through a ten-participant study, we evaluated the performance of our prototype across 11 common objects including hands, 8 force gestures, and 30 NFC tag placements. We yielded a 92.3% personal cross-validation accuracy for object recognition, 96.4% accuracy for gesture recognition, and a 100% accuracy for detecting NFC tags at close distance . We conclude by demonstrating the interactions enabled by our pocket-based sensor in several applications.
SP  - 1
EP  - 13
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445712
ER  - 

TY  - NA
AU  - Gonzalez, Eric J.; Ofek, Eyal; Gonzalez-Franco, Mar; Sinclair, Mike
TI  - UIST - X-Rings: A Hand-mounted 360° Shape Display for Grasping in Virtual Reality
PY  - 2021
AB  - X-Rings is a novel hand-mounted 360° shape display for Virtual Reality that renders objects in 3D and responds to user-applied touch and grasping force. Designed as a modular stack of motor-driven expandable rings (5.7-7.7 cm diameter), X-Rings renders radially-symmetric surfaces graspable by the user’s whole hand. The device is strapped to the palm, allowing the fingers to freely make and break contact with the device. Capacitance sensors and motor current sensing provide estimates of finger touch states and gripping force. We present the results of a user study evaluating participants’ ability to associate device-rendered shapes with visually-rendered objects as well as a demo application that allows users to freely interact with a variety of objects in a virtual environment.
SP  - 732
EP  - 742
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474782
ER  - 

TY  - NA
AU  - Schoop, Eldon; Zhou, Xin; Li, Gang; Chen, Zhourong; Hartmann, Bjoern; Li, Yang
TI  - Predicting and Explaining Mobile UI Tappability with Vision Modeling and Saliency Analysis
PY  - 2022
AB  - We use a deep learning based approach to predict whether a selected element in a mobile UI screenshot will be perceived by users as tappable, based on pixels only instead of view hierarchies required by previous work. To help designers better understand model predictions and to provide more actionable design feedback than predictions alone, we additionally use ML interpretability techniques to help explain the output of our model. We use XRAI to highlight areas in the input screenshot that most strongly influence the tappability prediction for the selected region, and use k-Nearest Neighbors to present the most similar mobile UIs from the dataset with opposing influences on tappability perception.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517497
ER  - 

TY  - CHAP
AU  - Yamanaka, Shota
TI  - INTERACT (2) - Comparing Performance Models for Bivariate Pointing Through a Crowdsourced Experiment
PY  - 2021
AB  - Evaluation of a novel user-performance model’s fitness requires comparison with baseline models, yet it is often time consuming and involves much effort by researchers to collect data from many participants. Crowdsourcing has recently been used for evaluating novel interaction techniques, but its potential for model comparison studies has not been investigated in detail. In this study, we evaluated four existing Fitts’ law models for rectangular targets, as though one of them was a proposed novel model. We recruited 210 crowd workers, who performed 94,080 clicks in total, and confirmed that the result for the best-fit model was consistent with previous studies. We also analyzed whether this conclusion would change depending on the sample size, but even when we randomly sampled data from five workers for 10,000 iterations, the best-fit model changed only once (0.01%). We have thus demonstrated a case in which crowdsourcing is beneficial for comparing performance models.
SP  - 76
EP  - 92
JF  - Human-Computer Interaction – INTERACT 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-85616-8_6
ER  - 

TY  - NA
AU  - Krosnick, Rebecca; Oney, Steve
TI  - ParamMacros: Creating UI Automation Leveraging End-User Natural Language Parameterization
PY  - 2022
AB  - Prior work in programming-by-demonstration (PBD) has explored ways to enable end-users to create custom automation without needing to write code. We propose a new end-user specification model &#x2013; asking the end-user to explicitly identify parts of their natural language query that can be generalized. We built a PBD system, ParamMacros, where users first generalize a concrete natural language question &#x2013; identifying parameters and their possible values &#x2013; and then create a demonstration of how to answer the question on the website of interest. ParamMacros then infers a generalized program by using the user-provided parameter values to identify relevant patterns in the website&#x2019;s structure. In a lab study we found that participants were able to meaningfully parameterize natural language queries and felt such a parameterization and demonstration process would be useful for creating custom automation.
SP  - NA
EP  - NA
JF  - 2022 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vl/hcc53370.2022.9833005
ER  - 

TY  - NA
AU  - Friedel, Marcus
TI  - HapticLever: Kinematic Force Feedback using a 3D Pantograph
PY  - 2022
AB  - HapticLever is a new kinematic approach for VR haptics which uses a 3D pantograph to stiffly render large-scale surfaces using small-scale proxies. The HapticLever approach does not consume power to render forces, but rather puts a mechanical constraint on the end effector using a small-scale proxy surface. The HapticLever approach provides stiff force feedback when the user interacts with a static virtual surface, but allows the user to move their arm freely when moving through free virtual space. We present the problem space, the related work, and the HapticLever design approach.
SP  - NA
EP  - NA
JF  - The Adjunct Publication of the 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526114.3558736
ER  - 

TY  - NA
AU  - Sun, Wei; Chen, Yanjun; Zhan, Simon; Han, Teng; Tian, Feng; Wang, Hongan; Yang, Xing-Dong
TI  - CHI - RElectrode: A Reconfigurable Electrode For Multi-Purpose Sensing Based on Microfluidics
PY  - 2021
AB  - In this paper, we propose a reconfigurable electrode, RElectrode, using a microfluidic technique that can change the geometry and material properties of the electrode to satisfy the needs for sensing a variety of different types of user input through touch/touchless gestures, pressure, temperature, and distinguish between different types of objects or liquids. Unlike the existing approaches, which depend on the specific-shaped electrode for particular sensing (e.g., coil for inductive sensing), RElectrode enables capacity, inductance, resistance/pressure, temperature, pH sensings all in a single package. We demonstrate the design and fabrication of the microfluidic structure of our RElectrode, evaluate its sensing performance through several studies, and provide some unique applications. RElectrode demonstrates technical feasibility and application values of integrating physical and biochemical properties of microfluidics into novel sensing interfaces.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445652
ER  - 

TY  - NA
AU  - Zhu, Junyi; Snowden, Jackson C.; Verdejo, Joshua; Chen, Emily; Zhang, Paul; Ghaednia, Hamid; Schwab, Joseph H.; Mueller, Stefanie
TI  - UIST (Adjunct Volume) - EIT-kit Demo: An Electrical Impedance Tomography Toolkit for Health and Motion Sensing
PY  - 2021
AB  - In this paper, we propose EIT-kit, an electrical impedance tomography toolkit for designing and fabricating health and motion sensing devices. EIT-kit contains (1) an extension to a 3D editor for personalizing the form factor of electrode arrays and electrode distribution, (2) a customized EIT sensing motherboard for performing the measurements, (3) a microcontroller library that automates signal calibration and facilitates data collection, and (4) an image reconstruction library for mobile devices for interpolating and visualizing the measured data. Together, these EIT-kit components allow for applications that require 2- or 4-terminal setups, up to 64 electrodes, and single or multiple (up to four) electrode arrays simultaneously. We motivate the design of each component of EIT-kit with a formative study, and conduct a technical evaluation of the data fidelity of our EIT measurements. We demonstrate the design space that EIT-kit enables by showing various applications in health as well as motion sensing and control.
SP  - 100
EP  - 102
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474758
ER  - 

TY  - NA
AU  - Lin, Richard; Ramesh, Rohit; Jain, Nikhil; Koe, Josephine; Nuqui, Ryan; Dutta, Prabal; Hartmann, Bjoern
TI  - UIST - Weaving Schematics and Code: Interactive Visual Editing for Hardware Description Languages
PY  - 2021
AB  - In many engineering disciplines such as circuit board, chip, and mechanical design, a hardware description language (HDL) approach provides important benefits over direct manipulation interfaces by supporting concepts like abstraction and generator meta-programming. While several such HDLs have emerged recently and promised power and flexibility, they also present challenges – especially to designers familiar with current graphical workflows. In this work, we investigate an IDE approach to provide a graphical editor for a board-level circuit design HDL. Unlike GUI builders which convert an entire diagram to code, we instead propose generating equivalent HDL from individual graphical edit actions. By keeping code as the primary design input, we preserve the full power of the underlying HDL, while remaining useful even to advanced users. We discuss our concept, design considerations such as performance, system implementation, and report on the results of an exploratory remote user study with four experienced hardware designers.
SP  - 1039
EP  - 1049
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474804
ER  - 

TY  - JOUR
AU  - Tu, Peihan; Wei, Li-Yi; Yatani, Koji; Igarashi, Takeo; Zwicker, Matthias
TI  - Continuous curve textures
PY  - 2020
AB  - Repetitive patterns are ubiquitous in natural and human-made objects, and can be created with a variety of tools and methods. Manual authoring provides unmatched degree of freedom and control, but can require significant artistic expertise and manual labor. Computational methods can automate parts of the manual creation process, but are mainly tailored for discrete pixels or elements instead of more general continuous structures. We propose an example-based method to synthesize continuous curve patterns from exemplars. Our main idea is to extend prior sample-based discrete element synthesis methods to consider not only sample positions (geometry) but also their connections (topology). Since continuous structures can exhibit higher complexity than discrete elements, we also propose robust, hierarchical synthesis to enhance output quality. Our algorithm can generate a variety of continuous curve patterns fully automatically. For further quality improvement and customization, we also present an autocomplete user interface to facilitate interactive creation and iterative editing. We evaluate our methods and interface via different patterns, ablation studies, and comparisons with alternative methods.
SP  - 11761
EP  - 11766
JF  - ACM Transactions on Graphics
VL  - 271
IS  - 20
PB  - 
DO  - 10.1145/3414685.3417780
ER  - 

TY  - NA
AU  - Li, Daniel; Chen, Thomas; Tung, Albert; Chilton, Lydia B.
TI  - Hierarchical Summarization for Longform Spoken Dialog
PY  - 2021
AB  - Every day we are surrounded by spoken dialog. This medium delivers rich diverse streams of information auditorily; however, systematically understanding dialog can often be non-trivial. Despite the pervasiveness of spoken dialog, automated speech understanding and quality information extraction remains markedly poor, especially when compared to written prose. Furthermore, compared to understanding text, auditory communication poses many additional challenges such as speaker disfluencies, informal prose styles, and lack of structure. These concerns all demonstrate the need for a distinctly speech tailored interactive system to help users understand and navigate the spoken language domain. While individual automatic speech recognition (ASR) and text summarization methods already exist, they are imperfect technologies; neither consider user purpose and intent nor address spoken language induced complications. Consequently, we design a two stage ASR and text summarization pipeline and propose a set of semantic segmentation and merging algorithms to resolve these speech modeling challenges. Our system enables users to easily browse and navigate content as well as recover from errors in these underlying technologies. Finally, we present an evaluation of the system which highlights user preference for hierarchical summarization as a tool to quickly skim audio and identify content of interest to the user.
SP  - NA
EP  - NA
JF  - arXiv: Computation and Language
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Lin, Georgianna; Haynes, Malcolm; Srinivas, Sarthak; Kotipalli, Pramod; Starner, Thad
TI  - Towards Finding the Optimum Position in the Visual Field for a Head Worn Display Used for Task Guidance with Non-registered Graphics
PY  - 2021
AB  - Where should a HWD be placed in a user's visual field? We present two studies that compare comfort, preference, task efficiency and accuracy for various HWD positions. The first study offsets a 9.2° horizontal field-of-view (FOV) display temporally (toward the ear) from 0° to 30° in 10° steps. 30° proves too uncomfortable while 10° is the most preferred position for a simple button-pushing game, corroborating results from previous single-task reading experiments. The second experiment uses a Magic Leap One to compare 10° x 10° FOV interfaces centered at line-of-sight, temporally offset 15° (center-right), inferiorly offset 15° (bottom-center), and offset in both directions (bottom-right) for an order picking task. The bottom-right position proved worst in terms of accuracy and several subjective metrics when compared to the line-of-sight position.
SP  - 1
EP  - 26
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 1
PB  - 
DO  - 10.1145/3448091
ER  - 

TY  - NA
AU  - Zhang, Ting; Hu, Zhenhong; Gupta, Aakar; Wu, Chi-Hao; Benko, Hrvoje; Jonker, Tanya R.
TI  - RIDS: Implicit Detection of a Selection Gesture Using Hand Motion Dynamics During Freehand Pointing in Virtual Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545701
ER  - 

TY  - NA
AU  - Pouta, Emmi; Mikkonen, Jussi Ville
TI  - Woven eTextiles in HCI — a Literature Review
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Designing Interactive Systems Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532106.3533566
ER  - 

TY  - NA
AU  - Tyagi, Anjul; Zhao, Jian; Patel, Pushkar; Khurana, Swasti; Mueller, Klaus
TI  - User-Centric Semi-Automated Infographics Authoring and Recommendation
PY  - 2021
AB  - Designing infographics can be a tedious process for non-experts and time-consuming even for professional designers. Based on the literature and a formative study, we propose a flexible framework for automated and semi-automated infographics design. This framework captures the main design components in infographics and streamlines the generation workflow into three steps, allowing users to control and optimize each aspect independently. Based on the framework, we also propose an interactive tool, \name{}, for assisting novice designers with creating high-quality infographics from an input in a markdown format by offering recommendations of different design components of infographics. Simultaneously, more experienced designers can provide custom designs and layout ideas to the tool using a canvas to control the automated generation process partially. As part of our work, we also contribute an individual visual group (VG) and connection designs dataset (in SVG), along with a 1k complete infographic image dataset with segmented VGs. This dataset plays a crucial role in diversifying the infographic designs created by our framework. We evaluate our approach with a comparison against similar tools, a user study with novice and expert designers, and a case study. Results confirm that our framework and \name{} excel in creating customized infographics and exploring a large variety of designs.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Luo, Yiyue; Wu, Kui; Spielberg, Andrew; Foshey, Michael; Rus, Daniela; Palacios, Tomás; Matusik, Wojciech
TI  - Digital Fabrication of Pneumatic Actuators with Integrated Sensing by Machine Knitting
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517577
ER  - 

TY  - CHAP
AU  - Strahl, Jonathan; Peltonen, Jaakko; Floréen, Patrik
TI  - INTERACT (3) - Directing and Combining Multiple Queries for Exploratory Search by Visual Interactive Intent Modeling
PY  - 2021
AB  - In interactive information-seeking, a user often performs many interrelated queries and interactions covering multiple aspects of a broad topic of interest. Especially in difficult information-seeking tasks the user may need to find what is in common among such multiple aspects. Therefore, the user may need to compare and combine results across queries. While methods to combine queries or rankings have been proposed, little attention has been paid to interactive support for combining multiple queries in exploratory search. We introduce an interactive information retrieval system for exploratory search with multiple simultaneous search queries that can be combined. The user is able to direct search in the multiple queries, and combine queries by two operations: intersection and difference, which reveal what is relevant to the user intent of two queries, and what is relevant to one but not the other. Search is directed by relevance feedback on visualized user intent models of each query. Operations on queries act directly on the intent models inferring a combined user intent model. Each combination yields a new result (ranking) and acts as a new search that can be interactively directed and further combined. User experiments on difficult information-seeking tasks show that our novel system with query operations yields more relevant top-ranked documents in a shorter time than a baseline multiple-query system.
SP  - 514
EP  - 535
JF  - Human-Computer Interaction – INTERACT 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-85613-7_34
ER  - 

TY  - NA
AU  - Kou, Yubo; Gui, Xinning
TI  - CHI - Flag and Flaggability in Automated Moderation: The Case of Reporting Toxic Behavior in an Online Game Community
PY  - 2021
AB  - Online platforms rely upon users or automated tools to flag toxic behaviors, the very first step in online moderation. While much recent research has examined online moderation, the role of flag remains poorly understood. This question becomes even more urgent in automated moderation, where flagging becomes a primary source of human judgment. We conducted a qualitative study of flagging practices in League of Legends (LoL), a popular eSports game. We found stark differences between how flag is designed to identify toxicity, and flaggability, or how players use and appropriate flag. Players distrust flag, but also appropriate flag for instrumental purposes. Thus, flaggability diverges decidedly from the conception of toxicity, and must be understood within the highly competitive gaming context of LoL. These findings help shed light on the situated nature of flaggability, the role of flag in online moderation, as well as implications for designing flag and moderation.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445279
ER  - 

TY  - JOUR
AU  - Kern, Florian; Kullmann, Peter; Ganal, Elisabeth; Korwisi, Kristof; Stingl, René; Niebling, Florian; Latoschik, Marc Erich
TI  - Off-The-Shelf Stylus: Using XR Devices for Handwriting and Sketching on Physically Aligned Virtual Surfaces
PY  - 2021
AB  - This article introduces the Off-The-Shelf Stylus (OTSS), a framework for 2D interaction (in 3D) as well as for handwriting and sketching with digital pen, ink, and paper on physically aligned virtual surfaces in Virtual, Augmented, and Mixed Reality (VR, AR, MR: XR for short). OTSS supports self-made XR styluses based on consumer-grade six-degrees-of-freedom XR controllers and commercially available styluses. The framework provides separate modules for three basic but vital features: (1) The stylus module provides stylus construction and calibration features. (2) The surface module provides surface calibration and visual feedback features for virtual-physical 2D surface alignment using our so-called 3ViSuAl procedure, and surface interaction features. (3) The evaluation suite provides a comprehensive test bed combining technical measurements for precision, accuracy, and latency with extensive usability evaluations including handwriting and sketching tasks based on established visuomotor, graphomotor, and handwriting research. The framework’s development is accompanied by an extensive open source reference implementation targeting the Unity game engine using an Oculus Rift S headset and Oculus Touch controllers. The development compares three low-cost and low-tech options to equip controllers with a tip and includes a web browser-based surface providing support for interacting, handwriting, and sketching. The evaluation of the reference implementation based on the OTSS framework identified an average stylus precision of 0.98 mm (SD = 0.54 mm) and an average surface accuracy of 0.60 mm (SD = 0.32 mm) in a seated VR environment. The time for displaying the stylus movement as digital ink on the web browser surface in VR was 79.40 ms on average (SD = 23.26 ms), including the physical controller’s motion-to-photon latency visualized by its virtual representation (M = 42.57 ms, SD = 15.70 ms). The usability evaluation (N = 10) revealed a low task load, high usability, and high user experience. Participants successfully reproduced given shapes and created legible handwriting, indicating that the OTSS and it’s reference implementation is ready for everyday use. We provide source code access to our implementation, including stylus and surface calibration and surface interaction features, making it easy to reuse, extend, adapt and/or replicate previous results (https://go.uniwue.de/hci-otss).
SP  - 684498
EP  - NA
JF  - Frontiers in Virtual Reality
VL  - 2
IS  - NA
PB  - 
DO  - 10.3389/frvir.2021.684498
ER  - 

TY  - NA
AU  - Lin, Jenny; McCann, James
TI  - ICRA - An Artin Braid Group Representation of Knitting Machine State with Applications to Validation and Optimization of Fabrication Plans
PY  - 2021
AB  - Industrial knitting machines create fabric by manipulating loops held on hundreds of needles. A core problem in pattern making for these machines is transfer planning – coming up with a sequence of low-level operations that move loops to the appropriate needles so that knitting through those loops produces the correct final structure. Since each loop is connected to the larger piece in progress, transfer plans must account for not only loop position, but the way strands of yarn tangle around each other.We present the first complete, discrete representation of the machine’s loop-tangling process. Our representation combines a braid from the Artin Braid Group with an array of explicit loop positions to fully capture loop crossings. By storing braids in the Symmetric Normal Form, states can be quickly compared and updated incrementally with machine operations. This representation can be used to verify the equivalence of transfer operations, providing an important tool in optimizing knit manufacturing.We improve on prior work in transfer planning algorithms, which can only solve certain subclasses of problems and are frequently suboptimal in terms of fabrication time, by introducing a novel A* search heuristic and state-collapsing mechanism, which we show finds optimal transfer plans for a large benchmark set of small transfer planning problems.
SP  - 1147
EP  - 1153
JF  - 2021 IEEE International Conference on Robotics and Automation (ICRA)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/icra48506.2021.9562113
ER  - 

TY  - NA
AU  - Dube, Tafadzwa Joseph; Johnson, Kevin; Arif, Ahmed Sabbir
TI  - Shapeshifter: Gesture Typing in Virtual Reality with a Force-based Digital Thimble
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519679
ER  - 

TY  - JOUR
AU  - Willett, Wesley; Bon Adriel Aseniero, NA; Carpendale, Sheelagh; Dragicevic, Pierre; Jansen, Yvonne; Oehlberg, Lora; Isenberg, Petra
TI  - Perception! Immersion! Empowerment!: Superpowers as Inspiration for Visualization
PY  - 2021
AB  - We explore how the lens of fictional superpowers can help characterize how visualizations empower people and provide inspiration for new visualization systems. Researchers and practitioners often tout visualizations' ability to "make the invisible visible" and to "enhance cognitive abilities." Meanwhile superhero comics and other modern fiction often depict characters with similarly fantastic abilities that allow them to see and interpret the world in ways that transcend traditional human perception. We investigate the intersection of these domains, and show how the language of superpowers can be used to characterize existing visualization systems and suggest opportunities for new and empowering ones. We introduce two frameworks: The first characterizes seven underlying mechanisms that form the basis for a variety of visual superpowers portrayed in fiction. The second identifies seven ways in which visualization tools and interfaces can instill a sense of empowerment in the people who use them. Building on these observations, we illustrate a diverse set of "visualization superpowers" and highlight opportunities for the visualization community to create new systems and interactions that empower new experiences with data. Material and illustrations are available under CC-BY 4.0 at osf.io/8yhfz.
SP  - 1
EP  - 1
JF  - IEEE transactions on visualization and computer graphics
VL  - 28
IS  - 1
PB  - 
DO  - 10.1109/tvcg.2021.3114844
ER  - 

TY  - JOUR
AU  - Liu, Sophia L.; Cai, Haoyuan; Liu, Chang
TI  - Soft Body Belt-Type Touch Sensor With Impact Resistance: A Study of Dynamic Behavior
PY  - 2021
AB  - We report the development of a novel soft body touch sensor capable of measuring contact force along its length. The sensor can be embedded in soft objects and on curved surfaces for smart furniture, interactive electronics, and general robotics applications. The sensor uses pneumatic transduction principle and achieves both high sensitivity and impact loading tolerance. The development is motivated by the needs of consumer electronics industries for smart furniture and interactive toys. The current work fills a gap of existing soft-bodied touch sensors. The main sensor body is completely polymeric and contains no conductive or semiconducting material elements. It exhibits high pass frequency response to reject common mode contact forces or shape variations. The central question addressed by this paper is dynamic behavior of this sensor under normal and impact touch force. In this study we developed a theoretical model for the sensor output and validated with experimental measurements. We modeled sensor behavior under two operational regimes of different unloading speed. Depending on the rate of change, the sensor could be in force limited relaxation mode or elastic relaxation (free relaxation) mode. Measurements have been performed to capture time constants of occupant behavior in a smart cushion application.
SP  - 128460
EP  - 128466
JF  - IEEE Access
VL  - 9
IS  - NA
PB  - 
DO  - 10.1109/access.2021.3112391
ER  - 

TY  - NA
AU  - Dao, Emily; Muresan, Andreea; Hornbæk, Kasper; Knibbe, Jarrod
TI  - CHI - Bad Breakdowns, Useful Seams, and Face Slapping: Analysis of VR Fails on YouTube
PY  - 2021
AB  - Virtual reality (VR) is increasingly used in complex social and physical settings outside of the lab. However, not much is known about how these settings influence use, nor how to design for them. We analyse 233 YouTube videos of VR Fails to: (1) understand when breakdowns occur, and (2) reveal how the seams between VR use and the social and physical setting emerge. The videos show a variety of fails, including users flailing, colliding with surroundings, and hitting spectators. They also suggest causes of the fails, including fear, sensorimotor mismatches, and spectator participation. We use the videos as inspiration to generate design ideas. For example, we discuss more flexible boundaries between the real and virtual world, ways of involving spectators, and interaction designs to help overcome fear. Based on the findings, we further discuss the ‘moment of breakdown’ as an opportunity for designing engaging and enhanced VR experiences.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445435
ER  - 

TY  - NA
AU  - Jones, Isaiah; Hecht, Brent; Vincent, Nicholas
TI  - Misleading Tweets and Helpful Notes: Investigating Data Labor by Twitter Birdwatch Users
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Companion Computer Supported Cooperative Work and Social Computing
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3500868.3559461
ER  - 

TY  - NA
AU  - MacNeil, Stephen; Ding, Zijian; Quan, Kexin; Huang, Ziheng; Chen, Ken; Dow, Steven
TI  - UIST (Adjunct Volume) - ProbMap: Automatically constructing design galleries through feature extraction and semantic clustering
PY  - 2021
AB  - Making sense of large unstructured problem spaces is cognitively demanding. Structure can help, but adding structure to a problem space also takes significant effort. ProbMap is a novel application for automatically constructing a design gallery from unstructured text input. Given a list of problem statements, ProbMap extracts and semantically groups the stakeholders to construct hierarchical search facets which enables designers to more efficiently navigate the problem statements. We contribute a novel feature extraction algorithm using natural language processing and a technique for automatically constructing a design gallery. These stakeholders are grouped semantically by clustering stakeholders with higher pairwise similarity together. Preliminary trials show that these techniques, which mirror traditional design activities like stakeholder identification and affinity mapping, provide an initial structure to a large unstructured problem space. This resulted in similar features that would be extracted by humans and sensible clusters.
SP  - 134
EP  - 136
JF  - The Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3474349.3480203
ER  - 

TY  - NA
AU  - Peng, Yi-Hao; Wu, Jason; Bigham, Jeffrey; Pavel, Amy
TI  - Diffscriber: Describing Visual Design Changes to Support Mixed-Ability Collaborative Presentation Authoring
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545637
ER  - 

TY  - NA
AU  - Ogata, Masa; Koyama, Yuki
TI  - CHI - A Computational Approach to Magnetic Force Feedback Design
PY  - 2021
AB  - We present a computational approach to haptic design embedded in everyday tangible interaction with digital fabrication. To generate haptic feedback, the use of permanent magnets as the mechanism potentially contributes to simpleness and robustness; however, it is difficult to manually design how magnets should be embedded in the objects. Our approach enables the inverse design of magnetic force feedback; that is, we computationally solve an inverse problem to obtain an optimal arrangement of permanent magnets that renders the user-specified haptic sensation. To solve the inverse problem in a practical manner, we also present techniques on magnetic simulation and optimization. We demonstrate applications to explore the design possibility of augmenting digital fabrication for everyday use.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445631
ER  - 

TY  - NA
AU  - Tian, Rundong; Paulos, Eric
TI  - UIST - Adroid: Augmenting Hands-on Making with a Collaborative Robot
PY  - 2021
AB  - Adroid1 enables users to borrow precision and accuracy from a robotic arm when using hand-held tools. When a tool is mounted to the robot, the user can hold and move the tool directly—Adroid measures the user’s applied forces and commands the robot to move in response. Depending on the tool and scenario, Adroid can selectively restrict certain motions. In the resulting interaction, the robot acts like a virtual “jig” which constrains the tool’s motion, augmenting the user’s accuracy, technique, and strength, while not diminishing their agency during open-ended fabrication tasks. We complement these hands-on interactions with projected augmented reality for visual feedback about the state of the system. We show how tools augmented by Adroid can support hands-on making and discuss how it can be configured to support other tasks within and beyond fabrication.
SP  - 270
EP  - 281
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474749
ER  - 

TY  - CHAP
AU  - Gueorguiev, David; Javot, Bernard; Spiers, Adam; Kuchenbecker, Katherine J.
TI  - Larger Skin-Surface Contact Through a Fingertip Wearable Improves Roughness Perception
PY  - 2022
AB  - <jats:title>Abstract</jats:title><jats:p>With the aim of creating wearable haptic interfaces that allow the performance of everyday tasks, we explore how differently designed fingertip wearables change the sensory threshold for tactile roughness perception. Study participants performed the same two-alternative forced-choice roughness task with a bare finger and wearing three flexible fingertip covers: two with a square opening (64 and 36 mm<jats:inline-formula><jats:alternatives><jats:tex-math>$$^2$$</jats:tex-math><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:msup> <mml:mrow /> <mml:mn>2</mml:mn> </mml:msup> </mml:math></jats:alternatives></jats:inline-formula>, respectively) and the third with no opening. The results showed that adding the large opening improved the 75% JND by a factor of 2 times compared to the fully covered finger: the higher the skin-surface contact area, the better the roughness perception. Overall, the results show that even partial skin-surface contact through a fingertip wearable improves roughness perception, which opens design opportunities for haptic wearables that preserve natural touch.</jats:p>
SP  - 171
EP  - 179
JF  - Haptics: Science, Technology, Applications
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-06249-0_20
ER  - 

TY  - NA
AU  - Teyssier, Marc; Koelle, Marion; Strohmeier, Paul; Fruchard, Bruno; Steimle, Jürgen
TI  - CHI - Eyecam: Revealing Relations between Humans and Sensing Devices through an Anthropomorphic Webcam
PY  - 2021
AB  - We are surrounded by sensing devices. We are accustomed to them, appreciate their benefits, and even create affective bonds and might neglect the implications they might have for our daily life. By presenting Eyecam, an anthropomorphic webcam mimicking a human eye, we challenge conventional relationships with ubiquitous sensing devices and call to re-think how sensing devices might appear and behave. Inspired by critical design, Eyecam is an exaggeration of a familiar sensing device which allows for critical reflections on its perceived functionalities and its impact on human-human and human-device relations. We identify 5 different roles Eyecam can take: Mediator, Observer, Mirror, Presence, and Agent. Contributing design fictions and thinking prompts, we allow for articulation on privacy awareness and intrusion, affect in mediated communication, agency and self-perception along with speculation on potential futures. We envision this work to contribute to a bold and responsible design of ubiquitous sensing devices.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445491
ER  - 

TY  - NA
AU  - Weld, Galen; Glenski, Maria; Althoff, Tim
TI  - Political Bias and Factualness in News Sharing across more than 100,000 Online Communities
PY  - 2021
AB  - As civil discourse increasingly takes place online, misinformation and the polarization of news shared in online communities have become ever more relevant concerns with real world harms across our society. Studying online news sharing at scale is challenging due to the massive volume of content which is shared by millions of users across thousands of communities. Therefore, existing research has largely focused on specific communities or specific interventions, such as bans. However, understanding the prevalence and spread of misinformation and polarization more broadly, across thousands of online communities, is critical for the development of governance strategies, interventions, and community design. Here, we conduct the largest study of news sharing on reddit to date, analyzing more than 550 million links spanning 4 years. We use non-partisan news source ratings from Media Bias/Fact Check to annotate links to news sources with their political bias and factualness. We find that, compared to left-leaning communities, right-leaning communities have 105% more variance in the political bias of their news sources, and more links to relatively-more biased sources, on average. We observe that reddit users' voting and re-sharing behaviors generally decrease the visibility of extremely biased and low factual content, which receives 20% fewer upvotes and 30% fewer exposures from crossposts than more neutral or more factual content. This suggests that reddit is more resilient to low factual content than Twitter. We show that extremely biased and low factual content is very concentrated, with 99% of such content being shared in only 0.5% of communities, giving credence to the recent strategy of community-wide bans and quarantines.
SP  - NA
EP  - NA
JF  - arXiv: Computers and Society
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Wang, Zijie J.; Dai, Katie; Edwards, W. Keith
TI  - StickyLand: Breaking the Linear Presentation of Computational Notebooks
PY  - 2022
AB  - How can we better organize code in computational notebooks? Notebooks have become a popular tool among data scientists, as they seamlessly weave text and code together, supporting users to rapidly iterate and document code experiments. However, it is often challenging to organize code in notebooks, partially because there is a mismatch between the linear presentation of code and the non-linear process of exploratory data analysis. We present StickyLand, a notebook extension for empowering users to freely organize their code in non-linear ways. With sticky cells that are always shown on the screen, users can quickly access their notes, instantly observe experiment results, and easily build interactive dashboards that support complex visual analytics. Case studies highlight how our tool can enhance notebook users's productivity and identify opportunities for future notebook designs. StickyLand is available at https://github.com/xiaohk/stickyland.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519653
ER  - 

TY  - NA
AU  - Hossain, Ekram; Cahoon, Merritt Lee; Liu, Yao; Kurumada, Chigusa; Bai, Zhen
TI  - Context-responsive ASL Recommendation for Parent-Child Interaction
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 24th International ACM SIGACCESS Conference on Computers and Accessibility
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3517428.3550366
ER  - 

TY  - NA
AU  - Gonzalez Penuela, Ricardo E.; Poremba, Wren; Trice, Christina; Azenkot, Shiri
TI  - Hands-On: Using Gestures to Control Descriptions of a Virtual Environment for People with Visual Impairments
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The Adjunct Publication of the 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526114.3558669
ER  - 

TY  - NA
AU  - Khurana, Anjali; Alamzadeh, Parsa; Chilana, Parmit K.
TI  - VL/HCC - ChatrEx: Designing Explainable Chatbot Interfaces for Enhancing Usefulness, Transparency, and Trust
PY  - 2021
AB  - When breakdowns occur during a human-chatbot conversation, the lack of transparency and the “black-box” nature of task-oriented chatbots can make it difficult for end users to understand what went wrong and why. Inspired by recent HCI research on explainable AI solutions, we explored the design of in-application explainable chatbot interfaces (ChatrEx) that explain the underlying working of a chatbot during a breakdown. ChatrEx-VINC provides visual example-based step-by-step explanations in-context of the chat window whereas ChatrEx-VST provides explanations as a visual tour overlaid on the application interface. We implemented these chatbots for complex spreadsheet tasks and our comparative observational study (N=14) showed that the explanations provided by both ChatrEx-VINC and ChatrEx-VST enhanced users' understanding of the reasons for a breakdown and improved users' perceptions of usefulness, transparency, and trust. We identify several opportunities for future research to exploit explainable chatbot interfaces and better support human-chatbot interaction.
SP  - 1
EP  - 11
JF  - 2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vl/hcc51201.2021.9576440
ER  - 

TY  - NA
AU  - Oh, Seungjae; Park, Chaeyong; Jeon, Yo-Seb; Choi, Seungmoon
TI  - UIST - Identifying Contact Fingers on Touch Sensitive Surfaces by Ring-Based Vibratory Communication
PY  - 2021
AB  - As computing paradigms shift toward mobile and ubiquitous interaction, there is an increasing demand for wearable interfaces supporting multifaceted input in smart living environments. In this regard, we introduce a system that identifies contact fingers using vibration as a modality of communication. We investigate the vibration characteristics of the communication channels involved and simulate the transmission of vibration sequences. In the simulation, we test and refine modulation and demodulation methods to design vibratory communication protocols that are robust to environmental noises and can detect multiple simultaneous contact fingers. As a result, we encode an on-off keying sequence with a unique carrier frequency to each finger and demodulate the sequences by applying cross-correlation. We verify the communication protocols in two environments, laboratory and cafe, where the resulting highest accuracy was 93 % and 90.5 %, respectively. Our system achieves over 91 % accuracy in identifying seven contact states from three fingers while wearing only two actuator rings with the aid of a touch screen. Our findings shed light on diversifying touch interactions on rigid surfaces by means of vibratory communication.
SP  - 208
EP  - 222
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474745
ER  - 

TY  - NA
AU  - Qian, Xun; He, Fengming; Hu, Xiyun; Wang, Tianyi; Ipsita, Ananya; Ramani, Karthik
TI  - ScalAR: Authoring Semantically Adaptive Augmented Reality Experiences in Virtual Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517665
ER  - 

TY  - NA
AU  - Matthews, Brandon J.; Thomas, Bruce H.; Von Itzstein, G. Stewart; Smith, Ross T.
TI  - Shape Aware Haptic Retargeting for Accurate Hand Interactions
PY  - 2022
AB  - This paper presents Shape Aware Haptic Retargeting, an extension of "state-of-the-art" haptic retargeting that is the first to support retargeted interaction between any part of the user&#x2019;s hand and any part of the target object. In previous haptic retargeting algorithms, the maximum retargeting is applied only when the hand position aligns with the target position. Shape Aware Haptic Retargeting generalizes the distance computation process to instead consider the hand and target geometry. The shortest hand-target distance is then used to calculate the applied retargeting offset. This ensures the full amount of haptic retargeting is applied at the point of contact with the passive haptic regardless of contact position on the hand or target. We leverage existing geometry algorithms to implement three distance computation methods: Multi-Point, Primitive and Mesh Geometry, in addition to conventional single position approaches. These are evaluated through a set of simulated interactions instead of the single position representation used in previous haptic retargeting systems. The evaluation demonstrated all three approaches can provide improved interaction accuracy over a Point distance computation method, with Mesh Geometry being the most accurate and Primitive being the preferred method for combined performance and interaction accuracy.
SP  - NA
EP  - NA
JF  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr51125.2022.00083
ER  - 

TY  - NA
AU  - Hu, Xinlan Emily; Whiting, Mark E.; Bernstein, Michael S.
TI  - CHI - Can Online Juries Make Consistent, Repeatable Decisions?
PY  - 2021
AB  - A jury of one’s peers is a prominent way to adjudicate disputes and is increasingly used in participatory governance online. The fairness of this approach rests on the assumption that juries are consistent: that the same jury would hand down similar judgments to similar cases. However, prior literature suggests that social influence would instead cause early interactions to cascade into different judgments for similar cases. In this paper, we report an online experiment that changes participants’ pseudonyms as they appear to collaborators, temporarily masking a jury’s awareness that they have deliberated together before. This technique allows us to measure consistency by reconvening the same jury on similar cases. Counter to expectation, juries are equally consistent as individuals, a result that is “good for democracy.” But this consistency arises in part due to group polarization, as consensus develops by hardening initial majority opinions. Furthermore, we find that aggregating groups’ perspectives without deliberation erodes consistency.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445433
ER  - 

TY  - JOUR
AU  - Gadhave, K.; Cutler, Z.; Lex, A.
TI  - Reusing Interactive Analysis Workflows
PY  - 2022
AB  - Interactive visual analysis has many advantages, but an important disadvantage is that analysis processes and workflows cannot be easily stored and reused. This is in contrast to code-based analysis workflows, which can simply be run on updated datasets, and adapted when necessary. In this paper, we introduce methods to capture workflows in interactive visualization systems for different interactions such as selections, filters, categorizing/grouping, labeling, and aggregation. These workflows can then be applied to updated datasets, making interactive visualization sessions reusable. We demonstrate this specification using an interactive visualization system that tracks interaction provenance, and allows generating workflows from the recorded actions. The system can then be used to compare different versions of datasets and apply workflows to them. Finally, we introduce a Python library that can load workflows and apply it to updated datasets directly in a computational notebook, providing a seamless bridge between computational workflows and interactive visualization tools.
SP  - 133
EP  - 144
JF  - Computer Graphics Forum
VL  - 41
IS  - 3
PB  - 
DO  - 10.1111/cgf.14528
ER  - 

TY  - NA
AU  - Sun, Lingyun; Zhuoshu, Li; Yuyang, Zhang; Liu, Yanzhen; Lou, Shanghua; Zhibin, Zhou
TI  - CHI Extended Abstracts - Capturing the Trends, Applications, Issues, and Potential Strategies of Designing Transparent AI Agents
PY  - 2021
AB  - With the increasing prevalence of Artificial Intelligence (AI) agents, the transparency of agents becomes vital in addressing the interaction issues (e.g., explainability and trust). The existing body of research provides valuable theoretical and practical studies in this field. However, determining the transparency of AI agents requires the systematic consideration of the application categories and automation level, which is hardly considered by the prior literature. We thus apply the bibliometric analysis to gain insights from the published literature. Our work outlines the trend of how the number of studies about AI agent transparency increased over the years. We also identify the major application topics and issues in designing transparent AI agents. Furthermore, we categorize the identified applications according to the specific dimensions (risk and timeliness) and put forward potential strategies for designing different agents. Besides, we suggest the possible transparency degree corresponding to the automation level.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451819
ER  - 

TY  - NA
AU  - Chang, Joseph Chee; Kim, Yongsung; Miller, Victor; Liu, Michael Xieyang; Myers, Brad A.; Kittur, Aniket
TI  - UIST - Tabs.do: Task-Centric Browser Tab Management
PY  - 2021
AB  - Despite the increasing complexity and scale of people’s online activities, browser interfaces have stayed largely the same since tabs were introduced in major browsers nearly 20 years ago. The gap between simple tab-based browser interfaces and the complexity of users’ tasks can lead to serious adverse effects – commonly referred to as “tab overload.” This paper introduces a Chrome extension called Tabs.do, which explores bringing a task-centric approach to the browser, helping users to group their tabs into tasks and then organize, prioritize, and switch between those tasks fluidly. To lower the cost of importing, Tabs.do uses machine learning to make intelligent suggestions for grouping users’ open tabs into task bundles by exploiting behavioral and semantic features. We conducted a field deployment study where participants used Tabs.do with their real-life tasks in the wild, and showed that Tabs.do can decrease tab clutter, enabled users to create rich task structures with lightweight interactions, and allowed participants to context-switch among tasks more efficiently.
SP  - 663
EP  - 676
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474777
ER  - 

TY  - JOUR
AU  - Higashino, Kana; Kimoto, Mitsuhiko; Iio, Takamasa; Shimohara, Katsunori; Shiomi, Masahiro
TI  - Tactile stimulus is essential to increase motivation for touch interaction in virtual environment
PY  - 2021
AB  - This paper reports the effectiveness of a tactile stimulus in a virtual environment to increase people's motivations during a monotonous task by comparing a touch with only visual stimuli and anoth...
SP  - 1043
EP  - 1053
JF  - Advanced Robotics
VL  - 35
IS  - 17
PB  - 
DO  - 10.1080/01691864.2021.1967780
ER  - 

TY  - NA
AU  - Krug, Katja; Buschel, Wolfgang; Klamka, Konstantin; Dachselt, Raimund
TI  - CleAR Sight: Exploring the Potential of Interacting with Transparent Tablets in Augmented Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar55827.2022.00034
ER  - 

TY  - NA
AU  - Yang, Willa Yunqi; Zhuang, Yumeng; Darcy, Luke Andre; Liu, Grace; Ion, Alexandra
TI  - Reconfigurable Elastic Metamaterials
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545649
ER  - 

TY  - NA
AU  - Onishi, Yuki; Takashima, Kazuki; Higashiyama, Shoi; Fujita, Kazuyuki; Kitamura, Yoshifumi
TI  - WaddleWalls: Room-scale Interactive Partitioning System using a Swarm of Robotic Partitions
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545615
ER  - 

TY  - JOUR
AU  - Kim, Hanseob; Kim, Taehyung; Lee, Myungho; Kim, Gerard Jounghyun; Hwang, Jae-In
TI  - CIRO: The Effects of Visually Diminished Real Objects on Human Perception in Handheld Augmented Reality
PY  - 2021
AB  - Augmented reality (AR) scenes often inadvertently contain real world objects that are not relevant to the main AR content, such as arbitrary passersby on the street. We refer to these real-world objects as content-irrelevant real objects (CIROs). CIROs may distract users from focusing on the AR content and bring about perceptual issues (e.g., depth distortion or physicality conflict). In a prior work, we carried out a comparative experiment investigating the effects on user perception of the AR content by the degree of the visual diminishment of such a CIRO. Our findings revealed that the diminished representation had positive impacts on human perception, such as reducing the distraction and increasing the presence of the AR objects in the real environment. However, in that work, the ground truth test was staged with perfect and artifact-free diminishment. In this work, we applied an actual real-time object diminishment algorithm on the handheld AR platform, which cannot be completely artifact-free in practice, and evaluated its performance both objectively and subjectively. We found that the imperfect diminishment and visual artifacts can negatively affect the subjective user experience.
SP  - 900
EP  - NA
JF  - Electronics
VL  - 10
IS  - 8
PB  - 
DO  - 10.3390/electronics10080900
ER  - 

TY  - NA
AU  - Achberger, Alexander; Aust, Fabian; Pohlandt, Daniel; Vidackovic, Kresimir; Sedlmair, Michael
TI  - UIST - STRIVE: String-Based Force Feedback for Automotive Engineering
PY  - 2021
AB  - The large potential of force feedback devices for interacting in Virtual Reality (VR) has been illustrated in a plethora of research prototypes. Yet, these devices are still rarely used in practice and it remains an open challenge how to move this research into practice. To that end, we contribute a participatory design study on the use of haptic feedback devices in the automotive industry. Based on a 10-month observing process with 13 engineers, we developed STRIVE, a string-based haptic feedback device. In addition to the design of STRIVE, this process led to a set of requirements for introducing haptic devices into industrial settings, which center around a need for flexibility regarding forces, comfort, and mobility. We evaluated STRIVE with 16 engineers in five different day-to-day automotive VR use cases. The main results show an increased level of trust and perceived safety as well as further challenges towards moving haptics research into practice.
SP  - 841
EP  - 853
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474790
ER  - 

TY  - BOOK
AU  - Ikeda, Ryo; Hakka, Kyohei; Shizuki, Buntarou
TI  - AsianCHI@CHI - Hover-Based Reachability Technique for Executing Single-Touch Gesture on Smartphone
PY  - 2021
AB  - When operating a smartphone with only one hand, users typically use their thumb; however, there may be areas on the screen that the thumb cannot reach. Several reachability techniques have been developed to enable users to access such areas, but many of these techniques are designed to enable users to perform only a tap gesture, so other single-touch gestures such as long-tap, double-tap, swipe, and drag cannot be performed. To enable all single-touch gestures for unreachable areas, we designed a hover-based reachability technique that uses a cursor. In addition, we conducted a pilot study to compare user performance with our technique and that of existing techniques, One-Handed Mode (OM) and Event Forward Cursor (EC). The results showed that our technique was faster than EC, which uses the same cursor technique as ours, except for the double-tap gesture when the target was small. However, our technique was slower than OM, which is the technique that shrinks the entire screen. Lastly, we discuss possible improvements of our technique on the basis of the results.
SP  - 9
EP  - 15
JF  - Asian CHI Symposium 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3429360.3468171
ER  - 

TY  - NA
AU  - Santolucito, Mark
TI  - FARM@ICFP - Human-in-the-loop program synthesis for live coding
PY  - 2021
AB  - Live Coding is a creative coding practice, where the act of programming itself constitutes a performance. The code written during a Live Coding performance often generates media, for example a continuous stream of music or video. One of the challenges of Live Coding is in finding a balance in the language design, such that the language is both expressive enough for the artist, as well as simple enough to be programmed in real-time. In order to reduce the overhead of manually coding every part of a Live Coding performance, we propose a tool for Live Coding that leverages program synthesis to simplify the process. Program synthesis retains the "show your code" ethos of Live Coding performances, while also lowering the barrier to entry to the performance practice.
SP  - 47
EP  - 53
JF  - Proceedings of the 9th ACM SIGPLAN International Workshop on Functional Art, Music, Modelling, and Design
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3471872.3472972
ER  - 

TY  - NA
AU  - Kaimoto, Hiroki; Monteiro, Kyzyl; Faridan, Mehrad; Li, Jiatong; Farajian, Samin; Kakehi, Yasuaki; Nakagaki, Ken; Suzuki, Ryo
TI  - Sketched Reality: Sketching Bi-Directional Interactions Between Virtual and Physical Worlds with AR and Actuated Tangible UI
PY  - 2022
AB  - This paper introduces Sketched Reality, an approach that combines AR sketching and actuated tangible user interfaces (TUI) for bidirectional sketching interaction. Bi-directional sketching enables virtual sketches and physical objects to "affect" each other through physical actuation and digital computation. In the existing AR sketching, the relationship between virtual and physical worlds is only one-directional -- while physical interaction can affect virtual sketches, virtual sketches have no return effect on the physical objects or environment. In contrast, bi-directional sketching interaction allows the seamless coupling between sketches and actuated TUIs. In this paper, we employ tabletop-size small robots (Sony Toio) and an iPad-based AR sketching tool to demonstrate the concept. In our system, virtual sketches drawn and simulated on an iPad (e.g., lines, walls, pendulums, and springs) can move, actuate, collide, and constrain physical Toio robots, as if virtual sketches and the physical objects exist in the same space through seamless coupling between AR and robot motion. This paper contributes a set of novel interactions and a design space of bi-directional AR sketching. We demonstrate a series of potential applications, such as tangible physics education, explorable mechanism, tangible gaming for children, and in-situ robot programming via sketching.
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545626
ER  - 

TY  - NA
AU  - Scargill, Timothy; Chen, Ying; Eom, Sangjun; Dunn, Jessilyn; Gorlatova, Maria
TI  - Environmental, User, and Social Context-Aware Augmented Reality for Supporting Personal Development and Change
PY  - 2022
AB  - Robust pervasive context-aware augmented reality (AR) has the potential to enable a range of applications that support users in reaching their personal and professional goals. In such applications, AR can be used to deliver richer, more immersive, and more timely just in time adaptive interventions (JITAI) than conventional mo-bile solutions, leading to more effective support of the user. This position paper defines a research agenda centered on improving AR applications&#x0027; environmental, user, and social context awareness. Specifically, we argue for two key architectural approaches that will allow pushing AR context awareness to the next level: use of wearable and Internet of Things (IoT) devices as additional data streams that complement the data captured by the AR devices, and the development of edge computing-based mechanisms for enriching existing scene understanding and simultaneous localization and mapping (SLAM) algorithms. The paper outlines a collection of specific research directions in the development of such architectures and in the design of next-generation environmental, user, and social context awareness algorithms.
SP  - NA
EP  - NA
JF  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vrw55335.2022.00042
ER  - 

TY  - NA
AU  - Huang, Kunpeng; Sun, Ruojia; Zhang, Ximeng; Molla, Tahmidul Islam; Dunne, Margaret; Guimbretière, François; Kao, Cindy Hsin-Liu
TI  - Conference on Designing Interactive Systems - WovenProbe: Probing Possibilities for Weaving Fully-Integrated On-Skin Systems Deployable in the Field
PY  - 2021
AB  - On-skin interfaces demonstrate great potential given their direct skin contact; however, conducting field studies of these devices outside of laboratories and in real settings remains a challenge. We conduct a research-through-design investigation using an extended woven practice for fabricating fully-integrated and untethered multi-sensor on-skin systems that are resilient, versatile, and capable of field deployment. We designed, implemented, and deployed a woven on-skin index-finger and thumb-based inertial measurement unit (IMU) sensing system for multi-hour use as a technology probe to understand the social, technical, and design facets towards moving integrated on-skin systems into a wearer’s daily life. Further, we integrate a woven NFC coil into the IMU on-skin system, which is wirelessly powered by a smartwatch substitute, signifying the potential of our woven approach for developing wirelessly powered on-skin systems for longer-term continuous wear. Our investigation and the lessons learned shed light on the opportunities for designing on-skin systems for everyday wear.
SP  - 1143
EP  - 1158
JF  - Designing Interactive Systems Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3461778.3462105
ER  - 

TY  - NA
AU  - Zhu, Junyi; He, Liang; Nishida, Jun; Ghaednia, Hamid; Kao, Cindy Hsin-Liu; Froehlich, Jon E.; Wang, Edward Jay; Mueller, Stefanie
TI  - SIG: Towards More Personal Health Sensing
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3516408
ER  - 

TY  - NA
AU  - Griggs, Peter; Demiralp, Çağatay; Rahman, Sajjadur
TI  - Towards integrated, interactive, and extensible text data analytics with Leam
PY  - 2021
AB  - From tweets to product reviews, text is ubiquitous on the web and often contains valuable information for both enterprises and consumers. However, the online text is generally noisy and incomplete, requiring users to process and analyze the data to extract insights. While there are systems effective for different stages of text analysis, users lack extensible platforms to support interactive text analysis workflows end-to-end. To facilitate integrated text analytics, we introduce LEAM, which aims at combining the strengths of spreadsheets, computational notebooks, and interactive visualizations. LEAM supports interactive analysis via GUI-based interactions and provides a declarative specification language, implemented based on a visual text algebra, to enable user-guided analysis. We evaluate LEAM through two case studies using two popular Kaggle text analytics workflows to understand the strengths and weaknesses of the system.
SP  - 52
EP  - 58
JF  - Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances
VL  - NA
IS  - NA
PB  - 
DO  - 10.18653/v1/2021.dash-1.9
ER  - 

TY  - NA
AU  - Hofmann, Megan
TI  - UIST (Adjunct Volume) - Get the GIST: An Interactive Toolkit to Support Generative Design through Metaheuristic Optimization
PY  - 2021
AB  - Generative design tools afford designers new ways of creating complex objects from 3D models to machine knittable textures. However, implementing the optimization algorithms that make generative design possible requires the rare combination of programming and domain expertise. I present the Generative Interactive Synthesis Toolkit (GIST) to simplify the implementation of generative design tools in novel domains. GIST factors common optimization algorithms into elements of an extensible library and structures optimization tasks around objectives and tactics specified by domain experts in a simple GUI. This moves the burden of domain expertise from programmers to domain experts. I demonstrate GIST in three unique domains: machine knitting, cookie recipes, and tactile maps for blind users. These show the versatility of GIST’s structure.
SP  - 148
EP  - 152
JF  - The Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3474349.3477584
ER  - 

TY  - JOUR
AU  - Barrera-Leon, Luisa; Corno, Fulvio; De Russis, Luigi
TI  - How the Preattentive Process is Exploited in Practical Information Visualization Design: A Review
PY  - 2022
AB  - NA
SP  - 707
EP  - 720
JF  - International Journal of Human–Computer Interaction
VL  - 39
IS  - 4
PB  - 
DO  - 10.1080/10447318.2022.2049137
ER  - 

TY  - NA
AU  - Chang, Ruei-Che; Tsao, Chih-An; Liao, Fang-Ying; Yong, Seraphina; Yeh, Tom; Chen, Bing-Yu
TI  - UIST - Daedalus in the Dark: Designing for Non-Visual Accessible Construction of Laser-Cut Architecture
PY  - 2021
AB  - Design tools and research regarding laser-cut architectures have been widely explored in the past decade. However, such discussion has mostly revolved around technical and structural design questions instead of another essential element of laser-cut models — assembly — a process that relies heavily on components’ visual affordance, therefore less accessible to blind or low vision (BLV) people. To narrow the gap in this area, we co-designed with 7 BLV people to examine their assembly experience with different laser-cut architectures. From their feedback, we proposed several design heuristics and guidelines for Daedalus, a generative design tool that can produce tactile aids for laser-cut assembly given a few high-level manual inputs. We validate the proposed aids in a user study with 8 new BLV participants. Our results revealed that BLV users can manage laser-cut assembly more efficiently with Daedalus. Going forth from this design iteration, we discuss implications for future research on accessible laser-cut assembly.
SP  - 344
EP  - 358
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474754
ER  - 

TY  - NA
AU  - Chang, Joseph Chee; Hahn, Nathan; Kim, Yongsung; Coupland, Julina; Breneisen, Bradley; Kim, Hannah S; Hwong, John; Kittur, Aniket
TI  - CHI - When the Tab Comes Due:Challenges in the Cost Structure of Browser Tab Usage
PY  - 2021
AB  - Tabs have become integral to browsing the Web yet have changed little since their introduction nearly 20 years ago. In contrast, the internet has gone through dramatic changes, with users increasingly moving from navigating to websites to exploring information across many sources to support online sensemaking. This paper investigates how tabs today are overloaded with a diverse set of functionalities and issues users face when managing them. We interviewed ten information workers asking about their tab management strategies and walk through each open tab on their work computers four times over two weeks. We uncovered competing pressures pushing for keeping tabs open (ranging from interaction to emotional costs) versus pushing for closing them (such as limited attention and resources). We then surveyed 103 participants to estimate the frequencies of these pressures at scale. Finally, we developed design implications for future browser interfaces that can better support managing these pressures.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445585
ER  - 

TY  - NA
AU  - Sun, Lingyun; Pan, Deying; Fan, Yitao; Yang, Yue; Li, Jiaji; Chen, Yu; Tao, Ye; Wang, Guanyun
TI  - JellyBoard: A Flexible Breadboard for Electronic Prototyping
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - The Ninth International Symposium of Chinese CHI
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490355.3490369
ER  - 

TY  - JOUR
AU  - Shin, Sungbok; Chung, Sunghyo; Hong, Sanghyun; Elmqvist, Niklas
TI  - A Scanner Deeply: Predicting Gaze Heatmaps On Visualizations Using Crowdsourced Eye Movement Data.
PY  - 2022
AB  - Visual perception is a key component of data visualization. Much prior empirical work uses eye movement as a proxy to understand human visual perception. Diverse apparatus and techniques have been proposed to collect eye movements, but there is still no optimal approach. In this paper, we review 30 prior works for collecting eye movements based on three axes: (1) the tracker technology used to measure eye movements; (2) the image stimulus shown to participants; and (3) the collection methodology used to gather the data. Based on this taxonomy, we employ a webcam-based eyetracking approach using task-specific visualizations as the stimulus. The low technology requirement means that virtually anyone can participate, thus enabling us to collect data at large scale using crowdsourcing: approximately 12,000 samples in total. Choosing visualization images as stimulus means that the eye movements will be specific to perceptual tasks associated with visualization. We use these data to propose a SCANNER DEEPLY, a virtual eyetracker model that, given an image of a visualization, generates a gaze heatmap for that image. We employ a computationally efficient, yet powerful convolutional neural network for our model. We compare the results of our work with results from the DVS model and a neural network trained on the Salicon dataset. The analysis of our gaze patterns enables us to understand how users grasp the structure of visualized data. We also make our stimulus dataset of visualization images available as part of this paper's contribution.
SP  - 1
EP  - 11
JF  - IEEE transactions on visualization and computer graphics
VL  - PP
IS  - NA
PB  - 
DO  - 10.1109/tvcg.2022.3209472
ER  - 

TY  - CHAP
AU  - Lebrun, Flavien; Haliyo, Sinan; Bailly, Gilles
TI  - INTERACT (5) - A Trajectory Model for Desktop-Scale Hand Redirection in Virtual Reality
PY  - 2021
AB  - In Virtual Reality, visuo-haptic illusions such as hand redirection introduce a discrepancy between the user’s hand and its virtual avatar. This visual shift can be used, for instance, to provide multiple virtual haptic objects through a single physical proxy object. This low-cost approach improves the sense of presence, however, it is unclear how these illusions impact the hand trajectory and if there is a relationship between trajectory and the detection of illusion. In this paper, we present an empirical model predicting the hand trajectory as a function of the redirection. It relies on a cubic Bezier curve with 4 control points. We conduct a two alternative forced choice (2AFC) experiment to calibrate and validate our model. Results show that (1) our model predicts well the hand trajectory of each individual using a single parameter; (2) the hand trajectory better explains the detection of the illusion than the amplitude of the redirection alone; (3) a user specific calibration allows to predict per-user redirected trajectories and detection probabilities. Our findings provide a better understanding of visuo-haptic illusions and how they impact the user’s movements. As such they may provide foundations to design novel interaction techniques, e.g. interacting in a scene with multiple physical obstacles.
SP  - 105
EP  - 124
JF  - Human-Computer Interaction – INTERACT 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-85607-6_8
ER  - 

TY  - JOUR
AU  - Hetzel, Lorenz; Dudley, John; Feit, Anna Maria; Kristensson, Per Ola
TI  - Complex Interaction as Emergent Behaviour: Simulating Mid-Air Virtual Keyboard Typing using Reinforcement Learning
PY  - 2021
AB  - Accurately modelling user behaviour has the potential to significantly improve the quality of human-computer interaction. Traditionally, these models are carefully hand-crafted to approximate specific aspects of well-documented user behaviour. This limits their availability in virtual and augmented reality where user behaviour is often not yet well understood. Recent efforts have demonstrated that reinforcement learning can approximate human behaviour during simple goal-oriented reaching tasks. We build on these efforts and demonstrate that reinforcement learning can also approximate user behaviour in a complex mid-air interaction task: typing on a virtual keyboard. We present the first reinforcement learning-based user model for mid-air and surface-aligned typing on a virtual keyboard. Our model is shown to replicate high-level human typing behaviour. We demonstrate that this approach may be used to augment or replace human testing during the validation and development of virtual keyboards.
SP  - 4140
EP  - 4149
JF  - IEEE transactions on visualization and computer graphics
VL  - 27
IS  - 11
PB  - 
DO  - 10.1109/tvcg.2021.3106494
ER  - 

TY  - NA
AU  - Yamanaka, Shota; Usuba, Hiroki
TI  - Computing Touch-Point Ambiguity on Mobile Touchscreens for Modeling Target Selection Times
PY  - 2021
AB  - Finger-Fitts law (FFitts law) is a model to predict touch-pointing times modified from Fitts' law. It considers the absolute touch-point precision, or a finger tremor factor sigma_a, to decrease the admissible target area and thus increase the task difficulty. Among choices such as running an independent task or performing parameter optimization, there is no consensus on the best methodology to measure sigma_a. This inconsistency could be harmful to HCI studies such as evaluating pointing techniques and comparing user groups. By integrating the results of our 1D and 2D touch-pointing experiments and reanalyses of previous studies' data, we examined the advantages and disadvantages of each approach to compute sigma_a, and we found that using the parameter optimization method has overall the best prediction performance.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Yamamoto, Kenta; Suzuki, Ippei; Shitara, Akihisa; Ochiai, Yoichi
TI  - ASSETS - See-Through Captions: Real-Time Captioning on Transparent Display for Deaf and Hard-of-Hearing People
PY  - 2021
AB  - Real-time captioning is a useful technique for deaf and hard-of-hearing (DHH) people to talk to hearing people. With the improvement in device performance and the accuracy of automatic speech recognition (ASR), real-time captioning is becoming an important tool for helping DHH people in their daily lives. To realize higher-quality communication and overcome the limitations of mobile and augmented-reality devices, real-time captioning that can be used comfortably while maintaining nonverbal communication and preventing incorrect recognition is required. Therefore, we propose a real-time captioning system that uses a transparent display. In this system, the captions are presented on both sides of the display to address the problem of incorrect ASR results, and the highly transparent display makes it possible to see both the body language and the captions.
SP  - NA
EP  - NA
JF  - The 23rd International ACM SIGACCESS Conference on Computers and Accessibility
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3441852.3476551
ER  - 

TY  - NA
AU  - Li, Toby Jia-Jun; Popowski, Lindsay; Mitchell, Tom M.; Myers, Brad A.
TI  - Screen2Vec: Semantic Embedding of GUI Screens and GUI Components
PY  - 2021
AB  - Representing the semantics of GUI screens and components is crucial to data-driven computational methods for modeling user-GUI interactions and mining GUI designs. Existing GUI semantic representations are limited to encoding either the textual content, the visual design and layout patterns, or the app contexts. Many representation techniques also require significant manual data annotation efforts. This paper presents Screen2Vec, a new self-supervised technique for generating representations in embedding vectors of GUI screens and components that encode all of the above GUI features without requiring manual annotation using the context of user interaction traces. Screen2Vec is inspired by the word embedding method Word2Vec, but uses a new two-layer pipeline informed by the structure of GUIs and interaction traces and incorporates screen- and app-specific metadata. Through several sample downstream tasks, we demonstrate Screen2Vec's key useful properties: representing between-screen similarity through nearest neighbors, composability, and capability to represent user tasks.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445049
ER  - 

TY  - NA
AU  - Shi, Yinghan; Zhao, Lizhi; Lu, Xuequan; Hoang, Thuong; Wang, Meili
TI  - Grasping 3D Objects With Virtual Hand in VR Environment
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3574131.3574428
ER  - 

TY  - NA
AU  - Yan, Zeyu; Sathya, Anup; Carvalho, Pedro; Hu, Yongquan; Li, Annan; Peng, Huaishu
TI  - CHI Extended Abstracts - Towards On-the-wall Tangible Interaction: Using Walls as Interactive, Dynamic, and Responsive User Interface
PY  - 2021
AB  - This paper presents our vision of on-the-wall tangible interaction. We envision a future where tangible interaction can be extended from conventional horizontal surfaces to vertical surfaces; indoor vertical areas such as walls, windows, and ceilings can be used for dynamic and direct physical manipulation. We first discuss the unique properties that vertical surfaces may offer for tangible interaction and the interaction scenarios they imbue. We then propose two potential paths for realizing on-the-wall interaction and the technical challenges we face. We follow with one prototype called Climbot. We showcase how Climbot can be used as an on-the-wall tangible user interface for dynamic lighting and as a wall switch controller. We conclude with a discussion of future work.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451586
ER  - 

TY  - NA
AU  - Barlas, Efe; Du, Xin; Davis, James C.
TI  - Exploiting input sanitization for regex denial of service
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 44th International Conference on Software Engineering
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3510003.3510047
ER  - 

TY  - JOUR
AU  - Thomas, Paul; Czerwinksi, Mary; McDuff, Daniel; Craswell, Nick
TI  - Theories of Conversation for Conversational IR
PY  - 2021
AB  - Conversational information retrieval is a relatively new and fast-developing research area, but conversation itself has been well studied for decades. Researchers have analysed linguistic phenomena such as structure and semantics but also paralinguistic features such as tone, body language, and even the physiological states of interlocutors. We tend to treat computers as social agents—especially if they have some humanlike features in their design—and so work from human-to-human conversation is highly relevant to how we think about the design of human-to-computer applications. In this article, we summarise some salient past work, focusing on social norms; structures; and affect, prosody, and style. We examine social communication theories briefly as a review to see what we have learned about how humans interact with each other and how that might pertain to agents and robots. We also discuss some implications for research and design of conversational IR systems.
SP  - 1
EP  - 23
JF  - ACM Transactions on Information Systems
VL  - 39
IS  - 4
PB  - 
DO  - 10.1145/3439869
ER  - 

TY  - NA
AU  - Abdullah, Muhammad; Sommerfeld, Romeo; Sievers, Bjarne; Geier, Leonard; Noack, Jonas; Ding, Marcus; Thieme, Christoph; Seidel, Laurenz; Fritzsche, Lukas; Langenhan, Erik; Adameck, Oliver; Dzingel, Moritz; Kern, Thomas; Taraz, Martin; Lempert, Conrad; Katakura, Shohei; Elhassany, Hany Mohsen; Roumen, Thijs; Baudisch, Patrick
TI  - HingeCore: Laser-Cut Foamcore for Fast Assembly
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545618
ER  - 

TY  - NA
AU  - Abtahi, Parastoo
TI  - UIST (Adjunct Volume) - From Illusions to Beyond-Real Interactions in Virtual Reality
PY  - 2021
AB  - Despite recent advances in technology, current virtual reality (VR) experiences have many limitations. When designing VR interactions, we can leverage the unique affordances of this virtual medium and our ability to programmatically control the renderings to not only overcome these limitations, but also to create new interactions that go beyond the replication of the real world. In my dissertation, I seek to answer the following research questions: How can we utilize the unique affordances that VR offers to overcome the current limitations of this technology? How can we go even further and design mixed reality interactions that leverage these affordances to extend our experiences in the real world? In my work, I approach movement-based VR interactions from a sensorimotor control perspective, carefully considering the plasticity and limits of human perception. To answer the first research question, I explore various visuo-haptic illusions to overcome the limitations of existing haptic devices. In my ongoing work, I am building tools that help researchers and practitioners design and evaluate novel and usable mixed reality interactions that have no real-world counterparts.
SP  - 153
EP  - 157
JF  - The Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3474349.3477586
ER  - 

TY  - NA
AU  - Hofmann, Megan; Mack, Kelly; Birchfield, Jessica; Cao, Jerry; Hughes, Autumn G; Kurpad, Shriya; Lum, Kathryn J; Warnock, Emily; Caspi, Anat; Hudson, Scott E; Mankoff, Jennifer
TI  - Maptimizer: Using Optimization to Tailor Tactile Maps to Users Needs
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517436
ER  - 

TY  - NA
AU  - Zenner, André; Kriegler, Hannah Maria; Krüger, Antonio
TI  - CHI Extended Abstracts - HaRT - The Virtual Reality Hand Redirection Toolkit
PY  - 2021
AB  - Past research has proposed various hand redirection techniques for virtual reality (VR). Such techniques modify a user’s hand movements and have been successfully used to enhance haptics and 3D user interfaces. Up to now, however, no unified framework exists that implements previously proposed techniques such as body warping, world warping, and hybrid methods. In this work, we present the Virtual Reality Hand Redirection Toolkit (HaRT), an open-source framework developed for the Unity engine. The toolkit aims to support both novice and expert VR researchers and practitioners in implementing and evaluating hand redirection techniques. It provides implementations of popular redirection algorithms and exposes a modular class hierarchy for easy integration of new approaches. Moreover, simulation, logging, and visualization features allow users of the toolkit to analyze hand redirection setups with minimal technical effort. We present the architecture of the toolkit along with the results of a qualitative expert study.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451814
ER  - 

TY  - JOUR
AU  - Speicher, Maximilian; Lewis, Katy; Nebeling, Michael
TI  - Designers, the Stage Is Yours! Medium-Fidelity Prototyping of Augmented & Virtual Reality Interfaces with 360theater
PY  - 2021
AB  - While augmented and virtual reality technologies are becoming mainstream, it is still technically challenging and time-consuming to create new applications. Many designers draw from traditional low-fidelity prototyping methods that do not lend themselves well to designing in 3D. Developers use high-end programming frameworks such as Unity and Unreal which require significant hardware/software setups and coding skills. We see a gap in the medium-fidelity range where there is an opportunity for new tools to leverage the advantages of 360° content for AR/VR prototyping. Existing tools, however, have only limited support for 3D geometry, spatial and proxemic interactions, puppeteering, and storytelling. We present 360theater, a new method and a tool for rapid prototyping of AR/VR experiences, which takes dioramas into the virtual realm by enhancing 360° video capture with 3D geometry and simulating spatial interactions via Wizard of Oz. Our comparative evaluation of techniques with novice and experienced AR/VR designers shows that 360theater can close the gap and achieve a higher fidelity and more realistic AR/VR prototypes than comparable methods.
SP  - 1
EP  - 25
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 5
IS  - EICS
PB  - 
DO  - 10.1145/3461727
ER  - 

TY  - NA
AU  - Wang, Bryan; Li, Gang; Zhou, Xin; Chen, Zhourong; Grossman, Tovi; Li, Yang
TI  - Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning
PY  - 2021
AB  - Mobile User Interface Summarization generates succinct language descriptions of mobile screens for conveying important contents and functionalities of the screen, which can be useful for many language-based application scenarios. We present Screen2Words, a novel screen summarization approach that automatically encapsulates essential information of a UI screen into a coherent language phrase. Summarizing mobile screens requires a holistic understanding of the multi-modal data of mobile UIs, including text, image, structures as well as UI semantics, motivating our multi-modal learning approach. We collected and analyzed a large-scale screen summarization dataset annotated by human workers. Our dataset contains more than 112k language summarization across $\sim$22k unique UI screens. We then experimented with a set of deep models with different configurations. Our evaluation of these models with both automatic accuracy metrics and human rating shows that our approach can generate high-quality summaries for mobile screens. We demonstrate potential use cases of Screen2Words and open-source our dataset and model to lay the foundations for further bridging language and user interfaces.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Jhaver, Shagun; Frey, Seth; Zhang, Amy X.
TI  - Designing for Multiple Centers of Power: A Taxonomy of Multi-level Governance in Online Social Platforms
PY  - 2021
AB  - Many have criticized the centralized and unaccountable governance of prominent online social platforms, leading to renewed interest in governance that incorporates multiple centers of power. Decentralized power can arise horizontally, through parallel communities each with local administration, as well as vertically, through multiple levels of jurisdiction. Drawing from literature from organizational theory, federalism, and polycentricity on analogous offline institutions, we characterize the landscape of existing platforms through the lens of multi-level governance, allowing us to describe how a variety of platforms, including Reddit, Twitter, and YouTube, incorporate decentralization. In particular, we examine how local governance centers, or middle levels such as subreddits, Twitter blocklists, and YouTube channels, interact with one another and with a centralized governance system above and end users below. As not all aspects of offline institutions translate online, we discuss challenges unique to online governance and conclude with implications for decentralized governance design in online social platforms.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Isotani, Haruna; Washizaki, Hironori; Fukazawa, Yoshiaki; Nomoto, Tsutomu; Ouji, Saori; Saito, Shinobu
TI  - Sentence embedding and fine-tuning to automatically identify duplicate bugs
PY  - 2023
AB  - <jats:p>Industrial software maintenance is critical but burdensome. Activities such as detecting duplicate bug reports are often performed manually. Herein an automated duplicate bug report detection system improves maintenance efficiency using vectorization of the contents and deep learning–based sentence embedding to calculate the similarity of the whole report from vectors of individual elements. Specifically, sentence embedding is realized using Sentence-BERT fine tuning. Additionally, its performance is experimentally compared to baseline methods to validate the proposed system. The proposed system detects duplicate bug reports more effectively than existing methods.</jats:p>
SP  - NA
EP  - NA
JF  - Frontiers in Computer Science
VL  - 4
IS  - NA
PB  - 
DO  - 10.3389/fcomp.2022.1032452
ER  - 

TY  - JOUR
AU  - Hoque, E.; Kavehzadeh, P.; Masry, A.
TI  - Chart Question Answering: State of the Art and Future Directions
PY  - 2022
AB  - Information visualizations such as bar charts and line charts are very common for analyzing data and discovering critical insights. Often people analyze charts to answer questions that they have in mind. Answering such questions can be challenging as they often require a significant amount of perceptual and cognitive effort. Chart Question Answering (CQA) systems typically take a chart and a natural language question as input and automatically generate the answer to facilitate visual data analysis. Over the last few years, there has been a growing body of literature on the task of CQA. In this survey, we systematically review the current state-of-the-art research focusing on the problem of chart question answering. We provide a taxonomy by identifying several important dimensions of the problem domain including possible inputs and outputs of the task and discuss the advantages and limitations of proposed solutions. We then summarize various evaluation techniques used in the surveyed papers. Finally, we outline the open challenges and future research opportunities related to chart question answering.
SP  - 555
EP  - 572
JF  - Computer Graphics Forum
VL  - 41
IS  - 3
PB  - 
DO  - 10.1111/cgf.14573
ER  - 

TY  - JOUR
AU  - Butt, Javaid; Bhaskar, Raghunath; Mohaghegh, Vahaj
TI  - Investigating the effects of extrusion temperatures and material extrusion rates on FFF-printed thermoplastics
PY  - 2021
AB  - Fused filament fabrication (FFF) is one of the most widely used additive manufacturing processes in the market. It is based on material extrusion and utilises thermoplastic materials to manufacture bespoke products. The process is extremely popular due to its ease of operation and variety of available materials. To enhance the mechanical performance of parts made by FFF, reinforcements including nanoparticles, short or continuous fibres, and other additives have been added to commonly used thermoplastics such as acrylonitrile butadiene styrene (ABS) and polylactic acid (PLA). Such new materials require optimisation of process parameters to achieve the desired results. One such parameter is the material extrusion rate that can result in under- or over-extrusion leading to a variety of applications. In this study, PLA and HDPlas® PLA-GNP-A (PLA reinforced with functionalised graphene nanoplatelets) have been used to investigate the effects of material extrusion rate. An extensive comparative analysis has been provided where parts have been manufactured using a desktop 3D printer with the two materials at four extrusion temperatures (180 °C, 190 °C, 200 °C, and 210 °C) and ten different extrusion rates (ranging from 70 to 160%). The study aims to evaluate the effects of extrusion temperatures and material extrusion rates on mass, dimensional accuracy, surface texture, and mechanical properties of the two materials. Microstructural analysis has also been carried out to evaluate the surfaces of parts after manufacture as well as their fractured surfaces after mechanical testing to determine the impact of extrusion rate on failure modes. The results have shown that the graphene reinforced PLA material is affected more adversely by changes in material extrusion rate compared to PLA. This work provides a good comparison between two materials manufactured at four different extrusion temperatures and how the material extrusion rate can be leveraged to achieve optimal surface finish and mechanical strength.
SP  - 1
EP  - 21
JF  - The International Journal of Advanced Manufacturing Technology
VL  - 117
IS  - 9
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Ahuja, Karan; Mayer, Sven; Goel, Mayank; Harrison, Chris
TI  - CHI - Pose-on-the-Go: Approximating User Pose with Smartphone Sensor Fusion and Inverse Kinematics
PY  - 2021
AB  - We present Pose-on-the-Go, a full-body pose estimation system that uses sensors already found in today’s smartphones. This stands in contrast to prior systems, which require worn or external sensors. We achieve this result via extensive sensor fusion, leveraging a phone’s front and rear cameras, the user-facing depth camera, touchscreen, and IMU. Even still, we are missing data about a user’s body (e.g., angle of the elbow joint), and so we use inverse kinematics to estimate and animate probable body poses. We provide a detailed evaluation of our system, benchmarking it against a professional-grade Vicon tracking system. We conclude with a series of demonstration applications that underscore the unique potential of our approach, which could be enabled on many modern smartphones with a simple software update.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445582
ER  - 

TY  - CONF
AU  - Hong, Freddie; Myant, Connor; Boyle, David
TI  - CHI - Thermoformed Circuit Boards: Fabrication of highly conductive freeform 3D printed circuit boards with heat bending
PY  - 2021
AB  - Fabricating 3D printed electronics using desktop printers has become more accessible with recent developments in conductive thermoplastic filaments. Because of their high resistance and difficulties in printing traces in vertical directions, most applications are restricted to capacitive sensing. In this paper, we introduce Thermoformed Circuit Board (TCB), a novel approach that employs the thermoformability of the 3D printed plastics to construct various double-sided, rigid and highly conductive freeform circuit boards that can withstand high current applications through copper electroplating. To illustrate the capability of the TCB, we showcase a range of examples with various shapes, electrical characteristics and interaction mechanisms. We also demonstrate a new design tool extension to an existing CAD environment that allows users to parametrically draw the substrate and conductive trace, and export 3D printable files. TCB is an inexpensive and highly accessible fabrication technique intended to broaden HCI researcher participation.
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Jiang, Weiwei; Wang, Chaofan; Sarsenbayeva, Zhanna; Irlitti, Andrew; Knibbe, Jarrod; Dingler, Tilman; Goncalves, Jorge; Kostakos, Vassilis
TI  - InfoPrint: Embedding Information into 3D Printed Objects.
PY  - 2021
AB  - We present a technique to embed information invisible to the eye inside 3D printed objects. The information is integrated in the object model, and then fabricated using off-the-shelf dual-head FDM (Fused Deposition Modeling) 3D printers. Our process does not require human intervention during or after printing with the integrated model. The information can be arbitrary symbols, such as icons, text,binary, or handwriting. To retrieve the information, we evaluate two different infrared-based imaging devices that are readily available-thermal cameras and near-infrared scanners. Based on our results, we propose design guidelines for a range of use cases to embed and extract hidden information. We demonstrate how our method can be used for different applications, such as interactive thermal displays, hidden board game tokens, tagging functional printed objects, and autographing non-fungible fabrication work.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Setlur, Vidya; E, Battersby Sarah; Wong, Tracy
TI  - GeoSneakPique: Visual Autocompletion for Geospatial Queries
PY  - 2021
AB  - How many crimes occurred in the city center? And exactly which part of town is the 'city center'? While location is at the heart of many data questions, geographic location can be difficult to specify in natural language (NL) queries. This is especially true when working with fuzzy cognitive regions or regions that may be defined based on data distributions instead of absolute administrative location (e.g., state, country). GeoSneakPique presents a novel method for using a mapping widget to support the NL query process, allowing users to specify location via direct manipulation with data-driven guidance on spatial distributions to help select the area of interest. Users receive feedback to help them evaluate and refine their spatial selection interactively and can save spatial definitions for re-use in subsequent queries. We conduct a qualitative evaluation of the GeoSneakPique that indicates the usefulness of the interface as well as opportunities for better supporting geospatial workflows in visual analysis tasks employing cognitive regions.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Mallalieu, A.; Hajali, T.; Isaksson, O.; Panarotto, M.
TI  - The Role of Digital Infrastructure for the Industrialisation of Design for Additive Manufacturing
PY  - 2022
AB  - <jats:title>Abstract</jats:title><jats:p>The use of Additive Manufacturing (AM) can bring opportunities for industry, but several challenges need to be addressed, specifically the digital infrastructure comprising the AM value chain. A combination of a systematic literature review and an industrial use case study concludes that there is low consideration of the digital infrastructure in Design for Additive Manufacturing (DfAM) methods and tools which has a negative impact on the industrialisation of AM. It is therefore recommended that further studies are to be made on how to manage the digital infrastructure in DfAM processes.</jats:p>
SP  - 1401
EP  - 1410
JF  - Proceedings of the Design Society
VL  - 2
IS  - NA
PB  - 
DO  - 10.1017/pds.2022.142
ER  - 

TY  - NA
AU  - Pourjafarian, Narjes; Koelle, Marion; Mjaku, Fjolla; Strohmeier, Paul; Steimle, Jürgen
TI  - Print-A-Sketch: A Handheld Printer for Physical Sketching of Circuits and Sensors on Everyday Surfaces
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502074
ER  - 

TY  - NA
AU  - Lu, Qian; Darnal, Aryabhat; Takahashi, Haruki; Muliana, Anastasia Hanifah; Kim, Jeeeun
TI  - User-Centered Property Adjustment with Programmable Filament
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519864
ER  - 

TY  - CHAP
AU  - Schmidt, Johanna
TI  - Visual Data Science
PY  - 2022
AB  - <jats:p>Organizations are collecting an increasing amount of data every day. To make use of this rich source of information, more and more employees have to deal with data analysis and data science. Exploring data, understanding its structure, and finding new insights, can be greatly supported by data visualization. Therefore, the increasing interest in data science and data analytics also leads to a growing interest in data visualization and exploratory data analysis. We will outline how existing data visualization techniques are already successfully employed in different data science workflow stages. In some cases, visualization is beneficial, while still future research will be needed for other categories. The vast amount of libraries and applications available for data visualization has fostered its usage in data science. We will highlight the differences among the libraries and applications currently available. Unfortunately, there is still a clear gap between visualization research developments over the past decades and the features provided by commonly used tools and data science applications. Although basic charting options are commonly available, more advanced visualization techniques have hardly been integrated as new features yet.</jats:p>
SP  - NA
EP  - NA
JF  - Data Science, Data Visualization, and Digital Twins
VL  - NA
IS  - NA
PB  - 
DO  - 10.5772/intechopen.97750
ER  - 

TY  - NA
AU  - Matulic, Fabrice; Ganeshan, Aditya; Fujiwara, Hiroshi; Vogel, Daniel
TI  - CHI - Phonetroller: Visual Representations of Fingers for Precise Touch Input with Mobile Phones in VR
PY  - 2021
AB  - Smartphone touch screens are potentially attractive for interaction in virtual reality (VR). However, the user cannot see the phone or their hands in a fully immersive VR setting, impeding their ability for precise touch input. We propose mounting a mirror above the phone screen such that the front-facing camera captures the thumbs on or near the screen. This enables the creation of semi-transparent overlays of thumb shadows and inference of fingertip hover points with deep learning, which help the user aim for targets on the phone. A study compares the effect of visual feedback on touch precision in a controlled task and qualitatively evaluates three example applications demonstrating the potential of the technique. The results show that the enabled style of feedback is effective for thumb-size targets, and that the VR experience can be enriched by using smartphones as VR controllers supporting precise touch input.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445583
ER  - 

TY  - NA
AU  - Palani, Srishti; Ding, Zijian; MacNeil, Stephen; Dow, Steven
TI  - CHIIR - The "Active Search" Hypothesis: How Search Strategies Relate to Creative Learning
PY  - 2021
AB  - While research shows that web search plays a role throughout the creative process, less is known about about how people use web search to learn and frame their thinking about an open problem. People need web search to gather information about a problem area, but this can also influence the rest of the creative process. To understand how web search affects early-stage design, we collected and analyzed search log and self-report data from 34 students in a project-based design class. Participants reported struggling with scoping broad, ill-defined information goals into queries, learning domain-specific language, and assessing the usefulness of information. Analysis found that more active and diverse search behavior (i.e. issuing more frequent and diverse queries, and opening more webpages) related to more progress in early-stage design (i.e. gathering more facts, articulating more insights, and developing better problem frames). Based on these findings, we discuss implications for designing search tools to support peoples' creative processes.
SP  - 325
EP  - 329
JF  - Proceedings of the 2021 Conference on Human Information Interaction and Retrieval
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3406522.3446046
ER  - 

TY  - NA
AU  - Petrík, Vladimír; Tapaswi, Makarand; Laptev, Ivan; Sivic, Josef
TI  - Learning Object Manipulation Skills via Approximate State Estimation from Real Videos
PY  - 2020
AB  - Humans are adept at learning new tasks by watching a few instructional videos. On the other hand, robots that learn new actions either require a lot of effort through trial and error, or use expert demonstrations that are challenging to obtain. In this paper, we explore a method that facilitates learning object manipulation skills directly from videos. Leveraging recent advances in 2D visual recognition and differentiable rendering, we develop an optimization based method to estimate a coarse 3D state representation for the hand and the manipulated object(s) without requiring any supervision. We use these trajectories as dense rewards for an agent that learns to mimic them through reinforcement learning. We evaluate our method on simple single- and two-object actions from the Something-Something dataset. Our approach allows an agent to learn actions from single videos, while watching multiple demonstrations makes the policy more robust. We show that policies learned in a simulated environment can be easily transferred to a real robot.
SP  - NA
EP  - NA
JF  - arXiv: Robotics
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Bouzbib, Elodie; Bailly, Gilles
TI  - "Let's Meet and Work it Out": Understanding and Mitigating Encountered-Type of Haptic Devices Failure Modes in VR
PY  - 2022
AB  - Encountered-type of Haptic devices (ETHD) are robotic interfaces physically overlaying virtual counterparts prior to a user interaction in Virtual Reality. They theoretically reliably provide haptics in Virtual environments, yet they raise several intrinsic design challenges to properly display rich haptic feedback and interactions in VR applications. In this paper, we use a Failure Mode and Effects Analysis (FMEA) approach to identify, organise and analyse the failure modes and their causes in the different stages of an ETHD scenario and highlight appropriate solutions from the literature to mitigate them. We help justify these interfaces&#x2019; lack of deployment, to ultimately identify guidelines for future ETHD designers.
SP  - NA
EP  - NA
JF  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr51125.2022.00055
ER  - 

TY  - NA
AU  - Feick, Martin; Regitz, Kora Persephone; Tang, Anthony; Krüger, Antonio
TI  - Designing Visuo-Haptic Illusions with Proxies in Virtual Reality: Exploration of Grasp, Movement Trajectory and Object Mass
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517671
ER  - 

TY  - NA
AU  - Choi, Byungkuk; Eom, Haekwang; Mouscadet, Benjamin; Cullingford, Stephen; Ma, Kurt; Gassel, Stefanie; Kim, Suzi; Moffat, Andrew; Maier, Millicent; Revelant, Marco; Letteri, Joe; Singh, Karan
TI  - Animatomy: an Animator-centric, Anatomically Inspired System for 3D Facial Modeling, Animation and Transfer
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - SIGGRAPH Asia 2022 Conference Papers
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3550469.3555398
ER  - 

TY  - NA
AU  - Dong, Rui; Huang, Zhicheng; Lam, Ian Iong; Chen, Yan; Wang, Xinyu
TI  - WebRobot: web robotic process automation using interactive programming-by-demonstration
PY  - 2022
AB  - It is imperative to democratize robotic process automation (RPA), as RPA has become a main driver of the digital transformation but is still technically very demanding to construct, especially for non-experts. In this paper, we study how to automate an important class of RPA tasks, dubbed web RPA, which are concerned with constructing software bots that automate interactions across data and a web browser. Our main contributions are twofold. First, we develop a formal foundation which allows semantically reasoning about web RPA programs and formulate its synthesis problem in a principled manner. Second, we propose a web RPA program synthesis algorithm based on a new idea called speculative rewriting. This leads to a novel speculate-and-validate methodology in the context of rewrite-based program synthesis, which has also shown to be both theoretically simple and practically efficient for synthesizing programs from demonstrations. We have built these ideas in a new interactive synthesizer called WebRobot and evaluate it on 76 web RPA benchmarks. Our results show that WebRobot automated a majority of them effectively. Furthermore, we show that WebRobot compares favorably with a conventional rewrite-based synthesis baseline implemented using egg. Finally, we conduct a small user study demonstrating WebRobot is also usable.
SP  - NA
EP  - NA
JF  - Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3519939.3523711
ER  - 

TY  - CONF
AU  - Zhang, Baowen; Wang, Yangang; Deng, Xiaoming; Zhang, Yinda; Tan, Ping; Ma, Cuixia; Wang, Hongan
TI  - Interacting Two-Hand 3D Pose and Shape Reconstruction From Single Color Image
PY  - 2021
AB  - NA
SP  - 11354
EP  - 11363
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Wang, Zeyu; Nguyen, Cuong; Asente, Paul; Dorsey, Julie
TI  - CHI - DistanciAR: Authoring Site-Specific Augmented Reality Experiences for Remote Environments
PY  - 2021
AB  - Most augmented reality (AR) authoring tools only support the author’s current environment, but designers often need to create site-specific experiences for a different environment. We propose DistanciAR, a novel tablet-based workflow for remote AR authoring. Our baseline solution involves three steps. A remote environment is captured by a camera with LiDAR; then, the author creates an AR experience from a different location using AR interactions; finally, a remote viewer consumes the AR content on site. A formative study revealed understanding and navigating the remote space as key challenges with this solution. We improved the authoring interface by adding two novel modes: Dollhouse, which renders a bird’s-eye view, and Peek, which creates photorealistic composite images using captured images. A second study compared this improved system with the baseline, and participants reported that the new modes made it easier to understand and navigate the remote scene.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445552
ER  - 

TY  - NA
AU  - Pang, Rock Yuren; Wang, Ruotong; Nelson, Joely; Battle, Leilani
TI  - How Do Data Science Workers Communicate Intermediate Results?
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE Visualization in Data Science (VDS)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vds57266.2022.00010
ER  - 

TY  - NA
AU  - Liu, Vivian; Qiao, Han; Chilton, Lydia
TI  - Opal: Multimodal Image Generation for News Illustration
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545621
ER  - 

TY  - NA
AU  - Langerak, Thomas; Zarate, Juan Jose; Lindlbauer, David; Holz, Christian; Hilliges, Otmar
TI  - UIST - Omni: Volumetric Sensing and Actuation of Passive Magnetic Tools for Dynamic Haptic Feedback
PY  - 2020
AB  - We present Omni, a self-contained 3D haptic feedback system that is capable of sensing and actuating an untethered, passive tool containing only a small embedded permanent magnet. Omni enriches AR, VR and desktop applications by providing an active haptic experience using a simple apparatus centered around an electromagnetic base. The spatial haptic capabilities of Omni are enabled by a novel gradient-based method to reconstruct the 3D position of the permanent magnet in midair using the measurements from eight off-the-shelf hall sensors that are integrated into the base. Omni's 3 DoF spherical electromagnet simultaneously exerts dynamic and precise radial and tangential forces in a volumetric space around the device. Since our system is fully integrated, contains no moving parts and requires no external tracking, it is easy and affordable to fabricate. We describe Omni's hardware implementation, our 3D reconstruction algorithm, and evaluate the tracking and actuation performance in depth. Finally, we demonstrate its capabilities via a set of interactive usage scenarios.
SP  - 594
EP  - 606
JF  - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3379337.3415589
ER  - 

TY  - NA
AU  - Meuleman, Andreas; Jang, Hyeonjoong; Jeon, Daniel S.; Kim, Min H.
TI  - CVPR - Real-Time Sphere Sweeping Stereo from Multiview Fisheye Images
PY  - 2021
AB  - A set of cameras with fisheye lenses have been used to capture a wide field of view. The traditional scan-line stereo algorithms based on epipolar geometry are directly inapplicable to this non-pinhole camera setup due to optical characteristics of fisheye lenses; hence, existing complete 360° RGB-D imaging systems have rarely achieved realtime performance yet. In this paper, we introduce an efficient sphere-sweeping stereo that can run directly on multiview fisheye images without requiring additional spherical rectification. Our main contributions are: First, we introduce an adaptive spherical matching method that accounts for each input fisheye camera’s resolving power concerning spherical distortion. Second, we propose a fast inter-scale bilateral cost volume filtering method that refines distance in noisy and textureless regions with optimal complexity of O(n). It enables real-time dense distance estimation while preserving edges. Lastly, the fisheye color and distance images are seamlessly combined into a complete 360° RGB-D image via fast inpainting of the dense distance map. We demonstrate an embedded 360° RGB-D imaging prototype composed of a mobile GPU and four fisheye cameras. Our prototype is capable of capturing complete 360° RGB-D videos with a resolution of two megapixels at 29 fps. Results demonstrate that our real-time method outperforms traditional omnidirectional stereo and learning-based omnidirectional stereo in terms of accuracy and performance.
SP  - 11423
EP  - 11432
JF  - 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/cvpr46437.2021.01126
ER  - 

TY  - NA
AU  - Yan, Litao; Kim, Miryung; Hartmann, Bjoern; Zhang, Tianyi; Glassman, Elena L.
TI  - Concept-Annotated Examples for Library Comparison
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545647
ER  - 

TY  - CHAP
AU  - Burns, Andrea; Arsan, Deniz; Agrawal, Sanjna; Kumar, Ranjitha; Saenko, Kate; Plummer, Bryan A.
TI  - A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility
PY  - 2022
AB  - NA
SP  - 312
EP  - 328
JF  - Lecture Notes in Computer Science
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-20074-8_18
ER  - 

TY  - NA
AU  - Abler, Aline; Zarate, Juan Jose; Langerak, Thomas; Vechev, Velko; Hilliges, Otmar
TI  - WHC - Hedgehog: Handheld Spherical Pin Array based on a Central Electromagnetic Actuator
PY  - 2021
AB  - We present Hedgehog, a single-actuator spherical pin-array device that produces cutaneous haptic sensations to the user’s palms. Hedgehog can enrich digital experiences by providing dynamic haptic patterns over a spherical surface using a simple, hand-held device. The key to our design is that it uses a single central actuator, a spherical omnidirectional electromagnet, to control the extension of all the 86 movable pins. This keeps our design simple to fabricate and scalable. A core challenge with this type of design is that the pins in the array, made out of permanent magnets, need to have a stable position when retracted. We present a method to compute such an arrays’ spatial stability, evaluate our hardware implementation in terms of its output force and pin’s extension and compare it against our method’s predictions. We also report our findings from three user studies investigating the perceived force and speed of traveling patterns. Finally, we present insights on the possible applications of Hedgehog.
SP  - 133
EP  - 138
JF  - 2021 IEEE World Haptics Conference (WHC)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/whc49131.2021.9517197
ER  - 

TY  - NA
AU  - Zhang, Yongzhao; Chen, Yi-Chao; Wang, Haonan; Jin, Xingyu
TI  - UbiComp/ISWC Adjunct - CELIP: Ultrasonic-based Lip Reading with Channel Estimation Approach for Virtual Reality Systems
PY  - 2021
AB  - We developed an ultrasonic-based silent speech interface for Virtual Reality (VR). As more and more customized devices are proposed to enhance the immersion and experience of VR, our system can be used to improve the capability of interactions between users and the systems, while retaining the possibilities of using various customized devices and avoiding some limitations of traditional speech recognition. By employing the channel estimation techniques with ultrasonic waves, we can derive movement characteristics of users’ lips, which can be used to fine-tune existing speech recognition models and augmented by vast open-sourced speech datasets. Moreover, we use the speech interface to guide the initialization of customized models for new users, so that they can easily have the access to our system. A two-stage experiment has been conducted and the results show that our system can achieve 90.8% command-level accuracy and 1.3% word-error-rate in sentence-level accuracy.
SP  - 580
EP  - 585
JF  - Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3460418.3480163
ER  - 

TY  - NA
AU  - Zenner, André; Heqitz, Kora Persephone; Krüger, Antonio
TI  - VR - Blink-Suppressed Hand Redirection
PY  - 2021
AB  - Many interaction techniques in virtual reality break with the 1-to-1 mapping from real to virtual space. Instead, specialized techniques for 3D interaction and haptic retargeting leverage hand redirection, offsetting the virtual hand rendering from the real hand position. To achieve unnoticeable hand redirection, however, the utilization of change blindness phenomena has not been systematically explored. Inspired by recent advances in the domain of redirected walking, we present the first hand redirection technique that makes use of blink-induced visual suppression and corresponding change blindness. We introduce Blink-Suppressed Hand Redirection (BSHR) to study the feasibility and detectability of hand redirection based on blink suppression. Our technique is based on Cheng et al.'s (2017) [9] body warping algorithm and instantaneously shifts the virtual hand when the user's vision is suppressed during a blink. Additionally, it can be configured to continuously increment hand offsets when the user's eyes are opened, limited to an extent below detection thresholds. In a psychophysical experiment, we verify that unnoticeable blink-suppressed hand redirection is possible even in worst -case scenarios, and derive the corresponding conservative detection thresholds (CDTs). Moreover, our results show that the range of unnoticeable redirection can be increased by combining continuous warping and blink-suppressed instantaneous shifts. As an additional contribution, we derive the CDTs for Cheng et al.'s (2017) [9] redirection technique that does not leverage blinks.
SP  - 75
EP  - 84
JF  - 2021 IEEE Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr50410.2021.00028
ER  - 

TY  - NA
AU  - Wang, Bryan; Li, Gang; Zhou, Xin; Chen, Zhourong; Grossman, Tovi; Li, Yang
TI  - UIST - Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning
PY  - 2021
AB  - Mobile User Interface Summarization generates succinct language descriptions of mobile screens for conveying important contents and functionalities of the screen, which can be useful for many language-based application scenarios. We present Screen2Words, a novel screen summarization approach that automatically encapsulates essential information of a UI screen into a coherent language phrase. Summarizing mobile screens requires a holistic understanding of the multi-modal data of mobile UIs, including text, image, structures as well as UI semantics, motivating our multi-modal learning approach. We collected and analyzed a large-scale screen summarization dataset annotated by human workers. Our dataset contains more than 112k language summarization across ∼ 22k unique UI screens. We then experimented with a set of deep models with different configurations. Our evaluation of these models with both automatic accuracy metrics and human rating shows that our approach can generate high-quality summaries for mobile screens. We demonstrate potential use cases of Screen2Words and open-source our dataset and model to lay the foundations for further bridging language and user interfaces.
SP  - 498
EP  - 510
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474765
ER  - 

TY  - NA
AU  - Wang, Tianyi; Qian, Xun; He, Fengming; Ramani, Karthik
TI  - CHI Extended Abstracts - LightPaintAR: Assist Light Painting Photography with Augmented Reality
PY  - 2021
AB  - Light painting photos are created by moving light sources in mid-air while taking a long exposure photo. However, it is challenging for novice users to leave accurate light traces without any spatial guidance. Therefore, we present LightPaintAR, a novel interface that leverages augmented reality (AR) traces as a spatial reference to enable precise movement of the light sources. LightPaintAR allows users to draft, edit, and adjust virtual light traces in AR, and move light sources along the AR traces to generate accurate light traces on photos. With LightPaintAR, users can light paint complex patterns with multiple strokes and colors. We evaluate the effectiveness and the usability of our system with a user study and showcase multiple light paintings created by the users. Further, we discuss future improvements of LightPaintAR.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451672
ER  - 

TY  - NA
AU  - Reed, Courtney N.; Skach, Sophie; Strohmeier, Paul; McPherson, Andrew P.
TI  - Singing Knit: Soft Knit Biosensing for Augmenting Vocal Performances
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Augmented Humans 2022
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3519391.3519412
ER  - 

TY  - CHAP
AU  - Huang, Yu-Hsiung; Chen, Wei-Chun; Hsu, Su-Chu
TI  - HCI (5) - Creative Design of Gaussian Sensor System with Encoding and Decoding
PY  - 2021
AB  - Stuart Hall proposed the “encoding/decoding model of communication” for the theoretical method of media information production and dissemination in 1973. In 1980, he further proposed the research of classic contemporary culture titled “Encoding/Decoding”, which explained how media producers can “encode” an object, feeling, and ideas. Message in the media to achieve the purpose of disseminating information. In addition, “decoding” is the process and method of how the media message can be perceived by the “receiver” after being transformed and translated. It has been explained that the concept of encoding and decoding has a great influence on the research of different cultural media communication from the analogy to the digital age through many kinds of research. However, with the rapid development of digital media technology, we are faced with the production methods of information in tangible and intangible media, and most of them are translated in virtual form in programming languages or digital symbols. Encoding and decoding of digital symbols and codes has gradually changed the way we understand perception.
SP  - 385
EP  - 395
JF  - Lecture Notes in Computer Science
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-78361-7_29
ER  - 

TY  - NA
AU  - Cheymol, Antonin; Fribourg, Rebecca; Ogawa, Nami; Lecuyer, Anatole; Hirao, Yutaro; Narumi, Takuji; Argelaguet, Ferran; Normand, Jean-Marie
TI  - Studying the Role of Self and External Touch in the Appropriation of Dysmorphic Hands
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar55827.2022.00024
ER  - 

TY  - NA
AU  - Krings, Kevin; Weber, Philip; Jasche, Florian; Ludwig, Thomas
TI  - FADER: An Authoring Tool for Creating Augmented Reality-Based Avatars from an End-User Perspective
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Mensch und Computer 2022
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3543758.3543778
ER  - 

TY  - NA
AU  - Im, Jane; Dimond, Jill; Berton, Melody; Lee, Una; Mustelier, Katherine; Ackerman, Mark S.; Gilbert, Eric
TI  - CHI - Yes: Affirmative Consent as a Theoretical Framework for Understanding and Imagining Social Platforms
PY  - 2021
AB  - Affirmative consent is the idea that someone must ask for, and earn, enthusiastic approval before interacting with someone else. For decades, feminist activists and scholars have used affirmative consent to theorize and prevent sexual assault. In this paper, we ask: Can affirmative consent help to theorize online interaction? Drawing from feminist, legal, and HCI literature, we introduce the feminist theory of affirmative consent and use it to analyze social computing systems. We present affirmative consent’s five core concepts: it is voluntary, informed, revertible, specific, and unburdensome. Using these principles, this paper argues that affirmative consent is both an explanatory and generative theoretical framework. First, affirmative consent is a theoretical abstraction for explaining various problematic phenomena in social platforms—including mass online harassment, revenge porn, and problems with content feeds. Finally, we argue that affirmative consent is a generative theoretical foundation from which to imagine new design ideas for consentful socio-technical systems.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445778
ER  - 

TY  - JOUR
AU  - Kapoor, Sayash; Sun, Matthew; Wang, Mona; Jazwinska, Klaudia; Watkins, Elizabeth Anne
TI  - Weaving Privacy and Power
PY  - 2022
AB  - <jats:p>We investigate the privacy practices of labor organizers in the computing technology industry and explore the changes in these practices as a response to remote work. Our study is situated at the intersection of two pivotal shifts in workplace dynamics: (a) the increase in online workplace communications due to remote work, and (b) the resurgence of the labor movement and an increase in collective action in workplaces-especially in the tech industry, where this phenomenon has been dubbed the tech worker movement. The shift of work-related communications to online digital platforms in response to an increase in remote work is creating new opportunities for and risks to the privacy of workers. These risks are especially significant for organizers of collective action, with several well-publicized instances of retaliation against labor organizers by companies. Through a series of qualitative interviews with 29 tech workers involved in collective action, we investigate how labor organizers assess and mitigate risks to privacy while engaging in these actions. Among the most common risks that organizers experienced are retaliation from their employer, lateral worker conflict, emotional burnout, and the possibility of information about the collective effort leaking to management. Depending on the nature and source of the risk, organizers use a blend of digital security practices and community-based mechanisms. We find that digital security practices are more relevant when the threat comes from management, while community management and moderation are central to protecting organizers from lateral worker conflict. Since labor organizing is a collective rather than individual project, individual privacy and collective privacy are intertwined, sometimes in conflict and often mutually constitutive. Notions of privacy that solely center individuals are often incompatible with the needs of organizers, who noted that safety in numbers could only be achieved when workers presented a united front to management. Based on our interviews, we identify key topics for future research, such as the growing prevalence of surveillance software and the needs of international and gig worker organizers.We conclude with design recommendations that can help create safer, more secure and more private tools to better address the risks that organizers face.</jats:p>
SP  - 1
EP  - 33
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - CSCW2
PB  - 
DO  - 10.1145/3555574
ER  - 

TY  - NA
AU  - Senft, Emmanuel; Hagenow, Michael; Radwin, Robert G.; Zinn, Michael R.; Gleicher, Michael; Mutlu, Bilge
TI  - Situated Live Programming for Human-Robot Collaboration
PY  - 2021
AB  - We present situated live programming for human-robot collaboration, an approach that enables users with limited programming experience to program collaborative applications for human-robot interaction. Allowing end users, such as shop floor workers, to program collaborative robots themselves would make it easy to "retask" robots from one process to another, facilitating their adoption by small and medium enterprises. Our approach builds on the paradigm of trigger-action programming (TAP) by allowing end users to create rich interactions through simple trigger-action pairings. It enables end users to iteratively create, edit, and refine a reactive robot program while executing partial programs. This live programming approach enables the user to utilize the task space and objects by incrementally specifying situated trigger-action pairs, substantially lowering the barrier to entry for programming or reprogramming robots for collaboration. We instantiate situated live programming in an authoring system where users can create trigger-action programs by annotating an augmented video feed from the robot's perspective and assign robot actions to trigger conditions. We evaluated this system in a study where participants (n = 10) developed robot programs for solving collaborative light-manufacturing tasks. Results showed that users with little programming experience were able to program HRC tasks in an interactive fashion and our situated live programming approach further supported individualized strategies and workflows. We conclude by discussing opportunities and limitations of the proposed approach, our system implementation, and our study and discuss a roadmap for expanding this approach to a broader range of tasks and applications.
SP  - 613
EP  - 625
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474773
ER  - 

TY  - NA
AU  - Zhu, Zhengzhe; Liu, Ziyi; Wang, Tianyi; Zhang, Youyou; Qian, Xun; Raja, Pashin Farsak; Villanueva, Ana; Ramani, Karthik
TI  - MechARspace: An Authoring System Enabling Bidirectional Binding of Augmented Reality with Toys in Real-time
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545668
ER  - 

TY  - NA
AU  - Görtler, Jochen; Hohman, Fred; Moritz, Dominik; Wongsuphasawat, Kanit; Ren, Donghao; Nair, Rahul; Kirchner, Marc; Patel, Kayur
TI  - Neo: Generalizing Confusion Matrix Visualization to Hierarchical and Multi-Output Labels
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501823
ER  - 

TY  - NA
AU  - Cascaval, Dan; Shalah, Mira; Quinn, Phillip; Bodik, Rastislav; Agrawala, Maneesh; Schulz, Adriana
TI  - Differentiable 3D CAD Programs for Bidirectional Editing
PY  - 2021
AB  - Modern CAD tools represent 3D designs not only as geometry, but also as a program composed of geometric operations, each of which depends on a set of parameters. Program representations enable meaningful and controlled shape variations via parameter changes. However, achieving desired modifications solely through parameter editing is challenging when CAD models have not been explicitly authored to expose select degrees of freedom in advance. We introduce a novel bidirectional editing system for 3D CAD programs. In addition to editing the CAD program, users can directly manipulate 3D geometry and our system infers parameter updates to keep both representations in sync. We formulate inverse edits as a set of constrained optimization objectives, returning plausible updates to program parameters that both match user intent and maintain program validity. Our approach implements an automatically differentiable domain-specific language for CAD programs, providing derivatives for this optimization to be performed quickly on any expressed program. Our system enables rapid, interactive exploration of a constrained 3D design space by allowing users to manipulate the program and geometry interchangeably during design iteration. While our approach is not designed to optimize across changes in geometric topology, we show it is expressive and performant enough for users to produce a diverse set of design variants, even when the CAD program contains a large number of parameters.
SP  - NA
EP  - NA
JF  - arXiv: Graphics
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Yang, Xiaoying; Zhang, Yang
TI  - CHI Extended Abstracts - CubeSense: Wireless, Battery-Free Interactivity through Low-Cost Corner Reflector Mechanisms
PY  - 2021
AB  - Ubiquitous computing systems rely on ubiquitous methods to sense user interactions, which have manifested in our daily environments as physical buttons, switches, sliders, and beyond. These conventional controllers are either wired, which eliminates flexible deployments, or powered by batteries that require user maintenance. Additionally, built-in wireless communications such as Wi-Fi, Bluetooth, and RFID add up to the total cost. All aforementioned constraints prevent truly ubiquitous interactions from intelligent environments such as smart homes, industry 4.0, precision farming, and a wider range of Internet-of-Things (IoT) applications. We present CubeSense, a wireless and battery-free interactive sensing system which encodes user interactions into radar cross section (RCS) of corner reflectors. Through careful designs of corner reflector mechanisms, CubeSense achieves robust accuracies with controllers made of ultra-low-cost plastics and metal films, resulting in a total cost of around only 20 cents per unit.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451599
ER  - 

TY  - NA
AU  - Cao, Jacky; Lam, Kit-Yung; Lee, Lik Hang; Liu, Xiaoli; Hui, Pan; Su, Xiang
TI  - Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligence.
PY  - 2021
AB  - Mobile Augmented Reality (MAR) integrates computer-generated virtual objects with physical environments for mobile devices. MAR systems enable users to interact with MAR devices, such as smartphones and head-worn wearables, and performs seamless transitions from the physical world to a mixed world with digital entities. These MAR systems support user experiences by using MAR devices to provide universal accessibility to digital contents. Over the past 20 years, a number of MAR systems have been developed, however, the studies and design of MAR frameworks have not yet been systematically reviewed from the perspective of user-centric design. This article presents the first effort of surveying existing MAR frameworks (count: 37) and further discusses the latest studies on MAR through a top-down approach: 1) MAR applications; 2) MAR visualisation techniques adaptive to user mobility and contexts; 3) systematic evaluation of MAR frameworks including supported platforms and corresponding features such as tracking, feature extraction plus sensing capabilities; and 4) underlying machine learning approaches supporting intelligent operations within MAR systems. Finally, we summarise the development of emerging research fields, current state-of-the-art, and discuss the important open challenges and possible theoretical and technical directions. This survey aims to benefit both researchers and MAR system developers alike.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Kuznetsov, Andrew; Chang, Joseph Chee; Hahn, Nathan; Rachatasumrit, Napol; Breneisen, Bradley; Coupland, Julina; Kittur, Aniket
TI  - Fuse: In-Situ Sensemaking Support in the Browser
PY  - 2022
AB  - People spend a significant amount of time trying to make sense of the internet, collecting content from a variety of sources and organizing it to make decisions and achieve their goals. While humans are able to fluidly iterate on collecting and organizing information in their minds, existing tools and approaches introduce significant friction into the process. We introduce Fuse, a browser extension that externalizes users' working memory by combining low-cost collection with lightweight organization of content in a compact card-based sidebar that is always available. Fuse helps users simultaneously extract key web content and structure it in a lightweight and visual way. We discuss how these affordances help users externalize more of their mental model into the system (e.g., saving, annotating, and structuring items) and support fast reviewing and resumption of task contexts. Our 22-month public deployment and follow-up interviews provide longitudinal insights into the structuring behaviors of real-world users conducting information foraging tasks.
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545693
ER  - 

TY  - NA
AU  - Yu, Difeng; Jiang, Weiwei; Irlitti, Andrew; Dingler, Tilman; Velloso, Eduardo; Goncalves, Jorge; Kostakos, Vassilis
TI  - Haptics in VR Using Origami-Augmented Drones
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar-adjunct57072.2022.00198
ER  - 

TY  - NA
AU  - Isotani, Haruna; Washizaki, Hironori; Fukazawa, Yoshiaki; Nomoto, Tsutomu; Ouji, Saori; Saito, Shinobu
TI  - ICSME - Duplicate Bug Report Detection by Using Sentence Embedding and Fine-tuning.
PY  - 2021
AB  - NA
SP  - 535
EP  - 544
JF  - 2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/icsme52107.2021.00054
ER  - 

TY  - NA
AU  - Aminolroaya, Zahra; Willett, Wesley; Wiebe, Samuel; Josephson, Colin B.; Maurer, Frank
TI  - Watch The Videos Whenever You Have Time
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 2022 International Conference on Advanced Visual Interfaces
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3531073.3531181
ER  - 

TY  - NA
AU  - Han, Han L.
TI  - UIST (Adjunct Volume) - Designing Representations for Digital Documents
PY  - 2020
AB  - Hundreds of millions of users work with digital documents for their everyday tasks but the user interfaces have not fundamentally changed since they were first designed in the late seventies [10]. We focus on two examples of today's 'extreme users' of documents, legal professionals and scientists. Based on their work practices, we designed two document-centered tools: Textlets supports constraints and consistency within documents; FileWeaver automatically tracks dependencies across documents. I then describe two research directions that emerged from our empirical studies and recent literature: collaboration in documents, e.g. Jupyter notebook and direct manipulation for computational documents such as LaTeX. This dissertation will enhance our understanding of how today's users work with documents; demonstrate novel tools and expand the fundamental theory of interaction.
SP  - 174
EP  - 178
JF  - Adjunct Publication of the 33rd Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3379350.3415805
ER  - 

TY  - NA
AU  - Kaufmann, Manuel; Zhao, Yi; Tang, Chengcheng; Tao, Lingling; Twigg, Christopher; Song, Jie; Wang, Robert; Hilliges, Otmar
TI  - EM-POSE: 3D Human Pose Estimation from Sparse Electromagnetic Trackers
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - 2021 IEEE/CVF International Conference on Computer Vision (ICCV)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/iccv48922.2021.01131
ER  - 

TY  - NA
AU  - Zhou, Zhanhui; Tang, Man To; Pan, Qiping; Tan, Shangyin; Wang, Xinyu; Zhang, Tianyi
TI  - INTENT: Interactive Tensor Transformation Synthesis
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545653
ER  - 

TY  - JOUR
AU  - Usuba, Hiroki; Yamanaka, Shota; Miyashita, Homei
TI  - Modeling Movement Times and Success Rates for Acquisition of One-dimensional Targets with Uncertain Touchable Sizes
PY  - 2021
AB  - In touch interfaces, a target, such as an icon, has two widths: the visual width and the touchable width. The visual width is the target's appearance, and the touchable width is the area in which users can touch a target and execute an action. In this study, we conduct two experiments to investigate the effects of the visual and touchable widths on touch pointing performance (movement time and success rate). Based on the results, we build candidate models for predicting the movement time and compare them by the values of adjusted R^2 and AIC. In addition, we build a success rate model and test it through cross-validation. Existing models can be applied only to situations where the visual and touchable widths are equal, and we show that our refined model achieves better model fitness, even when such widths are different. We also discuss the design implications of the touch interfaces based on our models.
SP  - 1
EP  - 15
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 5
IS  - ISS
PB  - 
DO  - 10.1145/3486953
ER  - 

TY  - NA
AU  - O'Hagan, Joseph; Williamson, Julie R.; McGill, Mark; Khamis, Mohamed
TI  - ISMAR - Safety, Power Imbalances, Ethics and Proxy Sex: Surveying In-The-Wild Interactions Between VR Users and Bystanders
PY  - 2021
AB  - VR users and bystanders must sometimes interact, but our understanding of these interactions - their purpose, how they are accomplished, attitudes toward them, and where they break down - is limited. This current gap inhibits research into managing or supporting these interactions, and preventing unwanted or abusive activity. We present the results of the first survey (N=100) that investigates stories of actual emergent in-the-wild interactions between VR users and bystanders. Our analysis indicates VR user and bystander interactions can be categorised into one of three categories: coexisting, demoing, and interrupting. We highlight common interaction patterns and impediments encountered during these interactions. Bystanders play an important role in moderating the VR user’s experience, for example intervening to save the VR user from potential harm. However, our stories also suggest that the occlusive nature of VR introduces the potential for bystanders to exploit the vulnerable state of the VR user; and for the VR user to exploit the bystander for enhanced immersion, introducing significant ethical concerns.
SP  - 211
EP  - 220
JF  - 2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar52148.2021.00036
ER  - 

TY  - NA
AU  - Leiva, Germán; Grønbæk, Jens Emil; Klokmose, Clemens Nylandsted; Nguyen, Cuong; Kazi, Rubaiat Habib; Asente, Paul
TI  - UIST - Rapido: Prototyping Interactive AR Experiences through Programming by Demonstration
PY  - 2021
AB  - Programming by Demonstration (PbD) is a well-known technique that allows non-programmers to describe interactivity by performing examples of the expected behavior, but it has not been extensively explored for AR. We present Rapido, a novel early-stage prototyping tool to create fully interactive mobile AR prototypes from non-interactive video prototypes using PbD. In Rapido, designers use a mobile AR device to record a video prototype to capture context, sketch assets, and demonstrate interactions. They can demonstrate touch inputs, animation paths, and rules to, e.g., have a sketch follow the focus area of the device or the user’s world-space touches. Simultaneously, a live website visualizes an editable overview of all the demonstrated examples and infers a state machine of the user flow. Our key contribution is a method that enables designers to turn a video prototype into an executable state machine through PbD. The designer switches between these representations to interactively refine the final interactive prototype. We illustrate the power of Rapido’s approach by prototyping the main interactions of three popular AR mobile applications.
SP  - 626
EP  - 637
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474774
ER  - 

TY  - NA
AU  - Wang, April Yi; Epperson, Will; DeLine, Robert A; Drucker, Steven M.
TI  - Diff in the Loop: Supporting Data Comparison in Exploratory Data Analysis
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502123
ER  - 

TY  - NA
AU  - Davis, Keith M.; Spapé, Michiel M.; Ruotsalo, Tuukka
TI  - WWW - Collaborative Filtering with Preferences Inferred from Brain Signals
PY  - 2021
AB  - Collaborative filtering is a common technique in which interaction data from a large number of users are used to recommend items to an individual that the individual may prefer but has not interacted with. Previous approaches have achieved this using a variety of behavioral signals, from dwell time and clickthrough rates to self-reported ratings. However, such signals are mere estimations of the real underlying preferences of the users. Here, we use brain-computer interfacing to infer preferences directly from the human brain. We then utilize these preferences in a collaborative filtering setting and report results from an experiment where brain inferred preferences are used in a neural collaborative filtering framework. Our results demonstrate, for the first time, that brain-computer interfacing can provide a viable alternative for behavioral and self-reported preferences in realistic recommendation scenarios. We also discuss the broader implications of our findings for personalization systems and user privacy.
SP  - 602
EP  - 611
JF  - Proceedings of the Web Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3442381.3450031
ER  - 

TY  - JOUR
AU  - Goel, Purvi; James, Doug L.
TI  - Unified many-worlds browsing of arbitrary physics-based animations
PY  - 2022
AB  - <jats:p>Manually tuning physics-based animation parameters to explore a simulation outcome space or achieve desired motion outcomes can be notoriously tedious. This problem has motivated many sophisticated and specialized optimization-based methods for fine-grained (keyframe) control, each of which are typically limited to specific animation phenomena, usually complicated, and, unfortunately, not widely used.</jats:p> <jats:p> In this paper, we propose <jats:italic>Unified Many-Worlds Browsing</jats:italic> (UMWB), a practical method for sample-level control and exploration of physics-based animations. Our approach supports browsing of large simulation ensembles of arbitrary animation phenomena by using a unified volumetric WORLDPACK representation based on spatiotemporally compressed voxel data associated with geometric occupancy and other low-fidelity animation state. Beyond memory reduction, the WORLDPACK representation also enables unified query support for interactive browsing: it provides fast evaluation of approximate spatiotemporal queries, such as occupancy tests that find ensemble samples ("worlds") where material is either IN or NOT IN a user-specified spacetime region. WORLDPACKS also support real-time hardware-accelerated voxel rendering by exploiting the spatially hierarchical and temporal RLE raster data structure. Our UMWB implementation supports interactive browsing (and offline refinement) of ensembles containing thousands of simulation samples, and fast spatiotemporal queries and ranking. We show UMWB results using a wide variety of physics-based animation phenomena---not just JELL-O <jats:sup>®</jats:sup> . </jats:p>
SP  - 1
EP  - 15
JF  - ACM Transactions on Graphics
VL  - 41
IS  - 4
PB  - 
DO  - 10.1145/3528223.3530082
ER  - 

TY  - JOUR
AU  - Wirth, M.; Shea, K.; Chen, T.
TI  - 3D-printing textiles: multi-stage mechanical characterization of additively manufactured biaxial weaves
PY  - 2023
AB  - NA
SP  - 111449
EP  - NA
JF  - Materials & Design
VL  - 225
IS  - NA
PB  - 
DO  - 10.1016/j.matdes.2022.111449
ER  - 

TY  - BOOK
AU  - Jetter, Hans-Christian; Schröder, Jan-Henrik; Gugenheimer, Jan; Billinghurst, Mark; Anthes, Christoph; Khamis, Mohamed; Feuchtner, Tiare
TI  - ISS Companion - Transitional Interfaces in Mixed and Cross-Reality: A new frontier?
PY  - 2021
AB  - Transitional interfaces (TIs) and related concepts such as cross-reality (XR) or cross-virtuality (XV) are key topics for future HCI and AR/VR research. Future TIs will enable users to freely move between different locations within the reality-virtuality continuum during work, to choose the best technologies for their task at hand and current information need. Our workshop will explore the core advantages and challenges of TIs and related concepts and address them in presentations and workshop activities at ACM ISS 2021.
SP  - 46
EP  - 49
JF  - Interactive Surfaces and Spaces
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3447932.3487940
ER  - 

TY  - NA
AU  - Yang, Tian; Yao, Powen; Zyda, Mike
TI  - Flick Typing: Toward A New XR Text Input System Based on 3D Gestures and Machine Learning
PY  - 2022
AB  - We propose a new text entry input method in Extended Reality that we call Flick Typing. Flick Typing utilizes the user&#x0027;s knowledge of a QWERTY keyboard layout, but does not explicitly provide visualization of the keys, and is agnostic to user posture or keyboard position. To type with Flick Typing, users will move their controller to where they think the target key is with respect to the controller&#x0027;s starting position and orientation, often with a simple flick of their wrists. Machine learning model is trained and used to adapt to the user&#x0027;s mental map of the keys in 3D space.
SP  - NA
EP  - NA
JF  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vrw55335.2022.00295
ER  - 

TY  - NA
AU  - Weld, Galen; Zhang, Amy X.; Althoff, Tim
TI  - Making Online Communities 'Better': A Taxonomy of Community Values on Reddit.
PY  - 2021
AB  - Many researchers studying online social communities seek to make such communities better. However, understanding what 'better' means is challenging, due to the divergent opinions of community members, and the multitude of possible community values which often conflict with one another. Community members' own values for their communities are not well understood, and how these values align with one another is an open question. Previous research has mostly focused on specific and comparatively well-defined harms within online communities, such as harassment, rule-breaking, and misinformation. In this work, we ask 39 community members on reddit to describe their values for their communities. We gather 301 responses in members' own words, spanning 125 unique communities, and use iterative categorization to produce a taxonomy of 29 different community values across 9 major categories. We find that members value a broad range of topics ranging from technical features to the diversity of the community, and most frequently prioritize content quality. We identify important understudied topics such as content quality and community size, highlight where values conflict with one another, and call for research into governance methods for communities that protect vulnerable members.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Huang, Forrest; Li, Gang; Zhou, Xin; Canny, John; Li, Yang
TI  - Creating User Interface Mock-ups from High-Level Text Descriptions with Deep-Learning Models.
PY  - 2021
AB  - The design process of user interfaces (UIs) often begins with articulating high-level design goals. Translating these high-level design goals into concrete design mock-ups, however, requires extensive effort and UI design expertise. To facilitate this process for app designers and developers, we introduce three deep-learning techniques to create low-fidelity UI mock-ups from a natural language phrase that describes the high-level design goal (e.g. "pop up displaying an image and other options"). In particular, we contribute two retrieval-based methods and one generative method, as well as pre-processing and post-processing techniques to ensure the quality of the created UI mock-ups. We quantitatively and qualitatively compare and contrast each method's ability in suggesting coherent, diverse and relevant UI design mock-ups. We further evaluate these methods with 15 professional UI designers and practitioners to understand each method's advantages and disadvantages. The designers responded positively to the potential of these methods for assisting the design process.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Armstrong, Mark; Quest, Lawrence; Pai, Yun Suen; Kunze, Kai; Minamizawa, Kouta
TI  - BridgedReality: A Toolkit Connecting Physical and Virtual Spaces through Live Holographic Point Cloud Interaction
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - SIGGRAPH Asia 2021 Posters
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3476124.3488656
ER  - 

TY  - NA
AU  - Gordon, Mitchell L.; Lam, Michelle S.; Park, Joon Sung; Patel, Kayur; Hancock, Jeff; Hashimoto, Tatsunori; Bernstein, Michael S.
TI  - Jury Learning: Integrating Dissenting Voices into Machine Learning Models
PY  - 2022
AB  - Whose labels should a machine learning (ML) algorithm learn to emulate? For ML tasks ranging from online comment toxicity to misinformation detection to medical diagnosis, different groups in society may have irreconcilable disagreements about ground truth labels. Supervised ML today resolves these label disagreements implicitly using majority vote, which overrides minority groups' labels. We introduce jury learning, a supervised ML approach that resolves these disagreements explicitly through the metaphor of a jury: defining which people or groups, in what proportion, determine the classifier's prediction. For example, a jury learning model for online toxicity might centrally feature women and Black jurors, who are commonly targets of online harassment. To enable jury learning, we contribute a deep learning architecture that models every annotator in a dataset, samples from annotators' models to populate the jury, then runs inference to classify. Our architecture enables juries that dynamically adapt their composition, explore counterfactuals, and visualize dissent.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502004
ER  - 

TY  - JOUR
AU  - Moghaddam, Mohsen Ebrahimi; Wilson, Nicholas; Modestino, Alicia Sasser; Jona, Kemi; Marsella, Stacy
TI  - Exploring augmented reality for worker assistance versus training
PY  - 2021
AB  - NA
SP  - 101410
EP  - NA
JF  - Advanced Engineering Informatics
VL  - 50
IS  - NA
PB  - 
DO  - 10.1016/j.aei.2021.101410
ER  - 

TY  - NA
AU  - Ma, Hua; Yamaoka, Junichi
TI  - Smart Textile Using 3D Printed Conductive Sequins
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490149.3505577
ER  - 

TY  - NA
AU  - Ma, Hua; Yamaoka, Junichi
TI  - SenSequins: Smart Textile Using 3D Printed Conductive Sequins
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545688
ER  - 

TY  - JOUR
AU  - Li, Zhipeng; Jiang, Yu; Zhu, Yihao; Chen, Ruijia; Wang, Ruolin; Wang, Yuntao; Yan, Yukang; Shi, Yuanchun
TI  - Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention
PY  - 2022
AB  - <jats:p>An avatar mirroring the user's movement is commonly adopted in Virtual Reality(VR). Maintaining the user-avatar movement consistency provides the user a sense of body ownership and thus an immersive experience. However, breaking this consistency can enable new interaction functionalities, such as pseudo haptic feedback [45] or input augmentation [37, 59], at the expense of immersion. We propose to quantify the probability of users noticing the movement inconsistency while the inconsistency amplitude is being enlarged, which aims to guide the intervention of the users' sense of body ownership in VR. We applied angular offsets to the avatar's shoulder and elbow joints and recorded whether the user identified the inconsistency through a series of three user studies and built a statistical model based on the results. Results show that the noticeability of movement inconsistency increases roughly quadratically with the enlargement of offsets and the offsets at two joints negatively affect the probability distributions of each other. Leveraging the model, we implemented a technique that amplifies the user's arm movements with unnoticeable offsets and then evaluated implementations with different parameters(offset strength, offset distribution). Results show that the technique with medium-level and balanced-distributed offsets achieves the best overall performance. Finally, we demonstrated our model's extendability in interventions in the sense of body ownership with three VR applications including stroke rehabilitation, action game and widget arrangement.</jats:p>
SP  - 1
EP  - 26
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 2
PB  - 
DO  - 10.1145/3534590
ER  - 

TY  - JOUR
AU  - Zhang, Li; Liu, Yizhe; Bai, Huidong; Zou, Qianyuan; Chang, Zhuang; He, Weiping; Wang, Shuxia; Billinghurst, Mark
TI  - Robot-enabled tangible virtual assembly with coordinated midair object placement
PY  - 2023
AB  - NA
SP  - 102434
EP  - 102434
JF  - Robotics and Computer-Integrated Manufacturing
VL  - 79
IS  - NA
PB  - 
DO  - 10.1016/j.rcim.2022.102434
ER  - 

TY  - NA
AU  - Englmeier, David; Sajko, Wanja; Butz, Andreas
TI  - VR - Spherical World in Miniature: Exploring the Tiny Planets Metaphor for Discrete Locomotion in Virtual Reality
PY  - 2021
AB  - We explore the concept of a Spherical World in Miniature (SWIM) for discrete locomotion in Virtual Reality (VR). A SWIM wraps a planar WIM around a physically embodied sphere and thereby implements the metaphor of a tangible Tiny Planet that can be rotated and moved, enabling scrolling, scaling, and avatar teleportation. The scaling factor is set according to the sphere's distance from the head-mounted display (HMD), while rotation moves the current viewing window. Teleportation is triggered with a dwell time when looking at the sphere and keeping it still. In a lab study (N=20), we compare our SWIM implementation to a planar WIM with an established VR controller technique using physical buttons. We test both concepts in a navigation task and also investigate the effects of two different screen sizes. Our results show that the SWIM, despite its less direct geometrical transformation, performed superior in most evaluations. It outperformed the planar WIM not only in terms of task completion time (TCT) and accuracy but also in subjective ratings.
SP  - 345
EP  - 352
JF  - 2021 IEEE Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr50410.2021.00057
ER  - 

TY  - NA
AU  - Hoshikawa, Yukai; Fujita, Kazuyuki; Takashima, Kazuki; Fjeld, Morten; Kitamura, Yoshifumi
TI  - Demonstration of RedirectedDoors: Manipulating User's Orientation while Opening Doors in Virtual Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - SIGGRAPH Asia 2022 XR
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3550472.3558405
ER  - 

TY  - NA
AU  - Wenqiang, Chen; Bevan, Daniel; Stankovic, John A.
TI  - UIST (Adjunct Volume) - ViObject: A Smartwatch-based Object Recognition System via Vibrations
PY  - 2021
AB  - Today, in order to start an interaction with most digital technology, we must perform some sort of action to indicate our intention, such as shaking a computer’s mouse to wake it or pressing a coffee maker’s start button for your morning cup of coffee. Our system aims to help remove these currently necessary ”trigger actions” and aims to support an array of applications to create borderless and fluid interactions between the technological world and our own. Our system as has the potential for application within the world of accessible technology as well. The system we propose is a method of identifying held objects via a smartwatch’s accelerometer and gyroscope sensors. A preview demo video is available at https://youtu.be/1YCTzvjcJ18.
SP  - 97
EP  - 99
JF  - The Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3474349.3480182
ER  - 

TY  - NA
AU  - Qian, Jing; Sun, Qi; Wigington, Curtis; Han, Han L.; Sun, Tong; Healey, Jennifer; Tompkin, James; Huang, Jeff
TI  - Dually Noted: Layout-Aware Annotations with Smartphone Augmented Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502026
ER  - 

TY  - NA
AU  - van Binsbergen, L. Thomas; Frölich, Damian; Verano Merino, Mauricio; Lai, Joey; Jeanjean, Pierre; van der Storm, Tijs; Combemale, Benoit; Barais, Olivier
TI  - A Language-Parametric Approach to Exploratory Programming Environments
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 15th ACM SIGPLAN International Conference on Software Language Engineering
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3567512.3567527
ER  - 

TY  - JOUR
AU  - Yassien, Amal; Soliman, Mohamed Ahmed; Abdennadher, Slim
TI  - QuarantivityVR: Supporting Self-Embodiment for Non-HMD Users in Asymmetric Social VR Games
PY  - 2022
AB  - <jats:title>Abstract</jats:title> <jats:p>The prevalence of immersive head-mounted display (HMD) social virtual reality (VR) applications introduced asymmetric interaction among users within the virtual environment (VE). Therefore, researchers opted for (1) exploring the asymmetric social VR interaction dynamics in only co-located setups, (2) assigning interdependent roles to both HMD and non-HMD users, and (3) representing non-HMD users as abstract avatars in the VE. Therefore, we investigate the feasibility of supporting <jats:italic>Self-Embodiment</jats:italic> in an asymmetric VR interaction mode in a remote setup. To this end, we designed an asymmetric social VR game, <jats:italic>QuarantivityVR</jats:italic>, to (1) support sense of self-embodiment for non-HMD users in a remote setting by representing them as realistic full-body avatars within the VE, (2) augment visual-motor synchrony for the non-HMD users to increase their sense of agency and presence by detecting their motion through Kinect sensor and laptop’s webcam. During the game, each player performs three activities in succession, namely movie-guessing, spelling-bee, and answering mathematical questions. We believe that our work will act as a step towards the inclusion of a wide spectrum of users that can not afford full immersion and will aid researchers in creating enjoyable interactions for both users in the physical and virtual spaces.</jats:p>
SP  - 55
EP  - 70
JF  - i-com
VL  - 21
IS  - 1
PB  - 
DO  - 10.1515/icom-2022-0005
ER  - 

TY  - JOUR
AU  - Wu, Yifan; Chang, Remco; Hellerstein, Joseph M.; Satyanarayan, Arvind; Wu, Eugene
TI  - DIEL: Interactive Visualization Beyond the Here and Now.
PY  - 2021
AB  - Interactive visualization design and research have primarily focused on local data and synchronous events. However, for more complex use cases-e.g., remote database access and streaming data sources-developers must grapple with distributed data and asynchronous events. Currently, constructing these use cases is difficult and time-consuming; developers are forced to operationally program low-level details like asynchronous database querying and reactive event handling. This approach is in stark contrast to modern methods for browser-based interactive visualization, which feature high-level declarative specifications. In response, we present DIEL, a declarative framework that supports asynchronous events over distributed data. As in many declarative languages, DIEL developers specify only what data they want, rather than procedural steps for how to assemble it. Uniquely, DIEL models asynchronous events (e.g., user interactions, server responses) as streams of data that are captured in event logs. To specify the state of a visualization at any time, developers write declarative queries over the data and event logs; DIEL compiles and optimizes a corresponding dataflow graph, and automatically generates necessary low-level distributed systems details. We demonstrate DIEL's performance and expressivity through example interactive visualizations that make diverse use of remote data and asynchronous events. We further evaluate DIEL's usability using the Cognitive Dimensions of Notations framework, revealing wins such as ease of change, and compromises such as premature commitments.
SP  - 1
EP  - 1
JF  - IEEE transactions on visualization and computer graphics
VL  - 28
IS  - 1
PB  - 
DO  - 10.1109/tvcg.2021.3114796
ER  - 

TY  - JOUR
AU  - Suto, Kai; Noma, Yuta; Tanimichi, Kotaro; Narumi, Koya; Tachi, Tomohiro
TI  - Crane: An Integrated Computational Design Platformfor Functional, Foldable, and Fabricable Origami Products
PY  - 2022
AB  - <jats:p>Despite the recent trend of computational origami for human-computer interaction (HCI) and digital fabrication, it is still difficult for designers to complete a series of design, simulation, and fabrication of objects leveraging computational origami theory. In this paper, we propose Crane, an integrated origami design platform implemented with Grasshopper. With this platform, users can seamlessly (1) design the 2D and 3D crease pattern, (2) simulate 3D folding transformation from the given crease pattern, (3) inversely find a new pattern under design constraints, (4) thicken the 2D pattern into a 3D volume along with the appropriate hinge structures for different fabrication methods, and (5) optionally connect the resulting design to other Rhinoceros or Grasshopper plugins for post-processes. To help understand how to use our system and demonstrate its feasibility, we showed three examples of origami products designed using our system. We also reported user feedback from the workshop as an evaluation.</jats:p>
SP  - NA
EP  - NA
JF  - ACM Transactions on Computer-Human Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3576856
ER  - 

TY  - JOUR
AU  - Mercado, Victor; Marchal, Maud; Lécuyer, Anatole
TI  - “Haptics On-Demand”: A Survey on Encountered-Type Haptic Displays
PY  - 2021
AB  - Encountered-Type Haptic Displays (ETHDs) provide haptic feedback by positioning a tangible surface for the user to encounter. This permits users to freely eliciting haptic feedback with a surface during a virtual simulation. ETHDs differ from most of current haptic devices which rely on an actuator always in contact with the user. This article intends to describe and analyze the different research efforts carried out in this field. In addition, this article analyzes ETHD literature concerning definitions, history, hardware, haptic perception processes involved, interactions and applications. The paper proposes a formal definition of ETHDs, a taxonomy for classifying hardware types, and an analysis of haptic feedback used in literature. Taken together the overview of this survey intends to encourage future work in the ETHD field.
SP  - 449
EP  - 464
JF  - IEEE transactions on haptics
VL  - 14
IS  - 3
PB  - 
DO  - 10.1109/toh.2021.3061150
ER  - 

TY  - NA
AU  - McDonnell, Emma
TI  - Understanding Social and Environmental Factors to Enable Collective Access Approaches to the Design of Captioning Technology
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 24th International ACM SIGACCESS Conference on Computers and Accessibility
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3517428.3550417
ER  - 

TY  - NA
AU  - Gebhardt, Christoph; Hilliges, Otmar
TI  - Optimal Control to Support High-Level User Goals in Human-Computer Interaction
PY  - 2021
AB  - With emerging technologies like robots, mixed-reality systems or mobile devices, machine-provided capabilities are increasing, so is the complexity of their control and display mechanisms. To address this dichotomy, we propose optimal control as a framework to support users in achieving their high-level goals in human-computer tasks. We reason that it will improve user support over usual approaches for adaptive interfaces as its formalism implicitly captures the iterative nature of human-computer interaction. We conduct two case studies to test this hypothesis. First, we propose a model-predictive-control-based optimization scheme that supports end-users to plan and execute robotic aerial videos. Second, we introduce a reinforcement-learning-based method to adapt mixed-reality augmentations based on users’ preferences or tasks learned from their gaze interactions with a UI. Our results show that optimal control can better support users’ high-level goals in human-computer tasks than common approaches. Optimal control models human-computer interaction as a sequential decision problem which represents its nature and, hence, results in better predictability of user behavior than for other methods. In addition, our work highlights that optimization- and learning-based optimal control have complementary strengths with respect to interface adaptation.
SP  - 33
EP  - 72
JF  - Human–Computer Interaction Series
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-82681-9_2
ER  - 

TY  - NA
AU  - Suzuki, Ryo; Karim, Adnan; Xia, Tian; Hedayati, Hooman; Marquardt, Nicolai
TI  - Augmented Reality and Robotics: A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces
PY  - 2022
AB  - This paper contributes to a taxonomy of augmented reality and robotics based on a survey of 460 research papers. Augmented and mixed reality (AR/MR) have emerged as a new way to enhance human-robot interaction (HRI) and robotic interfaces (e.g., actuated and shape-changing interfaces). Recently, an increasing number of studies in HCI, HRI, and robotics have demonstrated how AR enables better interactions between people and robots. However, often research remains focused on individual explorations and key design strategies, and research questions are rarely analyzed systematically. In this paper, we synthesize and categorize this research field in the following dimensions: 1) approaches to augmenting reality; 2) characteristics of robots; 3) purposes and benefits; 4) classification of presented information; 5) design components and strategies for visual augmentation; 6) interaction techniques and modalities; 7) application domains; and 8) evaluation strategies. We formulate key challenges and opportunities to guide and inform future research in AR and robotics.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517719
ER  - 

TY  - JOUR
AU  - Kim, Jinwook; Kim, Seonghyeon; Lee, Jeongmi
TI  - The Effect of Multisensory Pseudo-Haptic Feedback on Perception of Virtual Weight
PY  - 2022
AB  - Providing realistic haptic feedback of virtual objects is critical for immersive VR experience, and there have been many approaches to simulate haptic properties. Most of them, however, are limited to a narrow modulation range of simulated perception. To overcome this limitation, the current paper examines the effect of multisensory pseudo-haptic feedback that combines control-to-display (C/D) ratio manipulation and electrical muscle stimulation (EMS) on simulated weight perception. In two experiments, we independently manipulated the C/D ratio and EMS status and observed the effects on the absolute and difference thresholds of simulated weight perception. From the absolute thresholds results, we specify the effective range of C/D ratio that can successfully induce weight perception and show that the range can be more than twice widened by multisensory pseudo-haptic feedback. Furthermore, we demonstrate that the sensitivity to weight difference increases as the standard C/D ratio decreases from the difference thresholds results, which provides practical design guidelines for assigning multiple levels of weight to virtual objects. This study contributes to understanding the psychological effects of multisensory pseudo-haptic feedback on simulated weight perception in virtual reality.
SP  - 5129
EP  - 5140
JF  - IEEE Access
VL  - 10
IS  - NA
PB  - 
DO  - 10.1109/access.2022.3140438
ER  - 

TY  - NA
AU  - Je, Seungwoo; Lim, Hyunseung; Moon, Kongpyung; Teng, Shan-Yuan; Brooks, Jas; Lopes, Pedro; Bianchi, Andrea
TI  - CHI - Elevate: A Walkable Pin-Array for Large Shape-Changing Terrains
PY  - 2021
AB  - Current head-mounted displays enable users to explore virtual worlds by simply walking through them (i.e., real-walking VR). This led researchers to create haptic displays that can also simulate different types of elevation shapes. However, existing shape-changing floors are limited by their tabletop scale or the coarse resolution of the terrains they can display due to the limited number of actuators and low vertical resolution. To tackle this challenge, we introduce Elevate, a dynamic and walkable pin-array floor on which users can experience not only large variations in shapes but also the details of the underlying terrain. Our system achieves this by packing 1200 pins arranged on a 1.80 × 0.60m platform, in which each pin can be actuated to one of ten height levels (resolution: 15mm/level). To demonstrate its applicability, we present our haptic floor combined with four walkable applications and a user study that reported increased realism and enjoyment.
SP  - 1
EP  - 11
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445454
ER  - 

TY  - NA
AU  - Li, Daniel; Chen, Thomas; Tung, Albert; Chilton, Lydia B.
TI  - UIST - Hierarchical Summarization for Longform Spoken Dialog
PY  - 2021
AB  - Every day we are surrounded by spoken dialog. This medium delivers rich diverse streams of information auditorily; however, systematically understanding dialog can often be non-trivial. Despite the pervasiveness of spoken dialog, automated speech understanding and quality information extraction remains markedly poor, especially when compared to written prose. Furthermore, compared to understanding text, auditory communication poses many additional challenges such as speaker disfluencies, informal prose styles, and lack of structure. These concerns all demonstrate the need for a distinctly speech tailored interactive system to help users understand and navigate the spoken language domain. While individual automatic speech recognition (ASR) and text summarization methods already exist, they are imperfect technologies; neither consider user purpose and intent nor address spoken language induced complications. Consequently, we design a two stage ASR and text summarization pipeline and propose a set of semantic segmentation and merging algorithms to resolve these speech modeling challenges. Our system enables users to easily browse and navigate content as well as recover from errors in these underlying technologies. Finally, we present an evaluation of the system which highlights user preference for hierarchical summarization as a tool to quickly skim audio and identify content of interest to the user.
SP  - 582
EP  - 597
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474771
ER  - 

TY  - NA
AU  - Bouzbib, Elodie; Bailly, Gilles; Haliyo, Sinan; Frey, Pascal
TI  - "Can I Touch This?": Survey of Virtual Reality Interactions via Haptic Solutions
PY  - 2021
AB  - Haptic feedback has become crucial to enhance the user experiences in Virtual Reality (VR). This justifies the sudden burst of novel haptic solutions proposed these past years in the HCI community. This article is a survey of Virtual Reality interactions, relying on haptic devices. We propose two dimensions to describe and compare the current haptic solutions: their degree of physicality, as well as their degree of actuation. We depict a compromise between the user and the designer, highlighting how the range of required or proposed stimulation in VR is opposed to the haptic interfaces flexibility and their deployment in real-life use-cases. This paper (1) outlines the variety of haptic solutions and provides a novel perspective for analysing their associated interactions, (2) highlights the limits of the current evaluation criteria regarding these interactions, and finally (3) reflects the interaction, operation and conception potentials of "encountered-type of haptic devices".
SP  - NA
EP  - NA
JF  - 32e Conférence Francophone sur l'Interaction Homme-Machine
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3450522.3451323
ER  - 

TY  - NA
AU  - Qiao, Han; Liu, Vivian; Chilton, Lydia
TI  - Initial Images: Using Image Prompts to Improve Subject Representation in Multimodal AI Generated Art
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Creativity and Cognition
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3527927.3532792
ER  - 

TY  - NA
AU  - Ku, Pin-Sung; Huang, Kunpeng; Kao, Cindy Hsin-Liu
TI  - Patch-O: Deformable Woven Patches for On-body Actuation
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517633
ER  - 

TY  - NA
AU  - Merino, Mauricio Verano; Thomas van Binsbergen, L.; Seraj, Mazyar
TI  - Making the Invisible Visible in Computational Notebooks
PY  - 2022
AB  - Notebooks are increasingly popular programming tools adopted by a diverse range of users, including professional and novice users, from various fields not necessarily skilled in software engineering, to experiment with programming and develop software. Notebooks are often used within interactive and exploratory programming settings; however, some of their main use cases are not naturally supported by their design. For example, users can only get insights into the program’s state by executing program fragments and updating one’s mental model. This paper discusses the possibility of defining widgets to improve notebooks by providing direct insights into the program state. The widgets are developed upon previous work in which a novel approach to incremental programming is suggested based on the notion of an exploring interpreter. As example, we present widgets for visualizing execution history and variable assignments, thereby reducing the cognitive load on users.
SP  - NA
EP  - NA
JF  - 2022 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vl/hcc53370.2022.9833148
ER  - 

TY  - NA
AU  - Wang, Chenglong; Feng, Yu; Bodik, Rastislav; Dillig, Isil; Cheung, Alvin; Ko, Amy J.
TI  - Falx: Synthesis-Powered Visualization Authoring
PY  - 2021
AB  - Modern visualization tools aim to allow data analysts to easily create exploratory visualizations. When the input data layout conforms to the visualization design, users can easily specify visualizations by mapping data columns to visual channels of the design. However, when there is a mismatch between data layout and the design, users need to spend significant effort on data transformation. We propose Falx, a synthesis-powered visualization tool that allows users to specify visualizations in a similarly simple way but without needing to worry about data layout. In Falx, users specify visualizations using examples of how concrete values in the input are mapped to visual channels, and Falx automatically infers the visualization specification and transforms the data to match the design. In a study with 33 data analysts on four visualization tasks involving data transformation, we found that users can effectively adopt Falx to create visualizations they otherwise cannot implement.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445249
ER  - 

TY  - CHAP
AU  - Avgustis, Iuliia; Shirokov, Aleksandr; Iivari, Netta
TI  - INTERACT (4) - “Please Connect Me to a Specialist”: Scrutinising ‘Recipient Design’ in Interaction with an Artificial Conversational Agent
PY  - 2021
AB  - This paper explores how callers formulate information enquiries for an artificial conversational agent in a call centre and compares it with the way enquiries are addressed to human operators of the same call centre. It includes 60 call recordings with human operators and 103 call recordings with the artificial conversational agent, transcribed and analysed using the method of Conversation Analysis. We show that people formulate and reformulate their enquiries differently to an artificial agent, even though the goal in both cases is to get an answer to the same enquiry. When talking to the artificial conversational agent, callers produce short enquiries, similar to web searches. When connected to human operators, callers formulate longer enquiries which include many details. By analysing the differences in the way callers formulate their enquiries to robots and human operators, we show what callers expect artificial conversational agents to process. These expectations affect the way the enquiry is formulated and, as a result, operators and artificial agents encounter different types of problems they have to repair to understand the question correctly and find an answer to it. Our findings have interesting implications for Human Computer Interaction both in terms of “robot-recipient design” and “user-recipient design”.
SP  - 155
EP  - 176
JF  - Human-Computer Interaction – INTERACT 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-85610-6_10
ER  - 

TY  - NA
AU  - Xia, Haijun; Jacobs, Jennifer; Agrawala, Maneesh
TI  - UIST - Crosscast: Adding Visuals to Audio Travel Podcasts
PY  - 2020
AB  - Audio travel podcasts are a valuable source of information for travelers. Yet, travel is, in many ways, a visual experience and the lack of visuals in travel podcasts can make it difficult for listeners to fully understand the places being discussed. We present Crosscast: a system for automatically adding visuals to audio travel podcasts. Given an audio travel podcast as input, Crosscast uses natural language processing and text mining to identify geographic locations and descriptive keywords within the podcast transcript. Crosscast then uses these locations and keywords to automatically select relevant photos from online repositories and synchronizes their display to align with the audio narration. In a user evaluation, we find that 85.7% of the participants preferred Crosscast generated audio-visual travel podcasts compared to audio-only travel podcasts.
SP  - 735
EP  - 746
JF  - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3379337.3415882
ER  - 

TY  - NA
AU  - Arawjo, Ian; DeArmas, Anthony; Roberts, Michael; Basu, Shrutarshi; Parikh, Tapan
TI  - Notational Programming for Notebook Environments: A Case Study with Quantum Circuits
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545619
ER  - 

TY  - JOUR
AU  - Yamanaka, Shota; Usuba, Hiroki
TI  - Computing Touch-Point Ambiguity on Mobile Touchscreens for Modeling Target Selection Times
PY  - 2021
AB  - <jats:p>Finger-Fitts law (FFitts law) is a model to predict touch-pointing times, modified from Fitts' law. It considers the absolute touch-point precision, or a finger tremor factor σa, to decrease the admissible target area and thus increase the task difficulty. Among choices such as running an independent task or performing parameter optimization, there is no consensus on the best methodology to measure σa. This inconsistency could be detrimental to HCI studies such as pointing technique evaluations and user group comparisons. By integrating the results of our 1D and 2D touch-pointing experiments and reanalyses of previous studies' data, we examined the advantages and disadvantages of each approach to compute σa. We found that the parameter optimization method is a suboptimal choice for predicting the performance.</jats:p>
SP  - 1
EP  - 21
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 4
PB  - 
DO  - 10.1145/3494976
ER  - 

TY  - NA
AU  - Signer, Beat; Roels, Reinout; van Barlingen, Robert; Willems, Brent
TI  - HT - Back to the Future: Bringing Original Hypermedia and Cross-Media Concepts to Modern Desktop Environments
PY  - 2021
AB  - Over the last few decades, we have seen massive improvements in computing power, but nevertheless we still rely on digital documents and file systems that were originally created by mimicking the characteristics of physical storage media with all its limitations. This is quite surprising given that even before the existence of the computer, Information Science visionaries such as Vannevar Bush described more powerful information management solutions. We therefore aim to improve the way information is managed in modern desktop environments by embedding a hypermedia engine offering rich hypermedia and cross-media concepts at the level of an operating system. We discuss the resource-selector-link (RSL) hypermedia metamodel as a candidate for realising such a general hypermedia engine and highlight its flexibility based on a number of domain-specific applications that have been developed over the last two decades. The underlying content repository will no longer rely on monolithic files, but rather contain a user's data in the form of content fragments, such as snippets of text or images, which are structurally linked to form the corresponding documents, and can be reused in other documents or even shared across computers. By increasing the scope to a system-wide hypermedia engine, we have to deal with fundamental challenges related to granularity, interoperability or context resolving. We strongly believe that computing technology has evolved enough to revisit and address these challenges, laying the foundation for a wide range of innovative use cases for efficiently managing cross-media content in modern desktop environments.
SP  - 277
EP  - 282
JF  - Proceedings of the 32st ACM Conference on Hypertext and Social Media
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3465336.3475122
ER  - 

TY  - NA
AU  - Sun, Lingyun; Li, Jiaji; Li, Mingming; Fan, Yitao; Chen, Yu; Pan, Deying; Yang, Yue; Ji, Junzhe; Tao, Ye; Wang, Guanyun
TI  - UIST (Adjunct Volume) - 3DP-Ori: Bridging-Printing Based Origami Fabrication Method with Modifiable Haptic properties
PY  - 2021
AB  - Origami is the art of making 2D/3D shapes by folding paper, HCI researchers have leveraged novel structure design and material techniques to create a wide range of origami-based shape-changing interface. Meanwhile, additive manufacturing which could easily fabricate complicated artifacts and augment the haptic sensation, has drawn more attention to the field. This paper presents 3DP-Ori, a fabrication method of flexible origami construction with conventional FDM printers. To create and end-to-end pipeline, we developed a parametric design tool with dynamic folding simulation and feasibility estimation, which enable our software to output a printable semi-folded origami model for further easy manual deformation. Adopting and optimizing bridging-based printing, we leverage multiple geometric patterns with adjustable flexibility on creases, which further effect the haptic properties on 3DP-Ori objects. We believe the 3DP-Ori extends the design space of 3D printing beyond typically hard and fixed forms, and it will help designers and researchers to fabricate interactivities with various physical properties.
SP  - 74
EP  - 77
JF  - The Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3474349.3480233
ER  - 

TY  - NA
AU  - Miyazaki, Kazuki; Takano, Shuhei; Tsuno, Ryo; Ishibashi, Hideaki; Furukawa, Tetsuo
TI  - Low-rank kernel decomposition for scalable manifold modeling
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 Joint 12th International Conference on Soft Computing and Intelligent Systems and 23rd International Symposium on Advanced Intelligent Systems (SCIS&ISIS)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/scisisis55246.2022.10001865
ER  - 

TY  - JOUR
AU  - Haimson, Oliver L.; Delmonaco, Daniel; Nie, Peipei; Wegner, Andrea
TI  - Disproportionate Removals and Differing Content Moderation Experiences for Conservative, Transgender, and Black Social Media Users: Marginalization and Moderation Gray Areas
PY  - 2021
AB  - Social media sites use content moderation to attempt to cultivate safe spaces with accurate information for their users. However, content moderation decisions may not be applied equally for all types of users, and may lead to disproportionate censorship related to people's genders, races, or political orientations. We conducted a mixed methods study involving qualitative and quantitative analysis of survey data to understand which types of social media users have content and accounts removed more frequently than others, what types of content and accounts are removed, and how content removed may differ between groups. We found that three groups of social media users in our dataset experienced content and account removals more often than others: political conservatives, transgender people, and Black people. However, the types of content removed from each group varied substantially. Conservative participants' removed content included content that was offensive or allegedly so, misinformation, Covid-related, adult, or hate speech. Transgender participants' content was often removed as adult despite following site guidelines, critical of a dominant group (e.g., men, white people), or specifically related to transgender or queer issues. Black participants' removed content was frequently related to racial justice or racism. More broadly, conservative participants' removals often involved harmful content removed according to site guidelines to create safe spaces with accurate information, while transgender and Black participants' removals often involved content related to expressing their marginalized identities that was removed despite following site policies or fell into content moderation gray areas. We discuss potential ways forward to make content moderation more equitable for marginalized social media users, such as embracing and designing specifically for content moderation gray areas.
SP  - 1
EP  - 35
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 5
IS  - CSCW2
PB  - 
DO  - 10.1145/3479610
ER  - 

TY  - JOUR
AU  - Yang, Xiaoying; Sayono, Jacob; Xu, Jess; Li, Jiahao Nick; Hester, Josiah; Zhang, Yang
TI  - MiniKers
PY  - 2022
AB  - <jats:p>Automating operations of objects has made life easier and more convenient for billions of people, especially those with limited motor capabilities. On the other hand, even able-bodied users might not always be able to perform manual operations (e.g., both hands are occupied), and manual operations might be undesirable for hygiene purposes (e.g., contactless devices). As a result, automation systems like motion-triggered doors, remote-control window shades, contactless toilet lids have become increasingly popular in private and public environments. Yet, these systems are hampered by complex building wiring or short battery lifetimes, negating their positive benefits for accessibility, energy saving, healthcare, and other domains. In this paper we explore how these types of objects can be powered in perpetuity by the energy generated from a unique energy source - user interactions, specifically, the manual manipulations of objects by users who can afford them when they can afford them. Our assumption is that users' capabilities for object operations are heterogeneous, there are desires for both manual and automatic operations in most environments, and that automatic operations are often not needed as frequently - for example, an automatic door in a public space is often manually opened many times before a need for automatic operation shows up. The energy harvested by those manual operations would be sufficient to power that one automatic operation. We instantiate this idea by upcycling common everyday objects with devices which have various mechanical designs powered by a general-purpose backbone embedded system. We call these devices, MiniKers. We built a custom driver circuit that can enable motor mechanisms to toggle between generating powers (i.e., manual operation) and actuating objects (i.e., automatic operation). We designed a wide variety of mechanical mechanisms to retrofit existing objects and evaluated our system with a 48-hour deployment study, which proves the efficacy of MiniKers as well as shedding light into this people-as-power approach as a feasible solution to address energy needed for smart environment automation.</jats:p>
SP  - 1
EP  - 22
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 3
PB  - 
DO  - 10.1145/3550287
ER  - 

TY  - JOUR
AU  - Kirshenbaum, Nurit; Davidson, Kylie; Harden, Jesse; North, Chris; Kobayashi, Dylan; Theriot, Ryan; Tabalba, Roderick S.; Rogers, Michael L.; Belcaid, NA; Burks, Andrew; Bharadwaj, Krishna; Renambot, Luc; Johnson, Andrew E.; Long, Lance; Leigh, Jason
TI  - Traces of Time through Space: Advantages of Creating Complex Canvases in Collaborative Meetings
PY  - 2021
AB  - Technology have long been a partner of workplace meeting facilitation. The recent outbreak of COVID-19 and the cautionary measures to reduce its spread have made it more prevalent than ever before in the form of online-meetings. In this paper, we recount our experiences during weekly meetings in three modalities: using SAGE2 - a collaborative sharing software designed for large displays - for co-located meetings, using a conventional projector for co-located meetings, and using the Zoom video-conferencing tool for distributed meetings. We view these meetings through the lens of effective meeting attributes and share ethnographic observations and attitudinal survey conducted in our research lab. We discuss patterns of content sharing, either sequential, parallel, or semi-parallel, and the potential advantages of creating complex canvases of content. We see how the SAGE2 tool affords parallel content sharing to create complex canvases, which represent queues of ideas and contributions (past, present, and future) using the space on a large display to suggest the progression of time through the meeting.
SP  - 1
EP  - 20
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 5
IS  - ISS
PB  - 
DO  - 10.1145/3488552
ER  - 

TY  - NA
AU  - Chen, Chen; Johnson, Janet G.; Charles, Kemeberly; Lee, Alice; Lifset, Ella T.; Hogarth, Michael; Moore, Alison A.; Farcas, Emilia; Weibel, Nadir
TI  - Understanding Barriers and Design Opportunities to Improve Healthcare and QOL for Older Adults through Voice Assistants.
PY  - 2021
AB  - Voice based Intelligent Virtual Assistants (IVAs) promise to improve healthcare management and Quality of Life (QOL) by introducing the paradigm of hands free and eye free interactions. However, there has been little understanding regarding the challenges for designing such systems for older adults, especially when it comes to healthcare related tasks. To tackle this, we consider the processes of care delivery and QOL enhancements for older adults as a collaborative task between patients and providers. By interviewing 16 older adults living independently or semi independently and 5 providers, we identified 12 barriers that older adults might encounter during daily routine and while managing health. We ultimately highlighted key design challenges and opportunities that might be introduced when integrating voice based IVAs into the life of older adults. Our work will benefit practitioners who study and attempt to create full fledged IVA powered smart devices to deliver better care and support an increased QOL for aging populations.
SP  - NA
EP  - NA
JF  - The 23rd International ACM SIGACCESS Conference on Computers and Accessibility
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3441852.3471218
ER  - 

TY  - NA
AU  - Zhu, Junyi
TI  - Design and Fabricate Personal Health Sensing Devices
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The Adjunct Publication of the 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526114.3558528
ER  - 

TY  - JOUR
AU  - Xiao, Ya-Qian; Kan, Chi-Wai
TI  - Review on Development and Application of 3D-Printing Technology in Textile and Fashion Design
PY  - 2022
AB  - <jats:p>Three-dimensional printing (3DP) allows for the creation of highly complex products and offers customization for individual users. It has generated significant interest and shows great promise for textile and fashion design. Here, we provide a timely and comprehensive review of 3DP technology for the textile and fashion industries according to recent advances in research. We describe the four 3DP methods for preparing textiles; then, we summarize three routes to use 3DP technology in textile manufacturing, including printing fibers, printing flexible structures and printing on textiles. In addition, the applications of 3DP technology in fashion design, functional garments and electronic textiles are introduced. Finally, the challenges and prospects of 3DP technology are discussed.</jats:p>
SP  - 267
EP  - 267
JF  - Coatings
VL  - 12
IS  - 2
PB  - 
DO  - 10.3390/coatings12020267
ER  - 

TY  - JOUR
AU  - Jahanbakhsh, Farnaz; Zhang, Amy X.; Karger, David R.
TI  - Leveraging Structured Trusted-Peer Assessments to Combat Misinformation
PY  - 2022
AB  - <jats:p>Platform operators have devoted significant effort to combating misinformation on behalf of their users. Users are also stakeholders in this battle, but their efforts to combat misinformation go unsupported by the platforms. In this work, we consider three new user affordances that give social media users greater power in their fight against misinformation: (1) the ability to provide structured accuracy assessments of posts, (2) user-specified indication of trust in other users, and (3) and user configuration of social feed filters according to assessed accuracy. To understand the potential of these designs, we conducted a need-finding survey of 192 people who share and discuss news on social media, finding that many already act to limit or combat misinformation, albeit by repurposing existing platform affordances that lack customized structure for information assessment. We then conducted a field study of a prototype social media platform that implements these user affordances as structured inputs to directly impact how and whether posts are shown. The study involved 14 participants who used the platform for a week to share news while collectively assessing their accuracy. We report on users' perception and use of these affordances. We also provide design implications for platforms and researchers based on our empirical observations.</jats:p>
SP  - 1
EP  - 40
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - CSCW2
PB  - 
DO  - 10.1145/3555637
ER  - 

TY  - JOUR
AU  - Homaeian, Leila; Wallace, James R.; Scott, Stacey D.
TI  - Handoff and Deposit: Designing Temporal Coordination in Cross-Device Transfer Techniques for Mixed-Focus Collaboration
PY  - 2022
AB  - <jats:p>When working together, people frequently share information with each other to enable division of labour, assistance, and delegation of responsibility. The literature has explored both synchronous and asynchronous transfer techniques, known as Handoff and Deposit, respectively. However, current cross-device environments tend to only provide a single mechanism. Moreover, we have little understanding of the impact of different techniques on collaborative process. To understand how Handoff and Deposit may be designed to support complex sensemaking tasks, we followed a Research through Design process to iteratively design Handoff and Deposit techniques using paper and digital sketches and high-fidelity prototypes. We consulted the HCI literature to corroborate our findings with studies and descriptions of existing cross-device transfer designs and to understand the potential impact of those designs on mixed-focus collaboration. We learned that as we move away from a restricted physical workspace and leverage the flexibility of digital personal devices, there is a large design space for realizing cross-device transfer. To inform these designs, we provide five design considerations for cross-device transfer techniques: Transfer Acceptance, Action Dependencies, Immediate Usability, Interruption Potential, and Connection Actions.</jats:p>
SP  - 1
EP  - 23
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - CSCW2
PB  - 
DO  - 10.1145/3555192
ER  - 

TY  - NA
AU  - Lau, Samuel; Ragavan, Sruti Srinivasa; Milne, Ken; Barik, Titus; Sarkar, Advait
TI  - CHI - TweakIt: Supporting End-User Programmers Who Transmogrify Code
PY  - 2021
AB  - End-user programmers opportunistically copy-and-paste code snippets from colleagues or the web to accomplish their tasks. Unfortunately, these snippets often don’t work verbatim, so these people—who are non-specialists in the programming language—make guesses and tweak the code to understand and apply it successfully. To support their desired workflow and facilitate tweaking and understanding, we built a prototype tool, TweakIt, that provides users with a familiar live interaction to help them understand, introspect, and reify how different code snippets would transform their data. Through a usability study with 14 data analysts, participants found the tool to be useful to understand the function of otherwise unfamiliar code, to increase their confidence about what the code does, to identify relevant parts of code specific to their task, and to proactively explore and evaluate code. Overall, our participants were enthusiastic about incorporating TweakIt in their own day-to-day work.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445265
ER  - 

TY  - JOUR
AU  - Lu, Xiong; Yan, Yuxing; Qi, Beibei; Qian, Huang; Sun, Junbin; Quigley, Aaron
TI  - Contactless Haptic Display Through Magnetic Field Control.
PY  - 2022
AB  - Haptic rendering enables people to touch, perceive, and manipulate virtual objects in a virtual environment. Using six cascaded identical hollow disk electromagnets and a small permanent magnet attached to an operator's finger, this paper proposes and develops an untethered haptic interface through magnetic field control. The concentric hole inside the six cascaded electromagnets provides the workspace, where the 3D position of the permanent magnet is tracked with a Microsoft Kinect sensor. The driving currents of six cascaded electromagnets are calculated in real-time for generating the desired magnetic force. Offline data from an FEA (finite element analysis) based simulation, determines the relationship between the magnetic force, the driving currents, and the position of the permanent magnet. A set of experiments including the virtual object recognition experiment, the virtual surface identification experiment, and the user perception evaluation experiment were conducted to demonstrate the proposed system, where Microsoft HoloLens holographic glasses are used for visual rendering. The proposed magnetic haptic display leads to an untethered and non-contact interface for natural haptic rendering applications, which overcomes the constraints of mechanical linkages in tool-based traditional haptic devices.
SP  - 328
EP  - 338
JF  - IEEE transactions on haptics
VL  - 15
IS  - 2
PB  - 
DO  - 10.1109/toh.2022.3151673
ER  - 

TY  - NA
AU  - Ceyssens, Jeroen; Di Fiore, Fabian; Luyten, Kris
TI  - Context-Aware Support of Dexterity Skills in Cross-Reality Environments
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar-adjunct57072.2022.00214
ER  - 

TY  - NA
AU  - Müller, Philipp; Staal, Sander; Bâce, Mihai; Bulling, Andreas
TI  - Designing for Noticeability: Understanding the Impact of Visual Importance on Desktop Notifications
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501954
ER  - 

TY  - NA
AU  - Smith, Micah J.; Cito, Jürgen; Veeramachaneni, Kalyan
TI  - Meeting in the notebook: a notebook-based environment for micro-submissions in data science collaborations.
PY  - 2021
AB  - Developers in data science and other domains frequently use computational notebooks to create exploratory analyses and prototype models. However, they often struggle to incorporate existing software engineering tooling into these notebook-based workflows, leading to fragile development processes. We introduce Assemble, a new development environment for collaborative data science projects, in which promising code fragments of data science pipelines can be contributed as pull requests to an upstream repository entirely from within JupyterLab, abstracting away low-level version control tool usage. We describe the design and implementation of Assemble and report on a user study of 23 data scientists.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Liu, Vivian; Chilton, Lydia B
TI  - Design Guidelines for Prompt Engineering Text-to-Image Generative Models
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501825
ER  - 

TY  - NA
AU  - Abdullah, Muhammad; Sommerfeld, Romeo; Seidel, Laurenz; Noack, Jonas; Zhang, Ran; Roumen, Thijs; Baudisch, Patrick
TI  - UIST - Roadkill: Nesting Laser-Cut Objects for Fast Assembly
PY  - 2021
AB  - We present Roadkill, a software tool that converts 3D models to 2D cutting plans for laser cutting—such that the resulting layouts allow for fast assembly. Roadkill achieves this by putting all relevant information into the cutting plan: (1) Thumbnails indicate which area of the model a set of parts belongs to. (2) Parts with exposed finger joints are easy to access, thereby suggesting to start assembly here. (3) Openings in the sheet act as jigs, affording assembly within the sheet. (4) Users continue assembly by inserting what has already been assembled into parts that are immediately adjacent or are pointed to by arrows. Roadkill maximizes the number of joints rendered in immediate adjacency by breaking down models into “subassemblies.” Within a subassembly, Roadkill holds the parts together using break-away tabs. (5) Users complete subassemblies according to their labels 1, 2, 3…, following 1 -> 1 links to insert subassemblies into other subassemblies, until all parts come together. In our user study, Roadkill allowed participants to assemble layouts 2.4 times faster than layouts generated by a traditional pair-wise labeling of plates.
SP  - 972
EP  - 984
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474799
ER  - 

TY  - NA
AU  - Ivanov, Alexander; Ledo, David; Grossman, Tovi; Fitzmaurice, George; Anderson, Fraser
TI  - MoodCubes: Immersive Spaces for Collecting, Discovering and Envisioning Inspiration Materials
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Designing Interactive Systems Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532106.3533565
ER  - 

TY  - NA
AU  - Lin, Hongnan; He, Liang; Song, Fangli; Li, Yifan; Cheng, Tingyu; Zheng, Clement; Wang, Wei; Oh, HyunJoo
TI  - FlexHaptics: A Design Method for Passive Haptic Inputs Using Planar Compliant Structures
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502113
ER  - 

TY  - NA
AU  - Chang, Ruei-Che; Wang, Wen-Ping; Chiang, Chi-huan; Wu, Te-Yen; Xu, Zheer; Luo, Justin; Chen, Bing-Yu; Yang, Xing-Dong
TI  - CHI - AccessibleCircuits: Adaptive Add-On Circuit Components for People with Blindness or Low Vision
PY  - 2021
AB  - In this paper, we propose the designs for low cost and 3D-printable add-on components to adapt existing breadboards, circuit components and electronics tools for blind or low vision (BLV) users. Through an initial user study, we identified several barriers to entry for beginners with BLV in electronics and circuit prototyping. These barriers guided the design and development of our add-on components. We focused on developing adaptations that provide additional information about the specific component pins and breadboard holes, modify tools to make them easier to use for users with BLV, and expand non-visual feedback (e.g., audio, tactile) for tasks that require vision. Through a second user study, we demonstrated that our adaptations can effectively overcome the accessibility barriers in breadboard circuit prototyping for users with BLV.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445690
ER  - 

TY  - NA
AU  - Frey, Seth; Schneider, Nathan
TI  - Effective Voice: Beyond Exit and Affect in Online Communities
PY  - 2020
AB  - Online communities provide ample opportunities for user self-expression but generally lack the means for average users to exercise direct control over community policies. This paper sets out to identify a set of strategies and techniques through which the voices of participants might be better heard through defined mechanisms for institutional governance. Drawing on Albert O. Hirschman's distinction between "exit" and "voice" in institutional life, it introduces a further distinction between two kinds of participation: effective voice, as opposed to the far more widespread practices of affective voice. Effective voice is a form of individual or collective speech that brings about a binding effect according to transparent processes. Platform developers and researchers might explore this neglected form of voice by introducing mechanisms for authority and accountability, collective action, and community evolution.
SP  - NA
EP  - NA
JF  - arXiv: Computers and Society
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Ahuja, Karan; Shen, Vivian; Fang, Cathy Mengying; Riopelle, Nathan; Kong, Andy; Harrison, Chris
TI  - ControllerPose: Inside-Out Body Capture with VR Controller Cameras
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502105
ER  - 

TY  - JOUR
AU  - Hong, Freddie; Tendera, Luca; Myant, Connor; Boyle, David
TI  - Vacuum-Formed 3D Printed Electronics: Fabrication of Thin, Rigid and Free-Form Interactive Surfaces
PY  - 2022
AB  - <jats:title>Abstract</jats:title><jats:p>Vacuum-forming is a common manufacturing technique for constructing thin plastic shell products by pressing heated plastic sheets onto a mold using atmospheric pressure. Vacuum-forming is ubiquitous in packaging and casing products in the industry, spanning fast moving consumer goods to connected devices. Integrating advanced functionality, which may include sensing, computation and communication, within thin structures is desirable for various next-generation interactive devices. Hybrid additive manufacturing techniques like thermoforming are becoming popular for prototyping freeform surfaces owing to their design flexibility, speed and cost-effectiveness. This paper presents a new hybrid method for constructing thin, rigid and free-form interconnected surfaces via fused deposition modelling (FDM) 3D printing and vacuum-forming that builds on recent advances in thermoforming circuits. 3D printing the sheet material allows for the embedding of conductive traces within thin layers of the substrate, which can be vacuum-formed but remain conductive and insulated. This is an unexplored fabrication technique within the context of designing and manufacturing connected things. In addition to explaining the method, this paper characterizes the behavior of vacuum-formed 3D printed sheets, analyses the electrical performance of printed traces after vacuum-forming, and showcases a range of sample artefacts constructed using the technique. In addition, the paper describes a new design interface for designing conformal interconnects that allows designers to draw conductive patterns in 3D and export pre-distorted sheet models ready to be printed.</jats:p>
SP  - NA
EP  - NA
JF  - SN Computer Science
VL  - 3
IS  - 4
PB  - 
DO  - 10.1007/s42979-022-01174-1
ER  - 

TY  - CHAP
AU  - Zhang, Mingrui Ray; Wen, He; Cui, Wenzhe; Zhu, Suwen; Schwartz, H. Andrew; Bi, Xiaojun; Wobbrock, Jacob O.
TI  - AI-Driven Intelligent Text Correction Techniques for Mobile Text Entry
PY  - 2021
AB  - Current text correction processes on mobile touch devices are laborious: users either extensively use backspace, or navigate the cursor to the error position, make a correction, and navigate back, usually by employing multiple taps or drags over small targets. In this chapter, we present two techniques, Type, Then Correct and JustCorrect, that utilize the power of artificial intelligence to improve the text correction experience on mobile devices. All of the techniques skip error-deletion and cursor-positioning procedures, and instead allow the user to type the correction first, and then apply that correction to a previously committed error. We evaluated these techniques in and the results show that correction with the new techniques was faster than de facto cursor and backspace-based correction.
SP  - 131
EP  - 168
JF  - Human–Computer Interaction Series
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-82681-9_5
ER  - 

TY  - BOOK
AU  - Arakawa, Riku; Zhang, Yang
TI  - CHIIoT@EWSN/EICS - Low-Cost Millimeter-Wave Interactive Sensing through Origami Reflectors.
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Nisser, Martin; Makaram, Yashaswini; Covarrubias, Lucian; Bah, Amadou Yaye; Faruqi, Faraz; Suzuki, Ryo; Mueller, Stefanie
TI  - Mixels: Fabricating Interfaces using Programmable Magnetic Pixels
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545698
ER  - 

TY  - NA
AU  - Omar, Cyrus; Moon, David; Blinn, Andrew; Voysey, Ian; Collins, Nick; Chugh, Ravi
TI  - PLDI - Filling typed holes with live GUIs
PY  - 2021
AB  - Text editing is powerful, but some types of expressions are more naturally represented and manipulated graphically. Examples include expressions that compute colors, music, animations, tabular data, plots, diagrams, and other domain-specific data structures. This paper introduces live literals, or livelits, which allow clients to fill holes of types like these by directly manipulating a user-defined GUI embedded persistently into code. Uniquely, livelits are compositional: a livelit GUI can itself embed spliced expressions, which are typed, lexically scoped, and can in turn embed other livelits. Livelits are also uniquely live: a livelit can provide continuous feedback about the run-time implications of the client’s choices even when splices mention bound variables, because the system continuously gathers closures associated with the hole that the livelit is filling. We integrate livelits into Hazel, a live hole-driven programming environment, and describe case studies that exercise these novel capabilities. We then define a simply typed livelit calculus, which specifies how livelits operate as live graphical macros. The metatheory of macro expansion has been mechanized in Agda.
SP  - 511
EP  - 525
JF  - Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3453483.3454059
ER  - 

TY  - NA
AU  - Clarence, Aldrich; Knibbe, Jarrod; Cordeil, Maxime; Wybrow, Michael
TI  - VR - Unscripted Retargeting: Reach Prediction for Haptic Retargeting in Virtual Reality
PY  - 2021
AB  - Research is exploring novel ways of adding haptics to VR. One popular technique is haptic retargeting, where real and virtual hands are decoupled to enable the reuse of physical props. However, this technique requires the system to know the users' intended interaction target, or requires additional hardware for prediction. We explore software-based reach prediction as a means of facilitating responsive, unscripted retargeting. We trained a Long Short-Term Memory network on users' reach trajectories to predict intended targets. We achieved an accuracy of 81.1 % at approximately 65% of movement. This could enable haptic retargeting during the last 35% of movement. We discuss the implications for possible physical proxy locations.
SP  - 150
EP  - 159
JF  - 2021 IEEE Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr50410.2021.00036
ER  - 

TY  - NA
AU  - Suzuki, Ryo; Kazi, Rubaiat Habib; Wei, Li-Yi; DiVerdi, Stephen; Li, Wilmot; Leithinger, Daniel
TI  - RealitySketch
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - SIGGRAPH Asia 2021 Real-Time Live!
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3478511.3491313
ER  - 

TY  - NA
AU  - Wall, Ludwig Wilhelm
TI  - -1D Fabrication: Investigating Decoupling Dimensions of Fabrication Output and Fabrication Machine Size
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490149.3502423
ER  - 

TY  - NA
AU  - Mendez S., Luis Andres; Ng, Ho Yin; Lim, Zin Yin; Lu, Yi-Jie; Han, Ping-Hsuan
TI  - MovableBag: Substitutional Robot for Enhancing Immersive Boxing Training with Encountered-Type Haptic
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - SIGGRAPH Asia 2022 XR
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3550472.3558406
ER  - 

TY  - NA
AU  - Giunchi, Daniele; Sztrajman, Alejandro; James, Stuart; Steed, Anthony
TI  - Mixing Modalities of 3D Sketching and Speech for Interactive Model Retrieval in Virtual Reality
PY  - 2021
AB  - Sketch and speech are intuitive interaction methods that convey complementary information and have been independently used for 3D model retrieval in virtual environments. While sketch has been shown to be an effective retrieval method, not all collections are easily navigable using this modality alone. We design a new challenging database for sketch comprised of 3D chairs where each of the components (arms, legs, seat, back) are independently colored. To overcome this, we implement a multimodal interface for querying 3D model databases within a virtual environment. We base the sketch on the state-of-the-art for 3D Sketch Retrieval, and use a Wizard-of-Oz style experiment to process the voice input. In this way, we avoid the complexities of natural language processing which frequently requires fine-tuning to be robust. We conduct two user studies and show that hybrid search strategies emerge from the combination of interactions, fostering the advantages provided by both modalities.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - He, Liang; Wittkopf, Jarrid A.; Jun, Ji Won; Erickson, Kris; Ballagas, Rafael Tico
TI  - ModElec
PY  - 2021
AB  - <jats:p>Integrating electronics with highly custom 3D designs for the physical fabrication of interactive prototypes is traditionally cumbersome and requires numerous iterations of manual assembly and debugging. With the new capabilities of 3D printers, combining electronic design and 3D modeling workflows can lower the barrier for achieving interactive functionality or iterating on the overall design. We present ModElec---an interactive design tool that enables the coordinated expression of electronic and physical design intent by allowing designers to integrate 3D-printable circuits with 3D forms. With ModElec, the user can arrange electronic parts in a 3D body, modify the model design with embedded circuits updated, and preview the auto-generated 3D traces that can be directly printed with a multi-material-based 3D printer. We demonstrate the potential of ModElec with four example applications, from a set of game controls to reconfigurable devices. Further, the tool was reported as easy to use through a preliminary evaluation with eight designers.</jats:p>
SP  - 1
EP  - 20
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 4
PB  - 
DO  - 10.1145/3495000
ER  - 

TY  - NA
AU  - Li, Nianlong; Zhang, Zhengquan; Liu, Can; Yang, Zengyao; Fu, Yinan; Tian, Feng; Han, Teng; Fan, Mingming
TI  - CHI - vMirror: Enhancing the Interaction with Occluded or Distant Objects in VR with Virtual Mirrors
PY  - 2021
AB  - Interacting with out of reach or occluded VR objects can be cumbersome. Although users can change their position and orientation, such as via teleporting, to help observe and select, doing so frequently may cause loss of spatial orientation or motion sickness. We present vMirror, an interactive widget leveraging reflection of mirrors to observe and select distant or occluded objects. We first designed interaction techniques for placing mirrors and interacting with objects through mirrors. We then conducted a formative study to explore a semi-automated mirror placement method with manual adjustments. Next, we conducted a target-selection experiment to measure the effect of the mirror’s orientation on users’ performance. Results showed that vMirror can be as efficient as direct target selection for most mirror orientations. We further compared vMirror with teleport technique in a virtual treasure hunt game and measured participants’ task performance and subjective experiences. Finally, we discuss vMirorr user experience and present future directions.
SP  - 132
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445537
ER  - 

TY  - JOUR
AU  - Feger, Sebastian S.; Semmler, Lars; Schmidt, Albrecht; Kosch, Thomas
TI  - ElectronicsAR: Design and Evaluation of a Mobile and Tangible High-Fidelity Augmented Electronics Toolkit
PY  - 2022
AB  - <jats:p>Exploring and interacting with electronics is challenging as the internal processes of components are not visible. Further barriers to engagement with electronics include fear of injury and hardware damage. In response, Augmented Reality (AR) applications address those challenges to make internal processes and the functionality of circuits visible. However, current apps are either limited to abstract low-fidelity applications or entirely virtual environments. We present ElectronicsAR, a tangible high-fidelity AR electronics kit with scaled hardware components representing the shape of real electronics. Our evaluation with 24 participants showed that users were more efficient and more effective at naming components, as well as building and debugging circuits. We discuss our findings in the context of ElectronicsAR's unique characteristics that we contrast with related work. Based on this, we discuss opportunities for future research to design functional mobile AR applications that meet the needs of beginners and experts.</jats:p>
SP  - 700
EP  - 721
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - ISS
PB  - 
DO  - 10.1145/3567740
ER  - 

TY  - JOUR
AU  - Li, Changyang; Li, Wanwan; Huang, Haikun; Yu, Lap-Fai
TI  - Interactive augmented reality storytelling guided by scene semantics
PY  - 2022
AB  - <jats:p>We present a novel interactive augmented reality (AR) storytelling approach guided by indoor scene semantics. Our approach automatically populates virtual contents in real-world environments to deliver AR stories, which match both the story plots and scene semantics. During the storytelling process, a player can participate as a character in the story. Meanwhile, the behaviors of the virtual characters and the placement of the virtual items adapt to the player's actions. An input raw story is represented as a sequence of events, which contain high-level descriptions of the characters' states, and is converted into a graph representation with automatically supplemented low-level spatial details. Our hierarchical story sampling approach samples realistic character behaviors that fit the story contexts through optimizations; and an animator, which estimates and prioritizes the player's actions, animates the virtual characters to tell the story in AR. Through experiments and a user study, we validated the effectiveness of our approach for AR storytelling in different environments.</jats:p>
SP  - 1
EP  - 15
JF  - ACM Transactions on Graphics
VL  - 41
IS  - 4
PB  - 
DO  - 10.1145/3528223.3530061
ER  - 

TY  - NA
AU  - O'Leary, Jasper Tran; Nandi, Chandrakana; Lee, Khang; Peek, Nadya
TI  - UIST - Taxon: a Language for Formal Reasoning with Digital Fabrication Machines
PY  - 2021
AB  - Digital fabrication machines for makers have expanded access to manufacturing processes such as 3D printing, laser cutting, and milling. While digital models encode the data necessary for a machine to manufacture an object, understanding the trade-offs and limitations of the machines themselves is crucial for successful production. Yet, this knowledge is not codified and must be gained through experience, which limits both adoption of and creative exploration with digital fabrication tools. To formally represent machines, we present Taxon, a language that encodes a machine’s high-level characteristics, physical composition, and performable actions. With this programmatic foundation, makers can develop rules of thumb that filter for appropriate machines for a given job and verify that actions are feasible and safe. We integrate the language with a browser-based system for simulating and experimenting with machine workflows. The system lets makers engage with rules of thumb and enrich their understanding of machines. We evaluate Taxon by representing several machines from both common practice and digital fabrication research. We find that while Taxon does not exhaustively describe all machines, it provides a starting point for makers and HCI researchers to develop tools for reasoning about and making decisions with machines.
SP  - 691
EP  - 709
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474779
ER  - 

TY  - JOUR
AU  - Zhao, Maozheng; Cui, Wenzhe; Ramakrishnan, I. V.; Zhai, Shumin; Bi, Xiaojun
TI  - UIST - Voice and Touch Based Error-tolerant Multimodal Text Editing and Correction for Smartphones
PY  - 2021
AB  - Editing operations such as cut, copy, paste, and correcting errors in typed text are often tedious and challenging to perform on smartphones. In this paper, we present VT, a voice and touch-based multi-modal text editing and correction method for smartphones. To edit text with VT, the user glides over a text fragment with a finger and dictates a command, such as ”bold” to change the format of the fragment, or the user can tap inside a text area and speak a command such as ”highlight this paragraph” to edit the text. For text correcting, the user taps approximately at the area of erroneous text fragment and dictates the new content for substitution or insertion. VT combines touch and voice inputs with language context such as language model and phrase similarity to infer a user’s editing intention, which can handle ambiguities and noisy input signals. It is a great advantage over the existing error correction methods (e.g., iOS’s Voice Control) which require precise cursor control or text selection. Our evaluation shows that VT significantly improves the efficiency of text editing and text correcting on smartphones over the touch-only method and the iOS’s Voice Control method. Our user studies showed that VT reduced the text editing time by 30.80%, and text correcting time by 29.97% over the touch-only method. VT reduced the text editing time by 30.81%, and text correcting time by 47.96% over the iOS’s Voice Control method.
SP  - 162
EP  - 178
JF  - Proceedings of the ACM Symposium on User Interface Software and Technology. ACM Symposium on User Interface Software and Technology
VL  - 2021
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474742
ER  - 

TY  - NA
AU  - Liao, Jian; Karim, Adnan; Jadon, Shivesh Singh; Kazi, Rubaiat Habib; Suzuki, Ryo
TI  - RealityTalk: Real-Time Speech-Driven Augmented Presentation for AR Live Storytelling
PY  - 2022
AB  - We present RealityTalk, a system that augments real-time live presentations with speech-driven interactive virtual elements. Augmented presentations leverage embedded visuals and animation for engaging and expressive storytelling. However, existing tools for live presentations often lack interactivity and improvisation, while creating such effects in video editing tools require significant time and expertise. RealityTalk enables users to create live augmented presentations with real-time speech-driven interactions. The user can interactively prompt, move, and manipulate graphical elements through real-time speech and supporting modalities. Based on our analysis of 177 existing video-edited augmented presentations, we propose a novel set of interaction techniques and then incorporated them into RealityTalk. We evaluate our tool from a presenter's perspective to demonstrate the effectiveness of our system.
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545702
ER  - 

TY  - JOUR
AU  - Sin, Zackary P. T.; Chen, Peter Q.; Ng, Peter H. F.; Leong, Hong Va
TI  - Tracking Stuffed Toy for Naturally Mapped Interactive Play via a Soft-Pose Estimator
PY  - 2022
AB  - <jats:p>Have you ever picked up a stuffed toy and pretended to play with it in your childhood? We are motivated by the novel use of stuffed toys in enhancing extended reality interaction. A key goal of extended reality is to induce the feeling of presence in its users. Naturally mapped control interface has been shown to enhance presence. The literature also indicates that a high degree of freedom tracking is important to extended reality. Based on these observations, we show that a free-form naturally mapped control interface is well-motivated via a theoretical contextualization. We explore the possibility of building such a controller in the form of stuffed toys. To realize stuffed toys as controllers, a novel soft-pose estimator empowered by cage-based deformation is proposed. It is shown to be effective in tracking the poses and deformations of real soft objects even by training with synthetic data only. Three gameplay prototypes are developed to demonstrate that interactive play can be enabled by the soft-pose estimator. They also form the basis for two user studies that validate the success of tracking stuffed toys with the soft-pose estimator for interactive play.</jats:p>
SP  - 1
EP  - 25
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - CHI PLAY
PB  - 
DO  - 10.1145/3549518
ER  - 

TY  - NA
AU  - Pu, Kevin; Fu, Rainey; Dong, Rui; Wang, Xinyu; Chen, Yan; Grossman, Tovi
TI  - SemanticOn: Specifying Content-Based Semantic Conditions for Web Automation Programs
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545691
ER  - 

TY  - NA
AU  - Shen, Leixian; Shen, Enya; Luo, Yuyu; Yang, Xiaocong; Hu, Xuming; Zhang, Xiongshuai; Tai, Zhiwei; Wang, Jianmin
TI  - Towards Natural Language Interfaces for Data Visualization: A Survey.
PY  - 2021
AB  - Utilizing Visualization-oriented Natural Language Interfaces (V-NLI) as a complementary input modality to direct manipulation for visual analytics can provide an engaging user experience. It enables users to focus on their tasks rather than worrying about operating the interface to visualization tools. In the past two decades, leveraging advanced natural language processing technologies, numerous V-NLI systems have been developed both within academic research and commercial software, especially in recent years. In this article, we conduct a comprehensive review of the existing V-NLIs. In order to classify each paper, we develop categorical dimensions based on a classic information visualization pipeline with the extension of a V-NLI layer. The following seven stages are used: query understanding, data transformation, visual mapping, view transformation, human interaction, context management, and presentation. Finally, we also shed light on several promising directions for future work in the community.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Zhang, Mingrui Ray; Zhai, Shumin; Wobbrock, Jacob O.
TI  - TypeAnywhere: A QWERTY-Based Text Entry Solution for Ubiquitous Computing
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517686
ER  - 

TY  - NA
AU  - Smirnov, Oleg; Ketkar, Ameya; Bryksin, Timofey; Tsantalis, Nikolaos; Dig, Danny
TI  - IntelliTC: Automating Type Changes in IntelliJ IDEA
PY  - 2022
AB  - Developers often change types of program elements. Such refactoring often involves updating not only the type of the element itself, but also the API of all type-dependent references in the code, thus it is tedious and time-consuming. Despite type changes being more frequent than renamings, just a few current IDE tools provide partially-automated support only for a small set of hard-coded types. Researchers have recently proposed a data-driven approach to inferring API rewrite rules for type change patterns in Java using code commits history. In this paper, we build upon these recent advances and introduce IntelliTC — a tool to perform Java type change refactoring. We implemented it as a plugin for IntelliJ IDEA, a popular Java IDE developed by JetBrains. We present 3 different ways of providing support for such a refactoring from the standpoint of the user experience: Classic mode, Suggested Refactoring, and Inspection mode. To evaluate these modalities of using IntelliTC, we surveyed 22 experienced software developers. They positively rated the usefulness of the tool.The source code and distribution of the plugin are available on GitHub: https://github.com/JetBrains-Research/data-driven-type-migration. A demonstration video is available on YouTube: https://youtu.be/pdcfvADA1PY.
SP  - NA
EP  - NA
JF  - 2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/icse-companion55297.2022.9793766
ER  - 

TY  - NA
AU  - Maman, Ben; Bermano, Amit
TI  - TypeNet: Towards Camera Enabled Touch Typing on Flat Surfaces through Self-Refinement
PY  - 2022
AB  - Text entry for mobile devices nowadays is an equally crucial and time-consuming task, with no practical solution available for natural typing speeds without extra hardware. In this paper, we introduce a real-time method that is a significant step towards enabling touch typing on arbitrary flat surfaces (e.g., tables). The method employs only a simple video camera, placed in front of the user on the flat surface — at an angle practical for mobile usage. To achieve this, we adopt a classification framework, based on the observation that, in touch typing, similar hand configurations imply the same typed character across users. Importantly, this approach allows the convenience of un-calibrated typing, where the hand positions, with respect to the camera and each other, are not dictated.To improve accuracy, we propose a Language Processing scheme, which corrects the typed text and is specifically designed for real-time performance and integration with the vision-based signal. To enable feasible data collection and training, we propose a self-refinement approach that allows training on unlabeled flat-surface-typing footage; A network trained on (labeled) keyboard footage labels flat-surface videos using dynamic time warping, and is trained on them, in an Expectation Maximization (EM) manner.Using these techniques, we introduce the TypingHands26 Dataset, comprising videos of 26 different users typing on a keyboard, and 10 users typing on a flat surface, labeled at the frame level. We validate our approach and present a single camera-based system with character-level accuracy of 93.5% on average for known users, and 85.7% for unknown ones, outperforming pose-estimation-based methods by a large margin, despite performing at natural typing speeds of up to 80 Words Per Minute. Our method is the first to rely on a simple camera alone, and runs in interactive speeds, while still maintaining accuracy comparable to systems employing non-commodity equipment.
SP  - NA
EP  - NA
JF  - 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/wacv51458.2022.00064
ER  - 

TY  - NA
AU  - Lee, Lik Hang; Braud, Tristan; Hosio, Simo; Hui, Pan
TI  - Towards Augmented Reality-driven Human-City Interaction: Current Research on Mobile Headsets and Future Challenges
PY  - 2020
AB  - Interaction design for Augmented Reality (AR) is gaining increasing attention from both academia and industry. This survey discusses 260 articles (68.8% of articles published between 2015 - 2019) to review the field of human interaction in connected cities with emphasis on augmented reality-driven interaction. We provide an overview of Human-City Interaction and related technological approaches, followed by a review of the latest trends of information visualization, constrained interfaces, and embodied interaction for AR headsets. We highlight under-explored issues in interface design and input techniques that warrant further research, and conjecture that AR with complementary Conversational User Interfaces (CUIs) is a key enabler for ubiquitous interaction with immersive systems in smart cities. Our work helps researchers understand the current potential and future needs of AR in Human-City Interaction.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Kim, Joonho; Singh, Karan
TI  - Optimizing UI layouts for deformable face-rig manipulation
PY  - 2021
AB  - Complex deformable face-rigs have many independent parameters that control the shape of the object. A human face has upwards of 50 parameters (FACS Action Units), making conventional UI controls hard to find and operate. Animators address this problem by tediously hand-crafting in-situ layouts of UI controls that serve as visual deformation proxies, and facilitate rapid shape exploration. We propose the automatic creation of such in-situ UI control layouts. We distill the design choices made by animators into mathematical objectives that we optimize as the solution to an integer quadratic programming problem. Our evaluation is three-fold: we show the impact of our design principles on the resulting layouts; we show automated UI layouts for complex and diverse face rigs, comparable to animator handcrafted layouts; and we conduct a user study showing our UI layout to be an effective approach to face-rig manipulation, preferable to a baseline slider interface.
SP  - 1
EP  - 12
JF  - ACM Transactions on Graphics
VL  - 40
IS  - 4
PB  - 
DO  - 10.1145/3450626.3459842
ER  - 

TY  - JOUR
AU  - Ji, Naye; Zhang, Fan; Zhang, Haoxiang; Zhao, Youbing; Yu, Dingguo
TI  - Mixed reality depth contour occlusion using binocular similarity matching and three-dimensional contour optimisation
PY  - 2022
AB  - <jats:title>Abstract</jats:title><jats:p>Mixed reality applications often require virtual objects that are partly occluded by real objects. However, previous research and commercial products have limitations in terms of performance and efficiency. To address these challenges, we propose a novel depth contour occlusion (DCO) algorithm. The proposed method is based on the sensitivity of contour occlusion and a binocular stereoscopic vision device. In this method, a depth contour map is combined with a sparse depth map obtained from a two-stage adaptive filter area stereo matching algorithm and the depth contour map of the objects extracted by a digital image stabilisation optical flow method. We also propose a quadratic optimisation model with three constraints to generate an accurate dense map of the depth contour for high-quality real-virtual occlusion. The whole process is accelerated by GPU. To evaluate the effectiveness of the algorithm, we demonstrate a time consumption statistical analysis for each stage of the DCO algorithm execution. To verify the reliability of the real-virtual occlusion effect, we conduct an experimental analysis on single-sided, enclosed, and complex occlusions. Subsequently, we compare it with the occlusion method without quadratic optimisation. With our GPU implementation for real-time DCO, the evaluation indicates that applying the presented DCO algorithm enhances the real-time performance and the visual quality of real-virtual occlusion.</jats:p>
SP  - NA
EP  - NA
JF  - Virtual Reality
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/s10055-022-00695-7
ER  - 

TY  - NA
AU  - Saquib, Nazmus; Huq, Faria; Haque, Syed Arefinul
TI  - graphiti: Sketch-based Graph Analytics for Images and Videos
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501923
ER  - 

TY  - JOUR
AU  - Bayer, Ilker S
TI  - MEMS-Based Tactile Sensors: Materials, Processes and Applications in Robotics.
PY  - 2022
AB  - Commonly encountered problems in the manipulation of objects with robotic hands are the contact force control and the setting of approaching motion. Microelectromechanical systems (MEMS) sensors on robots offer several solutions to these problems along with new capabilities. In this review, we analyze tactile, force and/or pressure sensors produced by MEMS technologies including off-the-shelf products such as MEMS barometric sensors. Alone or in conjunction with other sensors, MEMS platforms are considered very promising for robots to detect the contact forces, slippage and the distance to the objects for effective dexterous manipulation. We briefly reviewed several sensing mechanisms and principles, such as capacitive, resistive, piezoresistive and triboelectric, combined with new flexible materials technologies including polymers processing and MEMS-embedded textiles for flexible and snake robots. We demonstrated that without taking up extra space and at the same time remaining lightweight, several MEMS sensors can be integrated into robotic hands to simulate human fingers, gripping, hardness and stiffness sensations. MEMS have high potential of enabling new generation microactuators, microsensors, micro miniature motion-systems (e.g., microrobots) that will be indispensable for health, security, safety and environmental protection.
SP  - 2051
EP  - 2051
JF  - Micromachines
VL  - 13
IS  - 12
PB  - 
DO  - 10.3390/mi13122051
ER  - 

TY  - NA
AU  - Cao, Yuanzhi; Fuste, Anna; Heun, Valentin
TI  - MobileTutAR: a Lightweight Augmented Reality Tutorial System using Spatially Situated Human Segmentation Videos
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519639
ER  - 

TY  - NA
AU  - McNutt, Andrew; Chugh, Ravi
TI  - Integrated Visualization Editing via Parameterized Declarative Templates
PY  - 2021
AB  - Interfaces for creating visualizations typically embrace one of several common forms. Textual specification enables fine-grained control, shelf building facilitates rapid exploration, while chart choosing promotes immediacy and simplicity. Ideally these approaches could be unified to integrate the user- and usage-dependent benefits found in each modality, yet these forms remain distinct. We propose parameterized declarative templates, a simple abstraction mechanism over JSON-based visualization grammars, as a foundation for multimodal visualization editors. We demonstrate how templates can facilitate organization and reuse by factoring the more than 160 charts that constitute Vega-Lite's example gallery into approximately 40 templates. We exemplify the pliability of abstracting over charting grammars by implementing -- as a template -- the functionality of the shelf builder Polestar (a simulacra of Tableau) and a set of templates that emulate the Google Sheets chart chooser. We show how templates support multimodal visualization editing by implementing a prototype and evaluating it through an approachability study.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445356
ER  - 

TY  - NA
AU  - McDonald, Denisa Qori; Mahajan, Shruti; Vallett, Richard; Dion, Genevieve; Shokoufandeh, Ali; Solovey, Erin
TI  - Interaction with Touch-Sensitive Knitted Fabrics: User Perceptions and Everyday Use Experiments
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502077
ER  - 

TY  - NA
AU  - Yan, Zeyu; Peng, Huaishu
TI  - UIST - FabHydro: Printing Interactive Hydraulic Devices with an Affordable SLA 3D Printer
PY  - 2021
AB  - We introduce FabHydro, a set of rapid and low-cost methods to prototype interactive hydraulic devices based on an off-the-shelf 3D printer and flexible photosensitive resin. We first present printer settings and custom support structures to warrant the successful print of flexible and deformable objects. We then demonstrate two printing methods to seal the transmission fluid inside these deformable structures: the Submerged Printing process that seals the liquid resin without manual assembly, and the Printing with Plugs method that allows the use of different transmission fluids without modification to the printer. Following the printing methods, we report a design space with a range of 3D printable primitives, including the hydraulic generator, transmitter, and actuator. To demonstrate the feasibility of our approaches and the breadth of new designs that they enable, we showcase a set of examples from a printed robotic gripper that can be operated at a distance to a mobile phone stand that serves as a status reminder by repositioning the user’s phone. We conclude with a discussion of our approach’s limitations and possible future improvements.
SP  - 298
EP  - 311
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474751
ER  - 

TY  - NA
AU  - Zhang, Zhong-Yi; Chen, Hong-Xian; Wang, Shih-Hao; Tsai, Hsin-Ruey
TI  - ELAXO : Rendering Versatile Resistive Force Feedback for Fingers Grasping and Twisting
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545677
ER  - 

TY  - NA
AU  - Dogan, Mustafa Doga; Taka, Ahmad; Lu, Michael; Zhu, Yunyi; Kumar, Akshat; Gupta, Aakar; Mueller, Stefanie
TI  - InfraredTags: Embedding Invisible AR Markers and Barcodes Using Low-Cost, Infrared-Based 3D Printing and Imaging Tools
PY  - 2022
AB  - Existing approaches for embedding unobtrusive tags inside 3D objects require either complex fabrication or high-cost imaging equipment. We present InfraredTags, which are 2D markers and barcodes imperceptible to the naked eye that can be 3D printed as part of objects, and detected rapidly by low-cost near-infrared cameras. We achieve this by printing objects from an infrared-transmitting filament, which infrared cameras can see through, and by having air gaps inside for the tag's bits, which appear at a different intensity in the infrared image. We built a user interface that facilitates the integration of common tags (QR codes, ArUco markers) with the object geometry to make them 3D printable as InfraredTags. We also developed a low-cost infrared imaging module that augments existing mobile devices and decodes tags using our image processing pipeline. Our evaluation shows that the tags can be detected with little near-infrared illumination (0.2lux) and from distances as far as 250cm. We demonstrate how our method enables various applications, such as object tracking and embedding metadata for augmented reality and tangible interactions.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501951
ER  - 

TY  - NA
AU  - Liu, Jingyuan; Fu, Hongbo; Tai, Chiew-Lan
TI  - UIST - PoseTween: Pose-driven Tween Animation
PY  - 2020
AB  - Augmenting human action videos with visual effects often requires professional tools and skills. To make this more accessible by novice users, existing attempts have focused on automatically adding visual effects to faces and hands, or let virtual objects strictly track certain body parts, resulting in rigid-looking effects. We present PoseTween, an interactive system that allows novice users to easily add vivid virtual objects with their movement interacting with a moving subject in an input video. Our key idea is to leverage the motion of the subject to create pose-driven tween animations of virtual objects. With our tool, a user only needs to edit the properties of a virtual object with respect to the subject's movement at keyframes, and the object is associated with certain body parts automatically. The properties of the object at intermediate frames are then determined by both the body movement and the interpolated object keyframe properties, producing natural object movements and interactions with the subject. We design a user interface to facilitate editing of keyframes and previewing animation results. Our user study shows that PoseTween significantly requires less editing time and fewer keyframes than using the traditional tween animation in making pose-driven tween animations for novice users.
SP  - 791
EP  - 804
JF  - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3379337.3415822
ER  - 

TY  - NA
AU  - Kshirsagar, Abhay; Patil, Neeraj
TI  - ICCCNT - IoT based smart lock with predictive maintenance
PY  - 2021
AB  - Security has been an essential matter of concern worldwide. Recently, cases of vehicle and consignment thefts have increased immensely. Security-based problems, as in goods' transportation through trucks, railways, private vehicles and other shipments, are vulnerable to frequent theft and security checks are done manually, as noted. It has been observed that physical locks are used for security that needs to be checked manually at regular intervals of time or at every halt or station. However, these systems are unreliable. The proposed circuit consists of a microcontroller, a tamper detection circuit, and a GPS module. Predictive maintenance will include monitoring the performance of the circuit components and predicting the likelihood of failures in the future. The aim is to provide security, safety monitoring, data tracking, real-time operations, etc. reducing theft cases, human efforts among other examples. The aim is to identify cargo robbery cases that are at risk and to provide security for different product types at various coordinates for transportation. The Internet of connected Things has enabled the devices in our environment to be and decisive devices, i.e., they exchange information or data with other devices or users of the network; wired/wireless, through a common Internet Protocol (IP) that connects with the Internet. In this way, we ensure that the devices are secure and capable of understanding unlawful events and changes in nearby areas and are acting and reacting autonomously largely without human intervention.
SP  - 1
EP  - 6
JF  - 2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/icccnt51525.2021.9579965
ER  - 

TY  - NA
AU  - Hertel, Julia; Karaosmanoglu, Sukran; Schmidt, Susanne; Bräker, Julia; Semmann, Martin; Steinicke, Frank
TI  - ISMAR - A Taxonomy of Interaction Techniques for Immersive Augmented Reality based on an Iterative Literature Review
PY  - 2021
AB  - Developers of interactive systems have a variety of interaction techniques to choose from, each with individual strengths and limitations in terms of the considered task, context, and users. While there are taxonomies for desktop, mobile, and virtual reality applications, augmented reality (AR) taxonomies have not been established yet. However, recent advances in immersive AR technology (i.e., head-worn or projection-based AR), such as the emergence of untethered headsets with integrated gesture and speech sensors, have enabled the inclusion of additional input modalities and, therefore, novel multimodal interaction methods have been introduced. To provide an overview of interaction techniques for current immersive AR systems, we conducted a literature review of publications between 2016 and 2021. Based on 44 relevant papers, we developed a comprehensive taxonomy focusing on two identified dimensions – task and modality. We further present an adaptation of an iterative taxonomy development method to the field of human-computer interaction. Finally, we discuss observed trends and implications for future work.
SP  - 431
EP  - 440
JF  - 2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar52148.2021.00060
ER  - 

TY  - NA
AU  - Hu, Jingmei; Vaithilingam, Priyan; Chong, Stephen; Seltzer, Margo; Glassman, Elena L.
TI  - UIST - Assuage: Assembly Synthesis Using A Guided Exploration
PY  - 2021
AB  - Assembly programming is challenging, even for experts. Program synthesis, as an alternative to manual implementation, has the potential to enable both expert and non-expert users to generate programs in an automated fashion. However, current tools and techniques are unable to synthesize assembly programs larger than a few instructions. We present Assuage : ASsembly Synthesis Using A Guided Exploration, which is a parallel interactive assembly synthesizer that engages the user as an active collaborator, enabling synthesis to scale beyond current limits. Using Assuage, users can provide two types of semantically meaningful hints that expedite synthesis and allow for exploration of multiple possibilities simultaneously. Assuage exposes information about the underlying synthesis process using multiple representations to help users guide synthesis. We conducted a within-subjects study with twenty-one participants working on assembly programming tasks. With Assuage, participants with a wide range of expertise were able to achieve significantly higher success rates, perceived less subjective workload, and preferred the usefulness and usability of Assuage over a state of the art synthesis tool.
SP  - 134
EP  - 148
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474740
ER  - 

TY  - JOUR
AU  - Michel, Elie; Boubekeur, Tamy
TI  - DAG amendment for inverse control of parametric shapes
PY  - 2021
AB  - Parametric shapes model objects as programs producing a geometry based on a few semantic degrees of freedom, called hyper-parameters. These shapes are the typical output of non-destructive modeling, CAD modeling or rigging. However they suffer from the core issue of being manipulated only indirectly, through a series of values rather than the geometry itself. In this paper, we introduce an amendment process of the underlying direct acyclic graph (DAG) of a parametric shape. This amendment enables a local differentiation of the shape w.r.t. its hyper-parameters that we leverage to provide interactive direct manipulation of the output. By acting on the shape synthesis process itself, our method is agnostic to the variations of the connectivity and topology that may occur in its output while changing the input hyper-parameters. Furthermore, our method is oblivious to the internal logic of the DAG nodes. We illustrate our approach on a collection of examples combining the typical nodes found in modern parametric modeling packages - such as deformation, booleans and surfacing operators - for which our method provides the user with inverse control over the hyper-parameters through a brush stroke metaphor.
SP  - 1
EP  - 14
JF  - ACM Transactions on Graphics
VL  - 40
IS  - 4
PB  - 
DO  - 10.1145/3450626.3459823
ER  - 

TY  - NA
AU  - Seguin, Joshua Paolo; Varghese, Delvin; Anwar, Misita; Bartindale, Tom; Olivier, Patrick
TI  - Co-designing Digital Platforms for Volunteer-led Migrant Community Welfare Support
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Designing Interactive Systems Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532106.3533544
ER  - 

TY  - JOUR
AU  - Polasek, Tomas; Hrusa, David; Benes, Bedrich; Čadík, Martin
TI  - ICTree
PY  - 2021
AB  - <jats:p>Many algorithms for virtual tree generation exist, but the visual realism of the 3D models is unknown. This problem is usually addressed by performing limited user studies or by a side-by-side visual comparison. We introduce an automated system for realism assessment of the tree model based on their perception. We conducted a user study in which 4,000 participants compared over one million pairs of images to collect subjective perceptual scores of a large dataset of virtual trees. The scores were used to train two neural-network-based predictors. A view independent ICTreeF uses the tree model's geometric features that are easy to extract from any model. The second is ICTreeI that estimates the perceived visual realism of a tree from its image. Moreover, to provide an insight into the problem, we deduce intrinsic attributes and evaluate which features make trees look like real trees. In particular, we show that branching angles, length of branches, and widths are critical for perceived realism. We also provide three datasets: carefully curated 3D tree geometries and tree skeletons with their perceptual scores, multiple views of the tree geometries with their scores, and a large dataset of images with scores suitable for training deep neural networks.</jats:p>
SP  - 1
EP  - 15
JF  - ACM Transactions on Graphics
VL  - 40
IS  - 6
PB  - 
DO  - 10.1145/3478513.3480519
ER  - 

TY  - NA
AU  - Abtahi, Parastoo; Hough, Sidney Q.; Landay, James A.; Follmer, Sean
TI  - Beyond Being Real: A Sensorimotor Control Perspective on Interactions in Virtual Reality
PY  - 2022
AB  - We can create Virtual Reality (VR) interactions that have no equivalent in the real world by remapping spacetime or altering users' body representation, such as stretching the user's virtual arm for manipulation of distant objects or scaling up the user's avatar to enable rapid locomotion. Prior research has leveraged such approaches, what we call beyond-real techniques, to make interactions in VR more practical, efficient, ergonomic, and accessible. We present a survey categorizing prior movement-based VR interaction literature as reality-based, illusory, or beyond-real interactions. We survey relevant conferences (CHI, IEEE VR, VRST, UIST, and DIS) while focusing on selection, manipulation, locomotion, and navigation in VR. For beyond-real interactions, we describe the transformations that have been used by prior works to create novel remappings. We discuss open research questions through the lens of the human sensorimotor control system and highlight challenges that need to be addressed for effective utilization of beyond-real interactions in future VR applications, including plausibility, control, long-term adaptation, and individual differences.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517706
ER  - 

TY  - NA
AU  - Jahanlou, Amir; Chilana, Parmit K
TI  - Katika: An End-to-End System for Authoring Amateur Explainer Motion Graphics Videos
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517741
ER  - 

TY  - NA
AU  - Srinivasan, Arjun; Setlur, Vidya
TI  - UIST - Snowy: Recommending Utterances for Conversational Visual Analysis
PY  - 2021
AB  - Natural language interfaces (NLIs) have become a prevalent medium for conducting visual data analysis, enabling people with varying levels of analytic experience to ask questions of and interact with their data. While there have been notable improvements with respect to language understanding capabilities in these systems, fundamental user experience and interaction challenges including the lack of analytic guidance (i.e., knowing what aspects of the data to consider) and discoverability of natural language input (i.e., knowing how to phrase input utterances) persist. To address these challenges, we investigate utterance recommendations that contextually provide analytic guidance by suggesting data features (e.g., attributes, values, trends) while implicitly making users aware of the types of phrasings that an NLI supports. We present Snowy, a prototype system that generates and recommends utterances for visual analysis based on a combination of data interestingness metrics and language pragmatics. Through a preliminary user study, we found that utterance recommendations in Snowy support conversational visual analysis by guiding the participants’ analytic workflows and making them aware of the system’s language interpretation capabilities. Based on the feedback and observations from the study, we discuss potential implications and considerations for incorporating recommendations in future NLIs for visual analysis.
SP  - 864
EP  - 880
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474792
ER  - 

TY  - NA
AU  - Palani, Srishti; Ledo, David; Fitzmaurice, George; Anderson, Fraser
TI  - "I don't want to feel like I'm working in a 1960s factory": The Practitioner Perspective on Creativity Support Tool Adoption
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501933
ER  - 

TY  - CHAP
AU  - Li, Toby Jia-Jun; Mitchell, Tom M.; Myers, Brad A.
TI  - Demonstration + Natural Language: Multimodal Interfaces for GUI-based Interactive Task Learning Agents
PY  - 2021
AB  - We summarize our past five years of work on designing, building, and studying Sugilite, an interactive task learning agent that can learn new tasks and relevant associated concepts interactively from the user’s natural language instructions and demonstrations leveraging the graphical user interfaces (GUIs) of third-party mobile apps. Through its multi-modal and mixed-initiative approaches for Human-AI interaction, Sugilite made important contributions in improving the usability, applicability, generalizability, flexibility, robustness, and shareability of interactive task learning agents. Sugilite also represents a new human-AI interaction paradigm for interactive task learning, where it uses existing app GUIs as a medium for users to communicate their intents with an AI agent instead of the interfaces for users to interact with the underlying computing services. In this chapter, we describe the Sugilite system, explain the design and implementation of its key features, and show a prototype in the form of a conversational assistant on Android.
SP  - 495
EP  - 537
JF  - Human–Computer Interaction Series
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-82681-9_15
ER  - 

TY  - NA
AU  - Wang, Tianyi; Qian, Xun; He, Fengming; Hu, Xiyun; Cao, Yuanzhi; Ramani, Karthik
TI  - UIST - GesturAR: An Authoring System for Creating Freehand Interactive Augmented Reality Applications
PY  - 2021
AB  - Freehand gesture is an essential input modality for modern Augmented Reality (AR) user experiences. However, developing AR applications with customized hand interactions remains a challenge for end-users. Therefore, we propose GesturAR, an end-to-end authoring tool that supports users to create in-situ freehand AR applications through embodied demonstration and visual programming. During authoring, users can intuitively demonstrate the customized gesture inputs while referring to the spatial and temporal context. Based on the taxonomy of gestures in AR, we proposed a hand interaction model which maps the gesture inputs to the reactions of the AR contents. Thus, users can author comprehensive freehand applications using trigger-action visual programming and instantly experience the results in AR. Further, we demonstrate multiple application scenarios enabled by GesturAR, such as interactive virtual objects, robots, and avatars, room-level interactive AR spaces, embodied AR presentations, etc. Finally, we evaluate the performance and usability of GesturAR through a user study.
SP  - 552
EP  - 567
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474769
ER  - 

TY  - NA
AU  - Qian, Jing; Zhou, Tongyu; Young-Ng, Meredith; Ma, Jiaju; Cheung, Angel; Li, Xiangyu; Gonsher, Ian; Huang, Jeff
TI  - Conference on Designing Interactive Systems - Portalware: Exploring Free-Hand AR Drawing with a Dual-Display Smartphone-Wearable Paradigm
PY  - 2021
AB  - Free-hand interaction enables users to directly create artistic augmented reality content using a smartphone, but lacks natural spatial depth information due to the small 2D display’s limited visual feedback. Through an autobiographical design process, three authors explored free-hand drawing over a total of 14 weeks. During this process, they expanded the design space from a single-display smartphone format to a dual-display smartphone-wearable format (Portalware). This new configuration extends the virtual content from a smartphone to a wearable display and enables multi-display free-hand interactions. The authors documented experiences where 1) the display extends the smartphone’s canvas perceptually, allowing the authors to work beyond the smartphone screen view; 2) the additional perspective mitigates the difficulties of depth perception and improves the usability of direct free-hand manipulation; 3) the wearable use cases depend on the nature of the drawing, such as: replicating physical objects, “in-situ” mixed reality pieces, and multi-planar drawings.
SP  - 205
EP  - 219
JF  - Designing Interactive Systems Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3461778.3462098
ER  - 

TY  - NA
AU  - Park, Keunwoo; Lempert, Conrad; Abdullah, Muhammad; Katakura, Shohei; Shigeyama, Jotaro; Roumen, Thijs; Baudisch, Patrick
TI  - FoolProofJoint: Reducing Assembly Errors of Laser Cut 3D Models by Means of Custom Joint Patterns
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501919
ER  - 

TY  - NA
AU  - Arabi, Abul Al; Li, Jiahao; Chen, Xiang 'Anthony; Kim, Jeeeun
TI  - Mobiot: Augmenting Everyday Objects into Moving IoT Devices Using 3D Printed Attachments Generated by Demonstration
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517645
ER  - 

TY  - JOUR
AU  - Luo, Shijian; Cui, Zhitong; Gu, Jiancheng; Chen, Ting; Shen, Chengyi; Lu, Yang; Wang, Yanan; Hansen, Preben
TI  - RoamFab: A Design Tool for Reconfiguring Parameterized Mechanisms to 3D Models With Structural Optimization
PY  - 2022
AB  - NA
SP  - 1
EP  - 15
JF  - International Journal of Human–Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1080/10447318.2022.2102600
ER  - 

TY  - JOUR
AU  - Cabrera, Ángel Alexander; Ribeiro, Marco Tulio; Lee, Bongshin; DeLine, Rob; Perer, Adam; Drucker, Steven M.
TI  - What Did My AI Learn? How Data Scientists Make Sense of Model Behavior
PY  - 2022
AB  - <jats:p> Data scientists require rich mental models of how AI systems behave to effectively train, debug, and work with them. Despite the prevalence of AI analysis tools, there is no general theory describing how people make sense of what their models have learned. We frame this process as a form of sensemaking and derive a framework describing how data scientists develop mental models of AI behavior. To evaluate the framework, we show how existing AI analysis tools fit into this sensemaking process and use it to design <jats:sc>AIFinnity</jats:sc> , a system for analyzing image-and-text models. Lastly, we explored how data scientists use a tool developed with the framework through a think-aloud study with 10 data scientists tasked with using <jats:sc>AIFinnity</jats:sc> to pick an image captioning model. We found that <jats:sc>AIFinnity</jats:sc> ’s sensemaking workflow reflected participants’ mental processes and enabled them to discover and validate diverse AI behaviors. </jats:p>
SP  - NA
EP  - NA
JF  - ACM Transactions on Computer-Human Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3542921
ER  - 

TY  - JOUR
AU  - Brun, Pierre-Thomas
TI  - Fluid-Mediated Fabrication of Complex Assemblies.
PY  - 2022
AB  - This Perspective accounts for recent progress in the directed control of interfacial fluid flows harnessed to assemble architected soft materials. We are focusing on the paradigmatic problem of free-surface flows in curable elastomers. These elastomers are initially liquid and cure into elastic solids whose shape is imparted by concomitant and competing phenomena: flow-induced deformations and curing. Particular attention is given to the role of capillary forces in these systems. Originating from the cohesive nature of liquids and thus favoring smooth interfaces, capillary forces can also promote the destabilization of interfaces, e.g., into droplets. In turn, such mechanical instabilities tend to grow into regular patterns, e.g., forming hexagonal lattices. We discuss how the universality, robustness, and ultimate regularity of these out-of-equilibrium processes could serve as a basis for new fabrication paradigms, where instabilities are directed to generate target architected solids obtained without each element laid in place by direct mechanized intervention.
SP  - 2417
EP  - 2425
JF  - JACS Au
VL  - 2
IS  - 11
PB  - 
DO  - 10.1021/jacsau.2c00427
ER  - 

TY  - NA
AU  - Ko, Hyung-Kwon; An, Subin; Park, Gwanmo; Kim, Seung Kwon; Kim, Daesik; Kim, Bohyoung; Jo, Jaemin; Seo, Jinwook
TI  - We-toon: A Communication Support System between Writers and Artists in Collaborative Webtoon Sketch Revision
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545612
ER  - 

TY  - NA
AU  - Subbaraman, Blair; Peek, Nadya
TI  - p5.fab: Direct Control of Digital Fabrication Machines from a Creative Coding Environment
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Designing Interactive Systems Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532106.3533496
ER  - 

TY  - JOUR
AU  - Lee, Lik Hang; Braud, Tristan; Hosio, Simo; Hui, Pan
TI  - Towards Augmented Reality Driven Human-City Interaction: Current Research on Mobile Headsets and Future Challenges
PY  - 2021
AB  - Interaction design for Augmented Reality (AR) is gaining attention from both academia and industry. This survey discusses 260 articles (68.8% of articles published between 2015–2019) to review the field of human interaction in connected cities with emphasis on augmented reality-driven interaction. We provide an overview of Human-City Interaction and related technological approaches, followed by reviewing the latest trends of information visualization, constrained interfaces, and embodied interaction for AR headsets. We highlight under-explored issues in interface design and input techniques that warrant further research and conjecture that AR with complementary Conversational User Interfaces (CUIs) is a crucial enabler for ubiquitous interaction with immersive systems in smart cities. Our work helps researchers understand the current potential and future needs of AR in Human-City Interaction.
SP  - 1
EP  - 38
JF  - ACM Computing Surveys
VL  - 54
IS  - 8
PB  - 
DO  - 10.1145/3467963
ER  - 

TY  - NA
AU  - Chen, Yilan; Kwan, Kin Chung; Wei, Li-Yi; Fu, Hongbo
TI  - Autocomplete Repetitive Stroking with Image Guidance
PY  - 2021
AB  - Image-guided drawing can compensate for the lack of skills but often requires a significant number of repetitive strokes to create textures. Existing automatic stroke synthesis methods are usually limited to predefined styles or require indirect manipulation that may break the spontaneous flow of drawing. We present a method to autocomplete repetitive short strokes during users' normal drawing process. Users can draw over a reference image as usual. At the same time, our system silently analyzes the input strokes and the reference to infer strokes that follow users' input style when certain repetition is detected. Users can accept, modify, or ignore the system predictions and continue drawing, thus maintaining the fluid control of drawing. Our key idea is to jointly analyze image regions and operation history for detecting and predicting repetitions. The proposed system can effectively reduce users' workload in drawing repetitive short strokes and facilitates users in creating results with rich patterns.
SP  - NA
EP  - NA
JF  - arXiv: Graphics
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Misztal, Sebastian; Carbonell, Guillermo; Schild, Jonas
TI  - Experiencing Age-Related Movement Impairment Through Visual Delegation in VR Can Substitute Haptic Impairments of an Age Simulation Suit
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE 10th International Conference on Serious Games and Applications for Health(SeGAH)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/segah54908.2022.9978590
ER  - 

TY  - JOUR
AU  - Kim, Joonho; Singh, Karan
TI  - Optimizing UI layouts for deformable face-rig manipulation
PY  - 2021
AB  - NA
SP  - 1
EP  - 12
JF  - ACM Transactions on Graphics
VL  - 40
IS  - 4
PB  - 
DO  - 10.1145/3476576.3476759
ER  - 

TY  - NA
AU  - Kiaghadi, Ali; Huang, Jin; Homayounfar, Seyedeh Zohreh; Andrew, Trisha; Ganesan, Deepak
TI  - FabToys
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3498361.3538931
ER  - 

TY  - NA
AU  - Jain, Naman; Vaidyanath, Skanda; Iyer, Arun; Natarajan, Nagarajan; Parthasarathy, Suresh; Rajamani, Sriram; Sharma, Rahul
TI  - Jigsaw
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 44th International Conference on Software Engineering
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3510003.3510203
ER  - 

TY  - NA
AU  - Lyu, Zhuoyue; Yang, Jackie (Junrui); Lam, Monica S.; Landay, James A.
TI  - HomeView: Automatically Building Smart Home Digital Twins With Augmented Reality Headsets
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The Adjunct Publication of the 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526114.3558709
ER  - 

TY  - NA
AU  - Verano Merino, Mauricio; Sáenz, Juan Pablo; Díaz Castillo, Ana María
TI  - Suppose You Had Blocks within a Notebook
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 1st ACM SIGPLAN International Workshop on Programming Abstractions and Interactive Notations, Tools, and Environments
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3563836.3568728
ER  - 

TY  - JOUR
AU  - Miyazaki, Masashi; Komuro, Takashi
TI  - AR Peephole Interface: Extending the workspace of a mobile device using real-space information
PY  - 2021
AB  - NA
SP  - 101489
EP  - NA
JF  - Pervasive and Mobile Computing
VL  - 78
IS  - NA
PB  - 
DO  - 10.1016/j.pmcj.2021.101489
ER  - 

TY  - NA
AU  - Dogan, Mustafa Doga; Colon, Steven Vidal Acevedo; Sinha, Varnika; Akşit, Kaan; Mueller, Stefanie
TI  - UIST - SensiCut: Material-Aware Laser Cutting Using Speckle Sensing and Deep Learning
PY  - 2021
AB  - Laser cutter users face difficulties distinguishing between visually similar materials. This can lead to problems, such as using the wrong power/speed settings or accidentally cutting hazardous materials. To support users, we present SensiCut, an integrated material sensing platform for laser cutters. SensiCut enables material awareness beyond what users are able to see and reliably differentiates among similar-looking types. It achieves this by detecting materials’ surface structures using speckle sensing and deep learning. SensiCut consists of a compact hardware add-on for laser cutters and a user interface that integrates material sensing into the laser cutting workflow. In addition to improving the traditional workflow and its safety1, SensiCut enables new applications, such as automatically partitioning designs when engraving on multi-material objects or adjusting their geometry based on the kerf of the identified material. We evaluate SensiCut’s accuracy for different types of materials under different sheet orientations and illumination conditions.
SP  - 24
EP  - 38
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474733
ER  - 

TY  - NA
AU  - Shen, Vivian; Harrison, Chris
TI  - Pull Gestures with Coordinated Graphics on Dual-Screen Devices
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3536221.3556620
ER  - 

TY  - JOUR
AU  - Cascaval, D.; Shalah, M.; Quinn, P.; Bodik, R.; Agrawala, M.; Schulz, A.
TI  - Differentiable 3D CAD Programs for Bidirectional Editing
PY  - 2022
AB  - NA
SP  - 309
EP  - 323
JF  - Computer Graphics Forum
VL  - 41
IS  - 2
PB  - 
DO  - 10.1111/cgf.14476
ER  - 

TY  - JOUR
AU  - Cambronero, José; Gulwani, Sumit; Le, Vu; Perelman, Daniel; Radhakrishna, Arjun; Simon, Clint; Tiwari, Ashish
TI  - FlashFill++: Scaling Programming by Example by Cutting to the Chase
PY  - 2023
AB  - <jats:p>Programming-by-Examples (PBE) involves synthesizing an "intended program" from a small set of user-provided input-output examples. A key PBE strategy has been to restrict the search to a carefully designed small domain-specific language (DSL) with "effectively-invertible" (EI) operators at the top and "effectively-enumerable" (EE) operators at the bottom. This facilitates an effective combination of top-down synthesis strategy (which backpropagates outputs over various paths in the DSL using inverse functions) with a bottom-up synthesis strategy (which propagates inputs over various paths in the DSL). We address the problem of scaling synthesis to large DSLs with several non-EI/EE operators. This is motivated by the need to support a richer class of transformations and the need for readable code generation. We propose a novel solution strategy that relies on propagating fewer values and over fewer paths.</jats:p> <jats:p>Our first key idea is that of "cut functions" that prune the set of values being propagated by using knowledge of the sub-DSL on the other side. Cuts can be designed to preserve completeness of synthesis; however, DSL designers may use incomplete cuts to have finer control over the kind of programs synthesized. In either case, cuts make search feasible for non-EI/EE operators and efficient for deep DSLs. Our second key idea is that of "guarded DSLs" that allow a precedence on DSL operators, which dynamically controls exploration of various paths in the DSL. This makes search efficient over grammars with large fanouts without losing recall. It also makes ranking simpler yet more effective in learning an intended program from very few examples. Both cuts and precedence provide a mechanism to the DSL designer to restrict search to a reasonable, and possibly incomplete, space of programs.</jats:p> <jats:p>Using cuts and gDSLs, we have built FlashFill++, an industrial-strength PBE engine for performing rich string transformations, including datetime and number manipulations. The FlashFill++ gDSL is designed to enable readable code generation in different target languages including Excel's formula language, PowerFx, and Python. We show FlashFill++ is more expressive, more performant, and generates better quality code than comparable existing PBE systems. FlashFill++ is being deployed in several mass-market products ranging from spreadsheet software to notebooks and business intelligence applications, each with millions of users.</jats:p>
SP  - 952
EP  - 981
JF  - Proceedings of the ACM on Programming Languages
VL  - 7
IS  - POPL
PB  - 
DO  - 10.1145/3571226
ER  - 

TY  - JOUR
AU  - Michel, Élie; Boubekeur, Tamy
TI  - DAG amendment for inverse control of parametric shapes
PY  - 2021
AB  - NA
SP  - 1
EP  - 14
JF  - ACM Transactions on Graphics
VL  - 40
IS  - 4
PB  - 
DO  - 10.1145/3476576.3476760
ER  - 

TY  - NA
AU  - Hoshikawa, Yukai; Fujita, Kazuyuki; Takashima, Kazuki; Fjeld, Morten; Kitamura, Yoshifumi
TI  - RedirectedDoors: Redirection While Opening Doors in Virtual Reality
PY  - 2022
AB  - We propose RedirectedDoors, a novel space-efficient technique for redirection in VR focused on door-opening behavior. This technique manipulates the user&#x2019;s walking direction by rotating the entire virtual environment (VE) at a certain angular ratio of the door being opened. This ratio is called door rotation gain. At the same time, the virtual door&#x2019;s position is kept unmanipulated so that a realistic door-opening user experience can be ensured. We designed and implemented the rotational manipulation algorithm and two types of door-opening interfaces; with and without a doorknob-type passive haptic prop. We then conducted a user study (N = 12) to investigate redirection performance and user feedback as we examined three independent variables: door rotation gain, door-opening interface, and door-opening direction (push/pull). From the results, the estimated detection thresholds generally showed a higher space efficiency of redirection with our technique. Our results also showed that providing the haptic feedback led to a higher noticeability of redirection, but at the same time supported a higher subjective sense of realism and less discomfort. Following our results, we discuss which combinations of gain and door-opening direction can jointly provide lower noticeability and higher acceptability.
SP  - NA
EP  - NA
JF  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr51125.2022.00066
ER  - 

TY  - NA
AU  - Fender, Andreas Rene; Holz, Christian
TI  - Causality-preserving Asynchronous Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501836
ER  - 

TY  - CHAP
AU  - Suzuki, Ippei; Yamamoto, Kenta; Shitara, Akihisa; Hyakuta, Ryosuke; Iijima, Ryo; Ochiai, Yoichi
TI  - See-Through Captions in a Museum Guided Tour: Exploring Museum Guided Tour for Deaf and Hard-of-Hearing People with Real-Time Captioning on Transparent Display
PY  - 2022
AB  - <jats:title>Abstract</jats:title><jats:p>Access to audible information for deaf and hard-of-hearing (DHH) people is an essential component as we move towards a diverse society. Real-time captioning is a technology with great potential to help the lives of DHH people, and various applications utilizing mobile devices have been developed. These technologies can improve the daily lives of DHH people and can considerably change the value of audio content provided in public facilities such as museums. We developed a real-time captioning system called See-Through Captions that displays subtitles on a transparent display and conducted a demonstration experiment to apply this system to a guided tour in a museum. Eleven DHH people participated in this demonstration experiment, and through questionnaires and interviews, we explored the possibility of utilizing the transparent subtitle system in a guided tour at the museum.</jats:p>
SP  - 542
EP  - 552
JF  - Lecture Notes in Computer Science
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-08648-9_64
ER  - 

TY  - NA
AU  - Lee, Lik Hang; Braud, Tristan; Hosio, Simo; Hui, Pan
TI  - Towards Augmented Reality-driven Human-City Interaction: Current Research and Future Challenges.
PY  - 2020
AB  - Interaction design for Augmented Reality (AR) is gaining increasing attention from both academia and industry. This survey discusses 205 articles (75% of articles published between 2015 - 2019) to review the field of human interaction in connected cities with emphasis on augmented reality-driven interaction. We provide an overview of Human-City Interaction and related technological approaches, followed by a review of the latest trends of information visualization, constrained interfaces, and embodied interaction for AR headsets. We highlight under-explored issues in interface design and input techniques that warrant further research, and conjecture that AR with complementary Conversational User Interfaces (CUIs) is a key enabler for ubiquitous interaction with immersive systems in smart cities. Our work helps researchers understand the current potential and future needs of AR in Human-City Interaction.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Tchernichovski, Ofer; Frey, Seth; Jacoby, Nori; Conley, Dalton
TI  - Experimenting With Online Governance
PY  - 2021
AB  - To solve the problems they face, online communities adopt comprehensive governance methods including committees, boards, juries, and even more complex institutional logics. Helping these kinds of communities succeed will require categorizing best practices and creating toolboxes that fit the needs of specific communities. Beyond such applied uses, there is also a potential for an institutional logic itself to evolve, taking advantage of feedback provided by the fast pace and large ecosystem of online communication. Here we outline an experimental strategy aiming at guiding and facilitating such an evolution. We first review the impact of recent technologies for efficiently running massive online experiments used for studying collective action. Research in this vein includes attempts to understand how behavior spreads, how cooperation evolves, and how the wisdom of the crowd can be improved. We then present the utility of virtual-world experiments with governance for improving the utility of social feedback. Such experiments can be used for improving community rating systems and monitoring (dashboard) systems. Finally, we present a framework for constructing large-scale experiments entirely in virtual worlds, aimed at capturing the complexity of governance dynamics, to empirically test outcomes of manipulating institutional logic.
SP  - NA
EP  - NA
JF  - Frontiers in Human Dynamics
VL  - 3
IS  - NA
PB  - 
DO  - 10.3389/fhumd.2021.629285
ER  - 

TY  - NA
AU  - Bäuerle, Alex; Cabrera, Ángel Alexander; Hohman, Fred; Maher, Megan; Koski, David; Suau, Xavier; Barik, Titus; Moritz, Dominik
TI  - Symphony: Composing Interactive Interfaces for Machine Learning
PY  - 2022
AB  - Interfaces for machine learning (ML), information and visualizations about models or data, can help practitioners build robust and responsible ML systems. Despite their benefits, recent studies of ML teams and our interviews with practitioners (n=9) showed that ML interfaces have limited adoption in practice. While existing ML interfaces are effective for specific tasks, they are not designed to be reused, explored, and shared by multiple stakeholders in cross-functional teams. To enable analysis and communication between different ML practitioners, we designed and implemented Symphony, a framework for composing interactive ML interfaces with task-specific, data-driven components that can be used across platforms such as computational notebooks and web dashboards. We developed Symphony through participatory design sessions with 10 teams (n=31), and discuss our findings from deploying Symphony to 3 production ML projects at Apple. Symphony helped ML practitioners discover previously unknown issues like data duplicates and blind spots in models while enabling them to share insights with other stakeholders.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502102
ER  - 

TY  - JOUR
AU  - Balaji, Ananta Narayanan; Kimber, Clayton; Li, David; Wu, Shengzhi; Du, Ruofei; Kim, David
TI  - RetroSphere
PY  - 2022
AB  - <jats:p>Advanced AR/VR headsets often have a dedicated depth sensor or multiple cameras, high processing power, and a high-capacity battery to track hands or controllers. However, these approaches are not compatible with the small form factor and limited thermal capacity of lightweight AR devices. In this paper, we present RetroSphere, a self-contained 6 degree of freedom (6DoF) controller tracker that can be integrated with almost any device. RetroSphere tracks a passive controller with just 3 retroreflective spheres using a stereo pair of mass-produced infrared blob trackers, each with its own infrared LED emitters. As the sphere is completely passive, no electronics or recharging is required. Each object tracking camera provides a tiny Arduino-compatible ESP32 microcontroller with the 2D position of the spheres. A lightweight stereo depth estimation algorithm that runs on the ESP32 performs 6DoF tracking of the passive controller. Also, RetroSphere provides an auto-calibration procedure to calibrate the stereo IR tracker setup. Our work builds upon Johnny Lee's Wii remote hacks and aims to enable a community of researchers, designers, and makers to use 3D input in their projects with affordable off-the-shelf components. RetroSphere achieves a tracking accuracy of about 96.5% with errors as low as ~3.5 cm over a 100 cm tracking range, validated with ground truth 3D data obtained using a LIDAR camera while consuming around 400 mW. We provide implementation details, evaluate the accuracy of our system, and demonstrate example applications, such as mobile AR drawing, 3D measurement, etc. with our Retrosphere-enabled AR glass prototype.</jats:p>
SP  - 1
EP  - 36
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 4
PB  - 
DO  - 10.1145/3569479
ER  - 

TY  - NA
AU  - Muehlbradt, Annika; Whiting, Gregory; Kane, Shaun; Devendorf, Laura
TI  - Knitting Access: Exploring Stateful Textiles with People with Disabilities
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Designing Interactive Systems Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532106.3533551
ER  - 

TY  - NA
AU  - Wu, Te-Yen; Yang, Xing-Dong
TI  - iWood: Makeable Vibration Sensor for Interactive Plywood
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545640
ER  - 

TY  - JOUR
AU  - Li, Bosheng; Kałużny, Jacek; Klein, Jonathan; Michels, Dominik L.; Pałubicki, Wojtek; Benes, Bedrich; Pirk, Sören
TI  - Learning to reconstruct botanical trees from single images
PY  - 2021
AB  - <jats:p>We introduce a novel method for reconstructing the 3D geometry of botanical trees from single photographs. Faithfully reconstructing a tree from single-view sensor data is a challenging and open problem because many possible 3D trees exist that fit the tree's shape observed from a single view. We address this challenge by defining a reconstruction pipeline based on three neural networks. The networks simultaneously mask out trees in input photographs, identify a tree's species, and obtain its 3D radial bounding volume - our novel 3D representation for botanical trees. Radial bounding volumes (RBV) are used to orchestrate a procedural model primed on learned parameters to grow a tree that matches the main branching structure and the overall shape of the captured tree. While the RBV allows us to faithfully reconstruct the main branching structure, we use the procedural model's morphological constraints to generate realistic branching for the tree crown. This constraints the number of solutions of tree models for a given photograph of a tree. We show that our method reconstructs various tree species even when the trees are captured in front of complex backgrounds. Moreover, although our neural networks have been trained on synthetic data with data augmentation, we show that our pipeline performs well for real tree photographs. We evaluate the reconstructed geometries with several metrics, including leaf area index and maximum radial tree distances.</jats:p>
SP  - 1
EP  - 15
JF  - ACM Transactions on Graphics
VL  - 40
IS  - 6
PB  - 
DO  - 10.1145/3478513.3480525
ER  - 

TY  - JOUR
AU  - Butt, Javaid; Bhaskar, Raghunath; Mohaghegh, Vahaj
TI  - Investigating the effects of extrusion temperatures and material extrusion rates on FFF-printed thermoplastics
PY  - 2021
AB  - NA
SP  - 2679
EP  - 2699
JF  - The International Journal of Advanced Manufacturing Technology
VL  - 117
IS  - 9-10
PB  - 
DO  - 10.1007/s00170-021-07850-5
ER  - 

TY  - NA
AU  - Wang, Qianwen; Chen, Zhutian; Wang, Yong; Qu, Huamin
TI  - A Survey on ML4VIS: Applying MachineLearning Advances to Data Visualization.
PY  - 2021
AB  - Inspired by the great success of machine learning (ML), researchers have applied ML techniques to visualizations to achieve a better design, development, and evaluation of visualizations. This branch of studies, known as ML4VIS, is gaining increasing research attention in recent years. To successfully adapt ML techniques for visualizations, a structured understanding of the integration of ML4VISis needed. In this paper, we systematically survey 88 ML4VIS studies, aiming to answer two motivating questions:what visualization processes can be assisted by MLandhow ML techniques can be used to solve visualization problemsThis survey reveals seven main processes where the employment of ML techniques can benefit visualizations:Data Processing4VIS, Data-VIS Mapping, InsightCommunication, Style Imitation, VIS Interaction, VIS Reading, and User Profiling. The seven processes are related to existing visualization theoretical models in an ML4VIS pipeline, aiming to illuminate the role of ML-assisted visualization in general visualizations.Meanwhile, the seven processes are mapped into main learning tasks in ML to align the capabilities of ML with the needs in visualization. Current practices and future opportunities of ML4VIS are discussed in the context of the ML4VIS pipeline and the ML-VIS mapping. While more studies are still needed in the area of ML4VIS, we hope this paper can provide a stepping-stone for future exploration. A web-based interactive browser of this survey is available at https://ml4vis.github.io.
SP  - 1
EP  - 1
JF  - IEEE Transactions on Visualization and Computer Graphics
VL  - NA
IS  - 01
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Smirnov, Oleg; Ketkar, Ameya; Bryksin, Timofey; Tsantalis, Nikolaos; Dig, Danny
TI  - IntelliTC
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3510454.3516851
ER  - 

TY  - NA
AU  - He, Zhenyi; Lutteroth, Christof; Perlin, Ken
TI  - TapGazer: Text Entry with Finger Tapping and Gaze-directed Word Selection
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501838
ER  - 

TY  - NA
AU  - Makled, Elhassan; Weidner, Florian; Broll, Wolfgang
TI  - Investigating User Embodiment of Inverse-Kinematic Avatars in Smartphone Augmented Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar55827.2022.00084
ER  - 

TY  - NA
AU  - Chidambaram, Subramanian; Reddy, Sai Swarup; Rumple, Matthew; Ipsita, Ananya; Villanueva, Ana; Redick, Thomas; Stuerzlinger, Wolfgang; Ramani, Karthik
TI  - EditAR: A Digital Twin Authoring Environment for Creation of AR/VR and Video Instructions from a Single Demonstration
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar55827.2022.00048
ER  - 

TY  - JOUR
AU  - Ma, Yan; Zhai, Shumin; Ramakrishnan, I. V.; Bi, Xiaojun
TI  - UIST - Modeling Touch Point Distribution with Rotational Dual Gaussian Model
PY  - 2021
AB  - Touch point distribution models are important tools for designing touchscreen interfaces. In this paper, we investigate how the finger movement direction affects the touch point distribution, and how to account for it in modeling. We propose the Rotational Dual Gaussian model, a refinement and generalization of the Dual Gaussian model, to account for the finger movement direction in predicting touch point distribution. In this model, the major axis of the prediction ellipse of the touch point distribution is along the finger movement direction, and the minor axis is perpendicular to the finger movement direction. We also propose using projected target width and height, in lieu of nominal target width and height to model touch point distribution. Evaluation on three empirical datasets shows that the new model reflects the observation that the touch point distribution is elongated along the finger movement direction, and outperforms the original Dual Gaussian Model in all prediction tests. Compared with the original Dual Gaussian model, the Rotational Dual Gaussian model reduces the RMSE of touch error rate prediction from 8.49% to 4.95%, and more accurately predicts the touch point distribution in target acquisition. Using the Rotational Dual Gaussian model can also improve the soft keyboard decoding accuracy on smartwatches.
SP  - 1197
EP  - 1209
JF  - Proceedings of the ACM Symposium on User Interface Software and Technology. ACM Symposium on User Interface Software and Technology
VL  - 2021
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474816
ER  - 

TY  - NA
AU  - Liu, Michael Xieyang; Kittur, Aniket; Myers, Brad A.
TI  - Crystalline: Lowering the Cost for Developers to Collect and Organize Information for Decision Making
PY  - 2022
AB  - Developers perform online sensemaking on a daily basis, such as researching and choosing libraries and APIs. Prior research has introduced tools that help developers capture information from various sources and organize it into structures useful for subsequent decision-making. However, it remains a laborious process for developers to manually identify and clip content, maintaining its provenance and synthesizing it with other content. In this work, we introduce a new system called Crystalline that attempts to automatically collect and organize information into tabular structures as the user searches and browses the web. It leverages natural language processing to automatically group similar criteria together to reduce clutter as well as passive behavioral signals such as mouse movement and dwell time to infer what information to collect and how to visualize and prioritize it. Our user study suggests that developers are able to create comparison tables about 20% faster with a 60% reduction in operational cost without sacrificing the quality of the tables.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501968
ER  - 

TY  - NA
AU  - Tsai, Hsin-Ruey; Liao, Yu-So; Tsai, Chieh
TI  - ImpactVest: Rendering Spatio-Temporal Multilevel Impact Force Feedback on Body in VR
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501971
ER  - 

TY  - NA
AU  - Qian, Xun; He, Fengming; Hu, Xiyun; Wang, Tianyi; Ramani, Karthik
TI  - ARnnotate: An Augmented Reality Interface for Collecting Custom Dataset of 3D Hand-Object Interaction Pose Estimation
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545663
ER  - 

TY  - NA
AU  - Ham, Auejin; Lim, Junsu; Kim, Sunjun
TI  - UIST - Do We Need a Faster Mouse? Empirical Evaluation of Asynchronicity-Induced Jitter
PY  - 2021
AB  - In gaming, accurately rendering input signals on a display is crucial, both spatially and temporally. However, the asynchronicity between the input and output signal frequencies results in unstable responses called jitter. A recent research modeled this jitter mathematically [2]; however, the effect of jitter on human performance is unknown. In this study, we investigated the empirical effect of asynchronicity-induced jitter using a state-of-the-art high-performance mouse and monitor device. In the first part, perceptual user experience under different jitter levels was examined using the ISO 4120:2004 triangle test protocol, and a jitter of over 0.3 ms could be perceived by sensitive subjects. In the second part, we measured the pointing task performance for different jitter levels using the ISO 9241-9 (i.e., Fitts’ law) test, and found that the pointing performance was unaffected up to a jitter of 1 ms. Finally, we recommended display and mouse combinations based on our results, which indicated the need for a higher mouse polling rate than that of the current standard 1000-Hz USB mouse.
SP  - 743
EP  - 753
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474783
ER  - 

TY  - JOUR
AU  - Usuba, Hiroki; Yamanaka, Shota; Sato, Junichi; Miyashita, Homei
TI  - Predicting Touch Accuracy for Rectangular Targets by Using One-Dimensional Task Results
PY  - 2022
AB  - <jats:p>We propose a method that predicts the success rate in pointing to 2D rectangular targets by using 1D vertical-bar and horizontal-bar task results. The method can predict the success rates for more practical situations under fewer experimental conditions. This shortens the duration of experiments, thus saving costs for researchers and practitioners. We verified the method through two experiments: laboratory-based and crowdsourced ones. In the laboratory-based experiment, we found that using 1D task results to predict the success rate for 2D targets slightly decreases the prediction accuracy. In the crowdsourced experiment, this method scored better than using 2D task results. Thus, we recommend that researchers use the method properly depending on the situation.</jats:p>
SP  - 525
EP  - 537
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - ISS
PB  - 
DO  - 10.1145/3567732
ER  - 

TY  - NA
AU  - Ko, Yu-Jung; Zhao, Hang; Ramakrishnan, Iv; Zhai, Shumin; Bi, Xiaojun
TI  - Issues Related to Using Finger-Fitts law to Model One-Dimensional Touch Pointing Tasks
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - The Ninth International Symposium of Chinese CHI
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490355.3490360
ER  - 

TY  - CHAP
AU  - Nijholt, Anton
TI  - Capturing Obstructed Nonverbal Cues in Augmented Reality Interactions: A Short Survey
PY  - 2022
AB  - AbstractWe present a short survey on recovering nonverbal communication cues that are hidden by head-mounted devices while interacting in augmented reality. The focus is on recovering facial expressions and gaze behavior by using various kinds of sensors that are attached to or integrated with these devices. The nonverbal cues can be made visible for other co-located or remote interactants on devices or avatars.KeywordsAugmented realityHead-mounted devicesNonverbal interactionFacial expressions
SP  - 1
EP  - 9
JF  - Proceedings of International Conference on Industrial Instrumentation and Control
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-981-16-7011-4_1
ER  - 

TY  - NA
AU  - Lee, Bokyung; Lee, Michael S.; Mogk, Jeremy P.M.; Goldstein, Rhys; Bibliowicz, Jacobo; Tessier, Alexander
TI  - Conference on Designing Interactive Systems - Designing a Multi-Agent Occupant Simulation System to Support Facility Planning and Analysis for COVID-19
PY  - 2021
AB  - The COVID-19 pandemic changed our lives, forcing us to reconsider our built environment, architectural designs, and even behaviours. Multiple stakeholders, including designers, building facility managers, and policy makers, are making decisions to reduce SARS-CoV-2 virus transmission and make our environment safer; however, systems to effectively and interactively evaluate virus transmission in physical spaces are lacking. To help fill this gap, we propose OccSim, a system that automatically generates occupancy behaviours in a 3D model of a building and helps users analyze the potential effect of virus transmission from a large-scale and longitudinal perspective. Our participatory evaluation with four groups of stakeholders revealed that OccSim could enhance their decision making processes by identifying specific risks of virus transmission in advance, and illuminating how each risk relates to complex human-building interactions. We reflect on our design and discuss OccSim’s potential implications in the domains of ‘design evaluation,’ ‘generative design,’ and ‘digital twins.’
SP  - 15
EP  - 30
JF  - Designing Interactive Systems Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3461778.3462030
ER  - 

TY  - NA
AU  - Lee, Chi-Jung; Tsai, Hsin-Ruey; Chen, Bing-Yu
TI  - CHI - HairTouch: Providing Stiffness, Roughness and Surface Height Differences Using Reconfigurable Brush Hairs on a VR Controller
PY  - 2021
AB  - Tactile feedback is widely used to enhance realism in virtual reality (VR). When touching virtual objects, stiffness and roughness are common and obvious factors perceived by the users. Furthermore, when touching a surface with complicated surface structure, differences from not only stiffness and roughness but also surface height are crucial. To integrate these factors, we propose a pin-based handheld device, HairTouch, to provide stiffness differences, roughness differences, surface height differences and their combinations. HairTouch consists of two pins for the two finger segments close to the index fingertip, respectively. By controlling brush hairs’ length and bending direction to change the hairs’ elasticity and hair tip direction, each pin renders various stiffness and roughness, respectively. By further independently controlling the hairs’ configuration and pins’ height, versatile stiffness, roughness and surface height differences are achieved. We conducted a perception study to realize users’ distinguishability of stiffness and roughness on each of the segments. Based on the results, we performed a VR experience study to verify that the tactile feedback from HairTouch enhances VR realism.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445285
ER  - 

TY  - NA
AU  - Sun, Lingyun; Yang, Yue; Chen, Yu; Li, Jiaji; Luo, Danli; Liu, Haolin; Yao, Lining; Tao, Ye; Wang, Guanyun
TI  - CHI - ShrinCage: 4D Printing Accessories that Self-Adapt
PY  - 2021
AB  - 3D printing technology makes Do-It-Yourself and reforming everyday objects a reality. However, designing and fabricating attachments that can seamlessly adapt existing objects to extended functionality is a laborious process, which requires accurate measuring, modeling, manufacturing, and assembly. This paper presents ShrinCage, a 4D printing system that allows novices to easily create shrinkable adaptations to fit and fasten existing objects. Specifically, the design tool presented in this work aid in the design of attachment that adapts to irregular morphologies, which accommodates the variations in measurements and fabrication, subsequently simplifying the modeling and assembly processes. We further conduct mechanical tests and user studies to evaluate the availability and feasibility of this method. Numerous application examples created by ShrinCage prove that it can be adopted by aesthetic modification, assistive technology, repair, upcycling, and augmented 3D printing.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445220
ER  - 

TY  - NA
AU  - Wu, Yifan; Chang, Remco; Hellerstein, Joseph M.; Satyanarayan, Arvind; Wu, Eugene
TI  - DIEL: Interactive Visualization Beyond the Here and Now
PY  - 2019
AB  - Interactive visualization design and research have primarily focused on local data and synchronous events. However, for more complex use cases---e.g., remote database access and streaming data sources---developers must grapple with distributed data and asynchronous events. Currently, constructing these use cases is difficult and time-consuming; developers are forced to operationally program low-level details like asynchronous database querying and reactive event handling. This approach is in stark contrast to modern methods for browser-based interactive visualization, which feature high-level declarative specifications. In response, we present DIEL, a declarative framework that supports asynchronous events over distributed data. Like many declarative visualization languages, DIEL developers need only specify what data they want, rather than procedural steps for how to assemble it; uniquely, DIEL models asynchronous events (e.g., user interactions or server responses) as streams of data that are captured in event logs. To specify the state of a user interface at any time, developers author declarative queries over the data and event logs; DIEL compiles and optimizes a corresponding dataflow graph, and synthesizes necessary low-level distributed systems details. We demonstrate DIEL's performance and expressivity through ex-ample interactive visualizations that make diverse use of remote data and coordination of asynchronous events. We further evaluate DIEL's usability using the Cognitive Dimensions of Notations framework, revealing wins such as ease of change, and compromises such as premature commitments.
SP  - NA
EP  - NA
JF  - arXiv: Databases
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Maheshwari, Aditi; Kumar Aggarwal, Abhay; Danielescu, Andreea
TI  - Designing Tools and Interfaces for Ecological Restoration: An Investigation into the Opportunities and Constraints for Technological Interventions
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517664
ER  - 

TY  - NA
AU  - Chen, Zhutian; Xia, Haijun
TI  - CrossData: Leveraging Text-Data Connections for Authoring Data Documents
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517485
ER  - 

TY  - NA
AU  - Gonzalez, Eric J; Chase, Elyse D. Z.; Kotipalli, Pramod; Follmer, Sean
TI  - A Model Predictive Control Approach for Reach Redirection in Virtual Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501907
ER  - 

TY  - CONF
AU  - Chen, Chen; Johnson, Janet G.; Charles, Kemeberly; Lee, Alice; Lifset, Ella T.; Hogarth, Michael; Moore, Alison A.; Farcas, Emilia; Weibel, Nadir
TI  - ASSETS - Understanding Barriers and Design Opportunities to Improve Healthcare and QOL for Older Adults through Voice Assistants
PY  - 2021
AB  - Voice-based Intelligent Virtual Assistants (IVAs) promise to improve healthcare management and Quality of Life (QOL) by introducing the paradigm of hands-free and eye-free interactions. However, there has been little understanding regarding the challenges for designing such systems for older adults, especially when it comes to healthcare related tasks. To tackle this, we consider the processes of care delivery and QOL enhancements for older adults as a collaborative task between patients and providers. By interviewing 16 older adults living independently or semi–independently and 5 providers, we identified 12 barriers that older adults might encounter during daily routine and while managing health. We ultimately highlighted key design challenges and opportunities that might be introduced when integrating voice-based IVAs into the life of older adults. Our work will benefit practitioners who study and attempt to create full-fledged IVA-powered smart devices to deliver better care and support an increased QOL for aging populations.
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Yuan, Ye; Riche, Nathalie; Marquardt, Nicolai; Nicholas, Molly Jane; Seyed, Teddy; Romat, Hugo; Lee, Bongshin; Pahud, Michel; Goldstein, Jonathan; Vishkaie, Rojin; Holz, Christian; Hinckley, Ken
TI  - Understanding Multi-Device Usage Patterns: Physical Device Configurations and Fragmented Workflows
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517702
ER  - 

TY  - NA
AU  - Guo, Philip J.
TI  - UIST - Ten Million Users and Ten Years Later: Python Tutor’s Design Guidelines for Building Scalable and Sustainable Research Software in Academia
PY  - 2021
AB  - Research software is often built as prototypes that never get widespread usage and are left unmaintained after a few papers get published. To counteract this trend, we propose a method for building research software with scale and sustainability in mind so that it can organically grow a large userbase and enable longer-term research. To illustrate this method, we present the design and implementation of Python Tutor (pythontutor.com), a code visualization tool that is, to our knowledge, one of the most widely-used pieces of research software developed within a university lab. Over the past decade, it has been used by over ten million people in over 180 countries. It has also contributed to 55 publications from 35 research groups in 13 countries. We distilled lessons from working on Python Tutor into three sets of design guidelines: 1) user experience design for scale and sustainability, 2) software architecture design for long-term sustainability, and 3) designing a sustainable software development workflow within academia. These guidelines can enable a student to create long-lasting software that reaches many users and facilitates research from many independent groups.
SP  - 1235
EP  - 1251
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474819
ER  - 

TY  - NA
AU  - Shrestha, Nischal; Barik, Titus; Parnin, Chris
TI  - UIST - Unravel: A Fluent Code Explorer for Data Wrangling
PY  - 2021
AB  - Data scientists have adopted a popular design pattern in programming called the fluent interface for composing data wrangling code. The fluent interface works by combining multiple transformations on a data table—or dataframes—with a single chain of expressions, which produces an output. Although fluent code promotes legibility, the intermediate dataframes are lost, forcing data scientists to unravel the chain through tedious code edits and re-execution. Existing tools for data scientists do not allow easy exploration or support understanding of fluent code. To address this gap, we designed a tool called Unravel that enables structural edits via drag-and-drop and toggle switch interactions to help data scientists explore and understand fluent code. Data scientists can apply simple structural edits via drag-and-drop and toggle switch interactions to reorder and (un)comment lines. To help data scientists understand fluent code, Unravel provides function summaries and always-on visualizations highlighting important changes to a dataframe. We discuss the design motivations behind Unravel and how it helps understand and explore fluent code. In a first-use study with 14 data scientists, we found that Unravel facilitated diverse activities such as validating assumptions about the code or data, exploring alternatives, and revealing function behavior.
SP  - 198
EP  - 207
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474744
ER  - 

TY  - JOUR
AU  - Fang, Wei; Hong, Jianhao
TI  - Bare-hand gesture occlusion-aware interactive augmented reality assembly
PY  - 2022
AB  - NA
SP  - 169
EP  - 179
JF  - Journal of Manufacturing Systems
VL  - 65
IS  - NA
PB  - 
DO  - 10.1016/j.jmsy.2022.09.009
ER  - 

TY  - BOOK
AU  - Günther, Sebastian; Müller, Florian; Hübner, Felix; Mühlhäuser, Max; Matviienko, Andrii
TI  - EICS - ActuBoard: An Open Rapid Prototyping Platform to integrate Hardware Actuators in Remote Applications
PY  - 2021
AB  - Prototyping is an essential step in developing tangible experiences and novel devices, ranging from haptic feedback to wearables. However, prototyping of actuated devices nowadays often requires repetitive and time-consuming steps, such as wiring, soldering, and programming basic communication, before HCI researchers and designers can focus on their primary interest: designing interaction. In this paper, we present ActuBoard, a prototyping platform to support 1) quick assembly, 2) less preparation work, and 3) the inclusion of non-tech-savvy users. With ActuBoard, users are not required to create complex circuitry, write a single line of firmware, or implementing communication protocols. Acknowledging existing systems, our platform combines the flexibility of low-level microcontrollers and ease-of-use of abstracted tinker platforms to control actuators from separate applications. As further contribution, we highlight the technical specifications and published the ActuBoard platform as Open Source.
SP  - 70
EP  - 76
JF  - Companion of the 2021 ACM SIGCHI Symposium on Engineering Interactive Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3459926.3464757
ER  - 

TY  - NA
AU  - Druga, Stefania; Ball, Thomas; Ko, Amy
TI  - How families design and program games: a qualitative analysis of a 4-week online in-home study
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Interaction Design and Children
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3501712.3529724
ER  - 

TY  - NA
AU  - Michalkova, Dominika; Parra-Rodriguez, Mario; Moshfeghi, Yashar
TI  - Information Need Awareness
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3477495.3531999
ER  - 

TY  - JOUR
AU  - EPPerson, Will; Jung‐Lin Lee, Doris; Wang, Leijie; Agarwal, Kunal; Parameswaran, Aditya G.; Moritz, Dominik; Perer, Adam
TI  - Leveraging Analysis History for Improved In Situ Visualization Recommendation
PY  - 2022
AB  - NA
SP  - 145
EP  - 155
JF  - Computer Graphics Forum
VL  - 41
IS  - 3
PB  - 
DO  - 10.1111/cgf.14529
ER  - 

TY  - CHAP
AU  - Camps, Iris; Vekemans, Verindi; Visscher, Mirthe; Tomico, Oscar; Andersen, Kristina
TI  - Life on Mars: First Person Speculation in the (Imaginary) Everyday
PY  - 2022
AB  - NA
SP  - 2789
EP  - 2805
JF  - [ ] With Design: Reinventing Design Modes
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-981-19-4472-7_180
ER  - 

TY  - NA
AU  - Chen, Yan; Grossman, Tovi
TI  - UIST - Umitation: Retargeting UI Behavior Examples for Website Design
PY  - 2021
AB  - Interface designers often refer to UI behavior examples found in the wild (e.g., commercial websites) for reference or design inspiration. While past research has looked at retargeting interface and webpage design, limited work has explored the challenges in retargeting interactive visual behaviors. We introduce Umitation, a system that helps designers extract, edit, and adapt example front-end UI behaviors to target websites. Umitation can also help designers specify the desired behaviors and reconcile their intended interaction details with their existing UI. In a qualitative evaluation, we found evidence that Umitation helps participants extract and retarget dynamic front-end UI behavior examples quickly and expressively.
SP  - 922
EP  - 935
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474796
ER  - 

TY  - NA
AU  - Zhang, Baowen; Wang, Yangang; Deng, Xiaoming; Zhang, Yinda; Tan, Ping; Ma, Cuixia; Wang, Hongan
TI  - Interacting Two-Hand 3D Pose and Shape Reconstruction from Single Color Image
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - 2021 IEEE/CVF International Conference on Computer Vision (ICCV)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/iccv48922.2021.01116
ER  - 

TY  - NA
AU  - Zuo, Chaoji; Assadi, Sepehr; Deng, Dong
TI  - Spine: Scaling up Programming-by-Negative-Example for String Filtering and Transformation
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 2022 International Conference on Management of Data
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3514221.3517908
ER  - 

TY  - NA
AU  - Lavric, Traian; Bricard, Emmanuel; Preda, Marius; Zaharia, Titus
TI  - ATOFIS, an AR Training System for Manual Assembly: A Full Comparative Evaluation against Guides
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar55827.2022.00072
ER  - 

TY  - JOUR
AU  - Park, Joon Sung; Seering, Joseph; Bernstein, Michael S.
TI  - Measuring the Prevalence of Anti-Social Behavior in Online Communities
PY  - 2022
AB  - <jats:p>With increasing attention to online anti-social behaviors such as personal attacks and bigotry, it is critical to have an accurate accounting of how widespread anti-social behaviors are. In this paper, we empirically measure the prevalence of anti-social behavior in one of the world's most popular online community platforms. We operationalize this goal as measuring the proportion of unmoderated comments in the 97 most popular communities on Reddit that violate eight widely accepted platform norms. To achieve this goal, we contribute a human-AI pipeline for identifying these violations and a bootstrap sampling method to quantify measurement uncertainty. We find that 6.25% (95% Confidence Interval [5.36%, 7.13%]) of all comments in 2016, and 4.28% (95% CI [2.50%, 6.26%]) in 2020, are violations of these norms. Most anti-social behaviors remain unmoderated: moderators only removed one in twenty violating comments in 2016, and one in ten violating comments in 2020. Personal attacks were the most prevalent category of norm violation; pornography and bigotry were the most likely to be moderated, while politically inflammatory comments and misogyny/vulgarity were the least likely to be moderated. This paper offers a method and set of empirical results for tracking these phenomena as both the social practices (e.g., moderation) and technical practices (e.g., design) evolve.</jats:p>
SP  - 1
EP  - 29
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - CSCW2
PB  - 
DO  - 10.1145/3555552
ER  - 

TY  - NA
AU  - Hartmann, Jeremy; Vogel, Daniel
TI  - Enhanced Videogame Livestreaming by Reconstructing an Interactive 3D Game View for Spectators
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517521
ER  - 

TY  - NA
AU  - Kwon, Nahyun; Deshpande, Himani; Hasan, Kamrul; Darnal, Aryabhat; Kim, Jeeeun
TI  - Multi-ttach: Techniques to Enhance Multi-material Attachments in Low-cost FDM 3D Printing
PY  - 2021
AB  - Recent advances in low-cost FDM 3D printing and a range of commercially available materials have enabled integrating different properties into a single object such as flexibility and conductivity, assisting fabrication of a wide variety of interactive devices through multi-material printing. Mechanically different materials such as rigid and flexible filament, however, display issues when adhering to each other making the object vulnerable to coming apart. In this work, we propose Multi-ttach, a low-cost technique to increase the adhesion between different materials utilizing various 3D printing parameters with three specialized geometric structures : (1) bead and (2) lattice structures that interlock layers in vertical material arrangement, and (3) stitching in horizontal material arrangement. We approach this by modifying the geometry of the interface layer at the G-code level and using processing parameters. We validate the result through mechanical testing using off-the-shelf materials and desktop printers and demonstrate the applicability through a range of existing applications that tackle the benefit of multi-material FDM 3D printing.
SP  - NA
EP  - NA
JF  - Symposium on Computational Fabrication
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3485114.3485116
ER  - 

TY  - NA
AU  - Matsuura, Mikihito; Narumi, Koya; Aoki, Toshiki; Noma, Yuta; Nakashima, Kazutaka; Kawahara, Yoshihiro; Igarashi, Takeo
TI  - Blow-up Print: Rapidly 3D Printing Inflatable Objects in the Compressed State
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - ACM SIGGRAPH 2022 Posters
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532719.3543230
ER  - 

TY  - NA
AU  - Gruenefeld, Uwe; Auda, Jonas; Mathis, Florian; Schneegass, Stefan; Khamis, Mohamed; Gugenheimer, Jan; Mayer, Sven
TI  - VRception: Rapid Prototyping of Cross-Reality Systems in Virtual Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501821
ER  - 

TY  - NA
AU  - Weld, Galen; Zhang, Amy X.; Althoff, Tim
TI  - What Makes Online Communities 'Better'? Measuring Values, Consensus, and Conflict across Thousands of Subreddits
PY  - 2021
AB  - Making online social communities 'better' is a challenging undertaking, as online communities are extraordinarily varied in their size, topical focus, and governance. As such, what is valued by one community may not be valued by another. In this work, we measure community values through a survey of 2,769 reddit users in 2,151 unique subreddits, the largest survey of community values to date. Through a combination of survey responses and a quantitative analysis of publicly available reddit data, we characterize how these values vary within and across communities. We find that there is 47.4% more disagreement over how safe communities are than disagreement over other aspects of communities' current state, that longstanding communities place 30.1% more emphasis on trustworthiness than newer communities, and that recently joined redditors perceive their communities more positively than more senior redditors. We find that community moderators want their communities to be 56.7% less democratic than non-moderator community members. Accurate and scalable modeling of community values enables research and governance which is tuned to each community's different values. To this end, we demonstrate that a small number of automatically quantifiable features captures a substantial amount of the variation in values between communities with a ROC AUC of 0.667 on a binary classification task. However, significant variation remains, and modeling community values remains an important topic for future work. We make our models and data public to inform community design and governance.
SP  - NA
EP  - NA
JF  - arXiv: Social and Information Networks
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Jiang, Yirui; Tran, Trung Hieu; Williams, Leon
TI  - Advanced Visual SLAM and Image Segmentation Techniques for Augmented Reality
PY  - 2022
AB  - <p>Augmented reality can enhance human perception to experience a virtual-reality intertwined world by computer vision techniques. However, the basic techniques cannot handle complex large-scale scenes, tackle real-time occlusion, and render virtual objects in augmented reality. Therefore, this paper studies potential solutions, such as visual SLAM and image segmentation, that can address these challenges in the augmented reality visualizations. This paper provides a review of advanced visual SLAM and image segmentation techniques for augmented reality. In addition, applications of machine learning techniques for improving augmented reality are presented.</p>
SP  - 1
EP  - 28
JF  - International Journal of Virtual and Augmented Reality
VL  - 6
IS  - 1
PB  - 
DO  - 10.4018/ijvar.307063
ER  - 

TY  - BOOK
AU  - Siddiqui, Nadia; Hoque, Enamul
TI  - IV - ConVisQA: A Natural Language Interface for Visually Exploring Online Conversations
PY  - 2020
AB  - There has been an exponential growth of asynchronous online conversations thanks to the rise of social media. Analyzing and gaining insights from such conversations can be quite challenging for a user, especially when the discussion becomes very long. Traditional sites present a conversation in a paginated list view, making it very difficult to find comments of interests about a specific topic and/or opinions which may be scattered around a long thread of discussion. In this paper, we introduce a natural language interface that supports the user to quickly locate and browse through the comments that are relevant to her information needs. Our system takes a question asked by the reader about a conversation as input and then automatically finds the answer using natural language processing techniques. It then presents the results by highlighting in a visual interface, enabling the user to quickly navigate through the comments that match her information needs. Our case studies with three users suggest that the system can help the user to effectively fulfill her information needs by highlighting the relevant comments to their question.
SP  - 440
EP  - 447
JF  - 2020 24th International Conference Information Visualisation (IV)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/iv51561.2020.00077
ER  - 

TY  - BOOK
AU  - Giunchi, Daniele; Sztrajman, Alejandro; James, Stuart; Steed, Anthony
TI  - IMX - Mixing Modalities of 3D Sketching and Speech for Interactive Model Retrieval in Virtual Reality
PY  - 2021
AB  - Sketch and speech are intuitive interaction methods that convey complementary information and have been independently used for 3D model retrieval in virtual environments. While sketch has been shown to be an effective retrieval method, not all collections are easily navigable using this modality alone. We design a new challenging database for sketch comprised of 3D chairs where each of the components (arms, legs, seat, back) are independently colored. To overcome this, we implement a multimodal interface for querying 3D model databases within a virtual environment. We base the sketch on the state-of-the-art for 3D Sketch Retrieval, and use a Wizard-of-Oz style experiment to process the voice input. In this way, we avoid the complexities of natural language processing which frequently requires fine-tuning to be robust. We conduct two user studies and show that hybrid search strategies emerge from the combination of interactions, fostering the advantages provided by both modalities.
SP  - 144
EP  - 155
JF  - ACM International Conference on Interactive Media Experiences
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3452918.3458806
ER  - 

TY  - JOUR
AU  - Parilusyan, Brice; Teyssier, Marc; Martinez-Missir, Valentin; Duhart, Clément; Serrano, Marcos
TI  - Sensurfaces
PY  - 2022
AB  - <jats:p>Ubiquitous touch sensing surfaces are largely influenced by touchscreens' look and feel and fail to express the physical richness of existing surrounding materials. We introduce Sensurfaces, a plug-and-play electronic module that allows to rapidly experiment with touch-sensitive surfaces while preserving the original appearance of materials. Sensurfaces is composed of plug-and-play modules that can be connected together to expand the size and number of materials composing a sensitive surface. The combination of Sensurfaces modules allows the creation of small or large multi-material sensitive surfaces that can detect multi-touch but also body proximity, pose, pass, or even human steps. In this paper, we present the design and implementation of Sensurfaces. We propose a design space describing the factors of Sensurfaces interfaces. Then, through a series of technical evaluations, we demonstrate the capabilities of our system. Finally, we report on two workshops validating the usability of our system.</jats:p>
SP  - 1
EP  - 19
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 2
PB  - 
DO  - 10.1145/3534616
ER  - 

TY  - JOUR
AU  - McNutt, Andrew M
TI  - No Grammar to Rule Them All: A Survey of JSON-style DSLs for Visualization.
PY  - 2022
AB  - There has been substantial growth in the use of JSON-based grammars, as well as other standard data serialization languages, to create visualizations. Each of these grammars serves a purpose: some focus on particular computational tasks (such as animation), some are concerned with certain chart types (such as maps), and some target specific data domains (such as ML). Despite the prominence of this interface form, there has been little detailed analysis of the characteristics of these languages. In this study, we survey and analyze the design and implementation of 57 JSON-style DSLs for visualization. We analyze these languages supported by a collected corpus of examples for each DSL (consisting of 4395 instances) across a variety of axes organized into concerns related to domain, conceptual model, language relationships, affordances, and general practicalities. We identify tensions throughout these areas, such as between formal and colloquial specifications, among types of users, and within the composition of languages. Through this work, we seek to support language implementers by elucidating the choices, opportunities, and tradeoffs in visualization DSL design.
SP  - 1
EP  - 11
JF  - IEEE transactions on visualization and computer graphics
VL  - PP
IS  - NA
PB  - 
DO  - 10.1109/tvcg.2022.3209460
ER  - 

TY  - JOUR
AU  - Herskovitz, Jaylin; Cheng, Yi Fei; Guo, Anhong; Sample, Alanson P.; Nebeling, Michael
TI  - XSpace: An Augmented Reality Toolkit for Enabling Spatially-Aware Distributed Collaboration
PY  - 2022
AB  - <jats:p>Augmented Reality (AR) has the potential to leverage environmental information to better facilitate distributed collaboration, however, such applications are difficult to develop. We present XSpace, a toolkit for creating spatially-aware AR applications for distributed collaboration. Based on a review of existing applications and developer tools, we design XSpace to support three methods for creating shared virtual spaces, each emphasizing a different aspect: shared objects, user perspectives, and environmental meshes. XSpace implements these methods in a developer toolkit, and also provides a set of complimentary visual authoring tools to allow developers to preview a variety of configurations for a shared virtual space. We present five example applications to illustrate that XSpace can support the development of a rich set of collaborative AR experiences that are difficult to produce with current solutions. Through XSpace, we discuss implications for future application design, including user space customization and privacy and safety concerns when sharing users' environments.</jats:p>
SP  - 277
EP  - 302
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - ISS
PB  - 
DO  - 10.1145/3567721
ER  - 

TY  - CHAP
AU  - Olshevsky, Vyacheslav; Bondarets, Ivan; Trunov, Oleksandr; Shcherbina, Artem
TI  - HCI (38) - Realistic Occlusion of Virtual Objects Using Three-Dimensional Hand Model
PY  - 2021
AB  - We develop a method for predicting virtual object occlusions during hand-object interaction in mixed reality. We reconstruct a 3D hand model from a monocular RGB camera frame and use it to predict occlusions. The quality of these occlusions, evaluated using dice coefficient, is at the same level as reported for other depth sensor and hand model based methods. Our model runs in real-time on off-the-shelf smartphone and gives a plausible experience of grabbing, rotating and translating virtual objects, which we confirmed through a dedicated user study. Volume penetration is the main reason for occlusion errors. However, the suitability of the object to the user scenario and its appealing look can compensate for the occlusion errors, and make a positive mixed reality experience.
SP  - 295
EP  - 301
JF  - HCI International 2021 - Posters
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-78642-7_40
ER  - 

TY  - CHAP
AU  - Lee, Bokyung; Saakes, Daniel
TI  - Understanding the Roles of Intelligent Product-Customization Systems Through Expert Interviews
PY  - 2022
AB  - NA
SP  - 1153
EP  - 1169
JF  - [ ] With Design: Reinventing Design Modes
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-981-19-4472-7_76
ER  - 

TY  - NA
AU  - Alaboudi, Abdulaziz; LaToza, Thomas D.
TI  - Edit-Run Behavior in Programming and Debugging
PY  - 2021
AB  - As developers program and debug, they continuously edit and run their code, a behavior known as edit-run cycles. While techniques such as live programming are intended to support this behavior, little is known about the characteristics of edit-run cycles themselves. To bridge this gap, we analyzed 28 hours of programming and debugging work from 11 professional developers which encompassed over three thousand development activities. We mapped activities to edit or run steps, constructing 581 debugging and 207 programming edit-run cycles. We found that edit-run cycles are frequent. Developers edit and run the program, on average, 7 times before fixing a defect and twice before introducing a defect. Developers waited longer before again running the program when programming than debugging, with a mean cycle length of 3 minutes for programming and 1 minute for debugging. Most cycles involved an edit to a single file after which a developer ran the program to observe the impact on the final output. Edit-run cycles which included activities beyond edit and run, such as navigating between files, consulting resources, or interacting with other IDE features, were much longer, with a mean length of 5 minutes, rather than 1.5 minutes. We conclude with a discussion of design recommendations for tools to enable more fluidity in edit-run cycles.
SP  - NA
EP  - NA
JF  - arXiv: Software Engineering
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Kurzhals, Kuno; Becher, Michael; Pathmanathan, Nelusa; Reina, Guido
TI  - Evaluating Situated Visualization in AR with Eye Tracking
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE Evaluation and Beyond - Methodological Approaches for Visualization (BELIV)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/beliv57783.2022.00013
ER  - 

TY  - JOUR
AU  - Wang, Qianwen; Chen, Zhutian; Wang, Yong; Qu, Huamin
TI  - A Survey on ML4VIS: Applying Machine Learning Advances to Data Visualization.
PY  - 2022
AB  - Inspired by the great success of machine learning (ML), researchers have applied ML techniques to visualizations to achieve a better design, development, and evaluation of visualizations. This branch of studies, known as ML4VIS, is gaining increasing research attention in recent years. To successfully adapt ML techniques for visualizations, a structured understanding of the integration of ML4VIS is needed. In this article, we systematically survey 88 ML4VIS studies, aiming to answer two motivating questions: "what visualization processes can be assisted by ML?" and "how ML techniques can be used to solve visualization problems? "This survey reveals seven main processes where the employment of ML techniques can benefit visualizations: Data Processing4VIS, Data-VIS Mapping, Insight Communication, Style Imitation, VIS Interaction, VIS Reading, and User Profiling. The seven processes are related to existing visualization theoretical models in an ML4VIS pipeline, aiming to illuminate the role of ML-assisted visualization in general visualizations. Meanwhile, the seven processes are mapped into main learning tasks in ML to align the capabilities of ML with the needs in visualization. Current practices and future opportunities of ML4VIS are discussed in the context of the ML4VIS pipeline and the ML-VIS mapping. While more studies are still needed in the area of ML4VIS, we hope this article can provide a stepping-stone for future exploration. A web-based interactive browser of this survey is available at https://ml4vis.github.io.
SP  - 5134
EP  - 5153
JF  - IEEE transactions on visualization and computer graphics
VL  - 28
IS  - 12
PB  - 
DO  - 10.1109/tvcg.2021.3106142
ER  - 

TY  - JOUR
AU  - Chen, Zhutian; Yang, Qisen; Xie, Xiao; Beyer, Johanna; Xia, Haijun; Wu, Yingcai; Pfister, Hanspeter
TI  - Sporthesia: Augmenting Sports Videos Using Natural Language.
PY  - 2022
AB  - Augmented sports videos, which combine visualizations and video effects to present data in actual scenes, can communicate insights engagingly and thus have been increasingly popular for sports enthusiasts around the world. Yet, creating augmented sports videos remains a challenging task, requiring considerable time and video editing skills. On the other hand, sports insights are often communicated using natural language, such as in commentaries, oral presentations, and articles, but usually lack visual cues. Thus, this work aims to facilitate the creation of augmented sports videos by enabling analysts to directly create visualizations embedded in videos using insights expressed in natural language. To achieve this goal, we propose a three-step approach - 1) detecting visualizable entities in the text, 2) mapping these entities into visualizations, and 3) scheduling these visualizations to play with the video - and analyzed 155 sports video clips and the accompanying commentaries for accomplishing these steps. Informed by our analysis, we have designed and implemented Sporthesia, a proof-of-concept system that takes racket-based sports videos and textual commentaries as the input and outputs augmented videos. We demonstrate Sporthesia's applicability in two exemplar scenarios, i.e., authoring augmented sports videos using text and augmenting historical sports videos based on auditory comments. A technical evaluation shows that Sporthesia achieves high accuracy (F1-score of 0.9) in detecting visualizable entities in the text. An expert evaluation with eight sports analysts suggests high utility, effectiveness, and satisfaction with our language-driven authoring method and provides insights for future improvement and opportunities.
SP  - 1
EP  - 11
JF  - IEEE transactions on visualization and computer graphics
VL  - PP
IS  - NA
PB  - 
DO  - 10.1109/tvcg.2022.3209497
ER  - 

TY  - JOUR
AU  - Li, Zhibin; Xiao, Songhua; Yue, Quan; Wang, Taihong
TI  - Electrical Capacitance Tomography Sensor With House Structure for Assisting Recognition of Objects
PY  - 2022
AB  - As a fast and non-invasive visualization technology, electrical capacitance tomography(ECT) avoids the problem that camera imaging technology is interfered by light and can’t identify material properties. However, the traditional ECT sensor research mainly focused on the image reconstruction of multiphase flow between electrodes, without considering the object recognition performance through the dielectric distribution of the objects. Therefore, we propose a new ECT sensor (called House Sensor) with house-like structure, which is suitable for multi features detection of household objects. We analyze the sensitivity distribution of House Sensor, and use linear back projection (LBP) and Tikhonov regularization for high-speed image reconstruction. 20 objects with different sizes and dielectric constants are visually clustered by t-distributed stochastic neighbor embedding (t-SNE) to verify the feasibility of classification, and the accuracy of Random Forest (RF) is up to 95.3% within 3.5ms. This implies that House Sensor provide a new feasible scheme to assist object recognition under non-vision conditions.
SP  - 4534
EP  - 4544
JF  - IEEE Sensors Journal
VL  - 22
IS  - 5
PB  - 
DO  - 10.1109/jsen.2022.3143709
ER  - 

TY  - NA
AU  - Suzuki, Ryo; Kazi, Rubaiat Habib; Wei, Li-Yi; DiVerdi, Stephen; Li, Wilmot; Leithinger, Daniel
TI  - RealitySketch: Embedding Responsive Graphics and Visualizations in AR with Dynamic Sketching
PY  - 2020
AB  - NA
SP  - NA
EP  - NA
JF  - Adjunct Publication of the 33rd Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3379350.3416155
ER  - 

TY  - NA
AU  - Heyko, Dar'ya
TI  - Supporting d/Deaf and Hard of Hearing Employees in Their Workplaces Through Technology, Design, and Community
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Salvato, M.; Heravi, Negin; Okamura, Allison M.; Bohg, Jeannette
TI  - Predicting Hand-Object Interaction for Improved Haptic Feedback in Mixed Reality
PY  - 2022
AB  - Accurately detecting when a user begins interaction with virtual objects is necessary for compelling multi-sensory experiences in mixed reality. To address inherent sensing, computation, display, and actuation latency, we propose to predict when a user will begin touch interaction with a virtual object before it occurs. We hypothesize that the sequence of hand poses when approaching an object, combined with object pose, contain sufficient information to predict when the user will begin contact. By leveraging this information, we could reduce or eliminate latency in providing haptic feedback during virtual object interaction. We focus on small time horizons, on the order of 100 ms, to overcome sense-to-actuation latency for haptic feedback in mixed reality systems. We use a time series of tracked hand poses, along with virtual object geometry to perform our prediction. By calculating minimum hand-object distance and feeding those along with hand poses to a self-attention-based network, we achieve approximately 52.8 ms of timing error for a 100 ms prediction horizon. Additionally, we test our system against different levels of tracking and hand-object alignment noise, finding minimal change in timing error. By contrast, when only extrapolating joint and hand velocities, we find that timing error consistently exceeds the prediction horizon.
SP  - 3851
EP  - 3857
JF  - IEEE Robotics and Automation Letters
VL  - 7
IS  - 2
PB  - 
DO  - 10.1109/lra.2022.3148458
ER  - 

TY  - NA
AU  - Wang, Yihong
TI  - An AR-based DC Circuit Connection Simulator for Beginners
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 4th International Conference on Image, Video and Signal Processing
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3531232.3531256
ER  - 

TY  - NA
AU  - Pamparău, Cristian; Vatavu, Radu-Daniel
TI  - The User Experience of Journeys in the Realm of Augmented Reality Television
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - ACM International Conference on Interactive Media Experiences
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3505284.3529969
ER  - 

TY  - NA
AU  - Hsueh, Hsuan-Yu; Chen, Chien-Hua; Chen, Irene; Yao, Chih-Yuan; Chu, Hung-Kuo
TI  - UbiComp/ISWC Adjunct - ARToken: A Tangible Device for Dynamically Binding Real-world Objects with Virtual Representation
PY  - 2021
AB  - Users are eager to interact with and control virtual proxies in the reconstructed virtual world using physical objects with haptic feedback since the development of AR/VR. Therefore, we propose ARToken, a device that virtualizes physical objects through AR tracking, and then links the relative positions of the Token device and virtual representations through its system, generating interactive virtual environments based on physical environments. In addition to tracking position through AR images, when the object exceeds the recognition range of AR Image, the IMU sensor can be used to detect rotation and displacement. ARToken sends this information through WiFi, allowing for real-time feedback of the state of the real object to the corresponding virtual representation. Also, this system allows for simultaneous tracking of multiple devices. To verify our design, we have produced two applications that exhibit how ARToken aids in generating virtual environments based on physical environments and links virtual and physical objects as one.
SP  - 560
EP  - 564
JF  - Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3460418.3480161
ER  - 

TY  - NA
AU  - Han, Han L.; Yu, Junhang; Bournet, Raphael; Ciorascu, Alexandre; Mackay, Wendy E.; Beaudouin-Lafon, Michel
TI  - Passages: Interacting with Text Across Documents
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502052
ER  - 

TY  - CONF
AU  - Yamanaka, Shota
TI  - Utility of Crowdsourced User Experiments for Measuring the Central Tendency of User Performance to Evaluate Error-Rate Models on GUIs
PY  - 2021
AB  - The usage of crowdsourcing to recruit numerous participants has been recognized as beneficial in the human-computer interaction (HCI) field, such as for designing user interfaces and validating user performance models. In this work, we investigate its effectiveness for evaluating an error-rate prediction model in target pointing tasks. In contrast to models for operational times, a clicking error (i.e., missing a target) occurs by chance at a certain probability, e.g., 5%. Therefore, in traditional laboratory-based experiments, a lot of repetitions are needed to measure the central tendency of error rates. We hypothesize that recruiting many workers would enable us to keep the number of repetitions per worker much smaller. We collected data from 384 workers and found that existing models on operational time and error rate showed good fits (both R^2 > 0.95). A simulation where we changed the number of participants N_P and the number of repetitions N_repeat showed that the time prediction model was robust against small N_P and N_repeat, although the error-rate model fitness was considerably degraded. These findings empirically demonstrate a new utility of crowdsourced user experiments for collecting numerous participants, which should be of great use to HCI researchers for their evaluation studies.
SP  - 155
EP  - 165
JF  - NA
VL  - 9
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Rajaram, Shwetha; Nebeling, Michael
TI  - Paper Trail: An Immersive Authoring System for Augmented Reality Instructional Experiences
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517486
ER  - 

TY  - JOUR
AU  - Macedo, Marcio C. F.; Apolinario, Antonio L.
TI  - Occlusion Handling in Augmented Reality: Past, Present and Future
PY  - NA
AB  - NA
SP  - 1590
EP  - 1609
JF  - IEEE Transactions on Visualization and Computer Graphics
VL  - 29
IS  - 2
PB  - 
DO  - 10.1109/tvcg.2021.3117866
ER  - 

TY  - NA
AU  - Zhao, Maozheng; Huang, Henry; Li, Zhi; Liu, Rui; Cui, Wenzhe; Toshniwal, Kajal; Goel, Ananya; Wang, Andrew; Zhao, Xia; Rashidian, Sina; Baig, Furqan; Phi, Khiem; Zhai, Shumin; Ramakrishnan, IV; Wang, Fusheng; Bi, Xiaojun
TI  - EyeSayCorrect: Eye Gaze and Voice Based Hands-free Text Correction for Mobile Devices
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 27th International Conference on Intelligent User Interfaces
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490099.3511103
ER  - 

TY  - JOUR
AU  - Amesaka, Takashi; Watanabe, Hiroki; Sugimoto, Masanori; Shizuki, Buntarou
TI  - Gesture Recognition Method Using Acoustic Sensing on Usual Garment
PY  - 2022
AB  - <jats:p>In this study, we show a new gesture recognition method for clothing-based gesture input methods using active and passive acoustic sensing. Our system consists of a piezoelectric speaker and a microphone. The speaker transmits ultrasonic swept sine signals, and the microphone simultaneously records the ultrasonic signals that propagate through the garment and the rubbing sounds generated by the gestures on the garment. Our method recognizes a variety of gestures, such as pinch, twist, touch, and swipe, by incorporating active and passive acoustic sensing. An important feature of our method is that it does not require a dedicated garment or embroidery embedded since our system only requires a pair of piezoelectric elements to be attached to the usual garment with a magnet. We performed recognition experiments of 11 gestures on the forearm with four types of garments made from different materials and recognition experiments of five one-handed gestures on the button of a shirt and the pocket of pants. The results of a per-user classifier confirmed that the f-scores were 83.9% and 95.9% for 11 gestures with four different types of garments and 5 gestures that were selected assuming actual use, respectively. In addition, we confirmed that the system recognizes five gestures, which can be performed with one hand, with 89.2% and 92.6% accuracy in the button and pocket sites, respectively.</jats:p>
SP  - 1
EP  - 27
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 2
PB  - 
DO  - 10.1145/3534579
ER  - 

TY  - NA
AU  - Dogan, Mustafa Doga; Yotamornsunthorn, Veerapatr; Taka, Ahmad; Gupta, Aakar; Mueller, Stefanie
TI  - InfraredTags Demo: Invisible AR Markers and Barcodes Using Infrared Imaging and 3D Printing
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The Adjunct Publication of the 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526114.3558660
ER  - 

TY  - NA
AU  - Dogan, Mustafa Doga; Yotamornsunthorn, Veerapatr; Taka, Ahmad; Zhu, Yunyi; Gupta, Aakar; Mueller, Stefanie
TI  - Demonstrating InfraredTags: Decoding Invisible 3D Printed Tags with Convolutional Neural Networks
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519905
ER  - 

TY  - NA
AU  - Zhao, Hang; Gu, Sophia; Yu, Chun; Bi, Xiaojun
TI  - Bayesian Hierarchical Pointing Models
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545708
ER  - 

TY  - JOUR
AU  - Dorsey, Kristen L; Roberts, Sonia F; Forman, Jack; Ishii, Hiroshi
TI  - Analysis of DefeXtiles: a 3D printed textile towards garments and accessories
PY  - 2022
AB  - <jats:title>Abstract</jats:title> <jats:p>This work investigates the structure and mechanical properties of a textile-like material fabricated from polylactic acid (PLA) filament in a fused deposition modeling (FDM) 3D printing process. FDM has expanded access to 3D printing, but the resultant parts are largely limited to rigid forms. The process characterized in this work may expand access to flexible, textile-like 3D-printed materials without requiring elastic filaments that are challenging to print. We investigate the mechanical properties of a previously demonstrated 3D printed textile (defeXtiles) that is fabricated by under-extruding a PLA filament during printing. We characterize the impact of selected print parameters on material structure and mechanical properties. We demonstrate materials with tunable flexural rigidity and a factor of 44 increase in stiffness between the most rigid and flexible textures, solely by changing print settings. We conclude by showcasing defeXtiles as a sustainable fabrication process that is accessible to hobbyists and artisans, with demonstrations of a wristband with integrated RFID tag and a fascinator hat.</jats:p>
SP  - 34005
EP  - NA
JF  - Journal of Micromechanics and Microengineering
VL  - 32
IS  - 3
PB  - 
DO  - 10.1088/1361-6439/ac4fad
ER  - 

TY  - NA
AU  - Nowak, Oliver; Schäfer, René; Brocker, Anke; Wacker, Philipp; Borchers, Jan
TI  - Shaping Textile Sliders: An Evaluation of Form Factors and Tick Marks for Textile Sliders
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517473
ER  - 

TY  - JOUR
AU  - Fang, Fengyi; Zhang, Hongwei; Zhan, Lishuang; Guo, Shihui; Zhang, Minying; Lin, Juncong; Qin, Yipeng; Fu, Hongbo
TI  - Handwriting Velcro
PY  - 2022
AB  - <jats:p>Text input is a desired feature for AR glasses. While there already exist various input modalities (e.g., voice, mid-air gesture), the diverse demands required by different input scenarios can hardly be met by the small number of fixed input postures offered by existing solutions. In this paper, we present Handwriting Velcro, a novel text input solution for AR glasses based on flexible touch sensors. The distinct advantage of our system is that it can easily stick to different body parts, thus endowing AR glasses with posture-adaptive handwriting input. We explored the design space of on-body device positions and identified the best interaction positions for various user postures. To flatten users' learning curves, we adapt our device to the established writing habits of different users by training a 36-character (i.e., A-Z, 0-9) recognition neural network in a human-in-the-loop manner. Such a personalization attempt ultimately achieves a low error rate of 0.005 on average for users with different writing styles. Subjective feedback shows that our solution has a good performance in system practicability and social acceptance. Empirically, we conducted a heuristic study to explore and identify the best interaction Position-Posture Correlation. Experimental results show that our Handwriting Velcro excels similar work [6] and commercial product in both practicality (12.3 WPM) and user-friendliness in different contexts.</jats:p>
SP  - 1
EP  - 31
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 4
PB  - 
DO  - 10.1145/3569461
ER  - 

TY  - JOUR
AU  - Alessandrini, Andrea
TI  - A Study of Students Engaged in Electronic Circuit Wiring in an Undergraduate Course
PY  - 2022
AB  - NA
SP  - 78
EP  - 95
JF  - Journal of Science Education and Technology
VL  - 32
IS  - 1
PB  - 
DO  - 10.1007/s10956-022-09994-9
ER  - 

TY  - CHAP
AU  - Faiña, Andres
TI  - Learning Hands-On Electronics from Home: A Simulator for Fritzing
PY  - 2022
AB  - AbstractThe recent pandemic has forced us to teach online, which is especially difficult for hand-on courses in robotics, like basic electronics. In this paper, I present a simulator which tries to replicate the same experience students will encounter during the exercises in the laboratory. The simulator has been developed in Fritzing, uses realistic multimeters for measuring and checks for common mistakes. Results show not only that the simulator was extremely useful during the pandemic, but also that it can supplement laboratory exercises when teaching in-classroom.KeywordsLearning electronicsElectronics simulatorFritzingEducational tools
SP  - 404
EP  - 413
JF  - Robotics in Natural Settings
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-15226-9_38
ER  - 

TY  - NA
AU  - Willett, Wesley; Bon Adriel Aseniero, NA; Carpendale, Sheelagh; Dragicevic, Pierre; Jansen, Yvonne; Oehlberg, Lora; Isenberg, Petra
TI  - Perception! Immersion! Empowerment! Superpowers as Inspiration for Visualization
PY  - 2021
AB  - We explore how the lens of fictional superpowers can help characterize how visualizations empower people and provide inspiration for new visualization systems. Researchers and practitioners often tout visualizations' ability to "make the invisible visible" and to "enhance cognitive abilities." Meanwhile superhero comics and other modern fiction often depict characters with similarly fantastic abilities that allow them to see and interpret the world in ways that transcend traditional human perception. We investigate the intersection of these domains, and show how the language of superpowers can be used to characterize existing visualization systems and suggest opportunities for new and empowering ones. We introduce two frameworks: The first characterizes seven underlying mechanisms that form the basis for a variety of visual superpowers portrayed in fiction. The second identifies seven ways in which visualization tools and interfaces can instill a sense of empowerment in the people who use them. Building on these observations, we illustrate a diverse set of "visualization superpowers" and highlight opportunities for the visualization community to create new systems and interactions that empower new experiences with data.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Endow, Shreyosi; Rakib, Mohammad Abu Nasir; Srivastava, Anvay; Rastegarpouyani, Sara; Torres, Cesar
TI  - Embr: A Creative Framework for Hand Embroidered Liquid Crystal Textile Displays
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502117
ER  - 

TY  - CHAP
AU  - Yang, Tian; Yao, Powen; Zyda, Michael
TI  - Flick Typing: A New VR Text Input System Based on Space Gestures
PY  - 2022
AB  - NA
SP  - 379
EP  - 392
JF  - Virtual, Augmented and Mixed Reality: Design and Development
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-05939-1_26
ER  - 

TY  - NA
AU  - Hong, Freddie; Tendera, Luca; Myant, Connor; Boyle, David
TI  - Vacuum-formed 3D printed electronics: fabrication of thin, rigid and free-form interactive surfaces.
PY  - 2021
AB  - Vacuum-forming is a common manufacturing technique for constructing thin plastic shell products by pressing heated plastic sheets onto a mold using atmospheric pressure. Vacuum-forming is ubiquitous in packaging and casing products in industry spanning fast moving consumer goods to connected devices. Integrating advanced functionality, which may include sensing, computation and communication, within thin structures is desirable for various next-generation interactive devices. Hybrid additive manufacturing techniques like thermoforming are becoming popular for prototyping freeform electronics given its design flexibility, speed and cost-effectiveness. In this paper, we present a new hybrid method for constructing thin, rigid and free-form interconnected surfaces via fused deposition modelling (FDM) 3D printing and vacuum-forming. While 3D printing a mold for vacuum-forming has been explored by many, utilising 3D printing to construct sheet materials has remains unexplored. 3D printing the sheet material allows embedding conductive traces within thin layers of the substrate, which can be vacuum-formed but remain conductive and insulated. We characterise the behaviour of the vacuum-formed 3D printed sheet, analyse the electrical performance of 3D printed traces after vacuum-forming, and showcase a range of examples constructed using the technique. We demonstrate a new design interface specifically for designing conformal interconnects, which allows designers to draw conductive patterns in 3D and export pre-distorted sheet models ready to be 3D printed.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Zheng, Qingyuan; Li, Zhuoru; Bargteil, Adam W.
TI  - Learning Aesthetic Layouts via Visual Guidance.
PY  - 2021
AB  - We explore computational approaches for visual guidance to aid in creating aesthetically pleasing art and graphic design. Our work complements and builds on previous work that developed models for how humans look at images. Our approach comprises three steps. First, we collected a dataset of art masterpieces and labeled the visual fixations with state-of-art vision models. Second, we clustered the visual guidance templates of the art masterpieces with unsupervised learning. Third, we developed a pipeline using generative adversarial networks to learn the principles of visual guidance and that can produce aesthetically pleasing layouts. We show that the aesthetic visual guidance principles can be learned and integrated into a high-dimensional model and can be queried by the features of graphic elements. We evaluate our approach by generating layouts on various drawings and graphic designs. Moreover, our model considers the color and structure of graphic elements when generating layouts. Consequently, we believe our tool, which generates multiple aesthetic layout options in seconds, can help artists create beautiful art and graphic designs.
SP  - NA
EP  - NA
JF  - arXiv: Computer Vision and Pattern Recognition
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Yamamoto, Kenta; Suzuki, Ippei; Shitara, Akihisa; Ochiai, Yoichi
TI  - See-Through Captions: Real-Time Captioning on Transparent Display for Deaf and Hard-of-Hearing People
PY  - 2021
AB  - Real-time captioning is a useful technique for deaf and hard-of-hearing (DHH) people to talk to hearing people. With the improvement in device performance and the accuracy of automatic speech recognition (ASR), real-time captioning is becoming an important tool for helping DHH people in their daily lives. To realize higher-quality communication and overcome the limitations of mobile and augmented-reality devices, real-time captioning that can be used comfortably while maintaining nonverbal communication and preventing incorrect recognition is required. Therefore, we propose a real-time captioning system that uses a transparent display. In this system, the captions are presented on both sides of the display to address the problem of incorrect ASR, and the highly transparent display makes it possible to see both the body language and the captions.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Wilmott, James P.; Erkelens, Ian M.; Murdison, T. Scott; Rio, Kevin W.
TI  - Perceptibility of Jitter in Augmented Reality Head-Mounted Displays
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar55827.2022.00063
ER  - 

TY  - NA
AU  - Tran O'Leary, Jasper; Jun, Eunice; Peek, Nadya
TI  - Improving Programming for Exploratory Digital Fabrication with Inline Machine Control and Styled Toolpath Visualizations
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Symposium on Computational Fabrication
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3559400.3561998
ER  - 

TY  - NA
AU  - Cheymol, Antonin; Hirao, Yutaro; Yoshida, Shigeo; Kuzuoka, Hideaki
TI  - Increasing the Perceived Speed of Dynamic Handheld Shape Displays through Visuo-Haptic Illusions
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Augmented Humans 2022
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3519391.3519410
ER  - 

TY  - NA
AU  - Vaithilingam, Priyan; Zhang, Tianyi; Glassman, Elena L.
TI  - Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519665
ER  - 

TY  - NA
AU  - Li, Jiahao; Samoylov, Alexis; Kim, Jeeeun; Chen, Xiang 'Anthony'
TI  - Roman: Making Everyday Objects Robotically Manipulable with 3D-Printable Add-on Mechanisms
PY  - 2022
AB  - One important vision of robotics is to provide physical assistance by manipulating different everyday objects, e.g., hand tools, kitchen utensils. However, many objects designed for dexterous hand-control are not easily manipulable by a single robotic arm with a generic parallel gripper. Complementary to existing research on developing grippers and control algorithms, we present Roman, a suite of hardware design and software tool support for robotic engineers to create 3D printable mechanisms attached to everyday handheld objects, making them easier to be manipulated by conventional robotic arms. The Roman hardware comes with a versatile magnetic gripper that can snap on/off handheld objects and drive add-on mechanisms to perform tasks. Roman also provides software support to register and author control programs. To validate our approach, we designed and fabricated Roman mechanisms for 14 everyday objects/tasks presented within a design space and conducted expert interviews with robotic engineers indicating that Roman serves as a practical alternative for enabling robotic manipulation of everyday objects.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501818
ER  - 

TY  - NA
AU  - Gobert, Camille; Beaudouin-Lafon, Michel
TI  - i-LaTeX : Manipulating Transitional Representations between LaTeX Code and Generated Documents
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517494
ER  - 

TY  - NA
AU  - Landwehr Sydow, Sophie; Jonsson, Martin; Tholander, Jakob
TI  - Modding the Pliable Machine: Unpacking the Creative and Social Practice of Upkeep at the Makerspace
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Creativity and Cognition
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3527927.3532804
ER  - 

TY  - CONF
AU  - McNutt, Andrew; Chugh, Ravi
TI  - CHI - Integrated Visualization Editing via Parameterized Declarative Templates
PY  - 2021
AB  - Interfaces for creating visualizations typically embrace one of several common forms. Textual specification enables fine-grained control, shelf building facilitates rapid exploration, while chart choosing promotes immediacy and simplicity. Ideally these approaches could be unified to integrate the user- and usage-dependent benefits found in each modality, yet these forms remain distinct. We propose parameterized declarative templates, a simple abstraction mechanism over JSON-based visualization grammars, as a foundation for multimodal visualization editors. We demonstrate how templates can facilitate organization and reuse by factoring the more than 160 charts that constitute Vega-Lite’s example gallery into approximately 40 templates. We exemplify the pliability of abstracting over charting grammars by implementing—as a template—the functionality of the shelf builder Polestar (a simulacra of Tableau) and a set of templates that emulate the Google Sheets chart chooser. We show how templates support multimodal visualization editing by implementing a prototype and evaluating it through an approachability study.
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Dogan, Mustafa Doga; Baudisch, Patrick; Benko, Hrvoje; Nebeling, Michael; Peng, Huaishu; Savage, Valkyrie; Mueller, Stefanie
TI  - Fabricate It or Render It? Digital Fabrication vs. Virtual Reality for Creating Objects Instantly
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3516510
ER  - 

TY  - CONF
AU  - Li, Toby Jia-Jun; Popowski, Lindsay; Mitchell, Tom M.; Myers, Brad A.
TI  - CHI - Screen2Vec: Semantic Embedding of GUI Screens and GUI Components
PY  - 2021
AB  - Representing the semantics of GUI screens and components is crucial to data-driven computational methods for modeling user-GUI interactions and mining GUI designs. Existing GUI semantic representations are limited to encoding either the textual content, the visual design and layout patterns, or the app contexts. Many representation techniques also require significant manual data annotation efforts. This paper presents Screen2Vec, a new self-supervised technique for generating representations in embedding vectors of GUI screens and components that encode all of the above GUI features without requiring manual annotation using the context of user interaction traces. Screen2Vec is inspired by the word embedding method Word2Vec, but uses a new two-layer pipeline informed by the structure of GUIs and interaction traces and incorporates screen- and app-specific metadata. Through several sample downstream tasks, we demonstrate Screen2Vec’s key useful properties: representing between-screen similarity through nearest neighbors, composability, and capability to represent user tasks.
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - CONF
AU  - Wang, Chenglong; Feng, Yu; Bodik, Rastislav; Dillig, Isil; Cheung, Alvin; Ko, Amy J.
TI  - CHI - Falx: Synthesis-Powered Visualization Authoring
PY  - 2021
AB  - Modern visualization tools aim to allow data analysts to easily create exploratory visualizations. When the input data layout conforms to the visualization design, users can easily specify visualizations by mapping data columns to visual channels of the design. However, when there is a mismatch between data layout and the design, users need to spend significant effort on data transformation. We propose Falx, a synthesis-powered visualization tool that allows users to specify visualizations in a similarly simple way but without needing to worry about data layout. In Falx, users specify visualizations using examples of how concrete values in the input are mapped to visual channels, and Falx automatically infers the visualization specification and transforms the data to match the design. In a study with 33 data analysts on four visualization tasks involving data transformation, we found that users can effectively adopt Falx to create visualizations they otherwise cannot implement.
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Roumen, Thijs; Apel, Ingo; Kern, Thomas; Taraz, Martin; Sharma, Ritesh; Schlueter, Ole; Johnson, Jeffrey; Meier, Dominik; Lempert, Conrad; Baudisch, Patrick
TI  - Structure-Preserving Editing of Plates and Volumes for Laser Cutting
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Symposium on Computational Fabrication
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3559400.3561996
ER  - 

TY  - NA
AU  - Davis, Keith M.; de la Torre-Ortiz, Carlos; Ruotsalo, Tuukka
TI  - Brain-Supervised Image Editing
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/cvpr52688.2022.01793
ER  - 

TY  - JOUR
AU  - Li, Xingjun; Zhang, Yizhi; Leung, Justin; Sun, Chengnian; Zhao, Jian
TI  - EDAssistant: Supporting Exploratory Data Analysis in Computational Notebooks with In-Situ Code Search and Recommendation
PY  - 2022
AB  - <jats:p>Using computational notebooks (e.g., Jupyter Notebook), data scientists rationalize their exploratory data analysis (EDA) based on their prior experience and external knowledge such as online examples. For novices or data scientists who lack specific knowledge about the dataset or problem to investigate, effectively obtaining and understanding the external information is critical to carrying out EDA. This paper presents EDAssistant, a JupyterLab extension that supports EDA with in-situ search of example notebooks and recommendation of useful APIs, powered by novel interactive visualization of search results. The code search and recommendation are enabled by advanced machine learning models, trained on a large corpus of EDA notebooks collected online. A user study is conducted to investigate both EDAssistant and data scientists’ current practice (i.e., using external search engines). The results demonstrate the effectiveness and usefulness of EDAssistant, and participants appreciated its smooth and in-context support of EDA. We also report several design implications regarding code recommendation tools.</jats:p>
SP  - NA
EP  - NA
JF  - ACM Transactions on Interactive Intelligent Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3545995
ER  - 

TY  - NA
AU  - Yamanaka, Shota; Usuba, Hiroki; Miyashita, Homei
TI  - Bivariate Effective Width Method to Improve the Normalization Capability for Subjective Speed-accuracy Biases in Rectangular-target Pointing
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517466
ER  - 

TY  - NA
AU  - Lee, Doris Jung Lin; Tang, Dixin; Agarwal, Kunal; Boonmark, Thyne; Chen, Caitlyn; Kang, Jake; Mukhopadhyay, Ujjaini; Song, Jerry; Yong, Micah; Hearst, Marti A.; Parameswaran, Aditya
TI  - Lux: Always-on Visualization Recommendations for Exploratory Data Science.
PY  - 2021
AB  - Exploratory data science largely happens in computational notebooks with dataframe API, such as pandas, that support flexible means to transform, clean, and analyze data. Yet, visually exploring data in dataframes remains tedious, requiring substantial programming effort for visualization and mental effort to determine what analysis to perform next. We propose Lux, an always-on framework for accelerating visual insight discovery in data science workflows. When users print a dataframe in their notebooks, Lux recommends visualizations to provide a quick overview of the patterns and trends and suggests promising analysis directions. Lux features a high-level language for generating visualizations on-demand to encourage rapid visual experimentation with data. We demonstrate that through the use of a careful design and three system optimizations, Lux adds no more than two seconds of overhead on top of pandas for over 98% of datasets in the UCI repository. We evaluate Lux in terms of usability via a controlled first-use study and interviews with early adopters, finding that Lux helps fulfill the needs of data scientists for visualization support within their dataframe workflows. Lux has already been embraced by data science practitioners, with over 1.9k stars on Github within its first 15 months.
SP  - NA
EP  - NA
JF  - arXiv: Databases
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Tyagi, Anjul; Zhao, Jian; Patel, Pushkar; Khurana, Swasti; Mueller, Klaus
TI  - Infographics Wizard: Flexible Infographics Authoring and Design Exploration
PY  - 2022
AB  - Infographics are an aesthetic visual representation of information following specific design principles of human perception. Designing infographics can be a tedious process for non-experts and time-consuming, even for professional designers. With the help of designers, we propose a semi-automated infographic framework for general structured and flow-based infographic design generation. For novice designers, our framework automatically creates and ranks infographic designs for a user-provided text with no requirement for design input. However, expert designers can still provide custom design inputs to customize the infographics. We will also contribute an individual visual group (VG) designs dataset (in SVG), along with a 1k complete infographic image dataset with segmented VGs in this work. Evaluation results confirm that by using our framework, designers from all expertise levels can generate generic infographic designs faster than existing methods while maintaining the same quality as hand-designed infographics templates.
SP  - 121
EP  - 132
JF  - Computer Graphics Forum
VL  - 41
IS  - 3
PB  - 
DO  - 10.1111/cgf.14527
ER  - 

TY  - JOUR
AU  - Yi, Jiawen; Liu, Jiaojiao; Zhang, Chuanlong; Lu, Xiong
TI  - Magnetic Motion Tracking for Natural Human Computer Interaction: A Review
PY  - 2022
AB  - NA
SP  - 22356
EP  - 22367
JF  - IEEE Sensors Journal
VL  - 22
IS  - 23
PB  - 
DO  - 10.1109/jsen.2022.3215285
ER  - 

TY  - CHAP
AU  - Wang, Liwen; Sandor, Christian
TI  - Can You Perceive the Size Change? Discrimination Thresholds for Size Changes in Augmented Reality
PY  - 2021
AB  - NA
SP  - 25
EP  - 36
JF  - Virtual Reality and Mixed Reality
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-90739-6_2
ER  - 

TY  - NA
AU  - Bai, Zhen; Codick, Elizabeth; Tenesaca, Ashely; Hu, Wanyin; Yu, Xiurong; Hao, Peirong; Kurumada, Chigusa; Hall, Wyatte
TI  - Signing-on-the-Fly: Technology Preferences to Reduce Communication Gap between Hearing Parents and Deaf Children
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Interaction Design and Children
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3501712.3529741
ER  - 

TY  - JOUR
AU  - Chen, Tuochao; Li, Yaxuan; Tao, Songyun; Lim, Hyunchul; Sakashita, Mose; Zhang, Ruidong; Guimbretière, François; Zhang, Cheng
TI  - NeckFace: Continuously Tracking Full Facial Expressions on Neck-mounted Wearables
PY  - 2021
AB  - Facial expressions are highly informative for computers to understand and interpret a person's mental and physical activities. However, continuously tracking facial expressions, especially when the user is in motion, is challenging. This paper presents NeckFace, a wearable sensing technology that can continuously track the full facial expressions using a neck-piece embedded with infrared (IR) cameras. A customized deep learning pipeline called NeckNet based on Resnet34 is developed to learn the captured infrared (IR) images of the chin and face and output 52 parameters representing the facial expressions. We demonstrated NeckFace on two common neck-mounted form factors: a necklace and a neckband (e.g., neck-mounted headphones), which was evaluated in a user study with 13 participants. The study results showed that NeckFace worked well when the participants were sitting, walking, or after remounting the device. We discuss the challenges and opportunities of using NeckFace in real-world applications.
SP  - 1
EP  - 31
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 2
PB  - 
DO  - 10.1145/3463511
ER  - 

TY  - JOUR
AU  - Oinas-Kukkonen, Harri; Pohjolainen, Sami; Agyei, Eunice
TI  - Mitigating Issues With/of/for True Personalization.
PY  - 2022
AB  - A common but false perception persists about the level and type of personalization in the offerings of contemporary software, information systems, and services, known as Personalization Myopia: this involves a tendency for researchers to think that there are many more personalized services than there genuinely are, for the general audience to think that they are offered personalized services when they really are not, and for practitioners to have a mistaken idea of what makes a service personalized. And yet in an era, which mashes up large amounts of data, business analytics, deep learning, and persuasive systems, true personalization is a most promising approach for innovating and developing new types of systems and services-including support for behavior change. The potential of true personalization is elaborated in this article, especially with regards to persuasive software features and the oft-neglected fact that users change over time.
SP  - 844817
EP  - NA
JF  - Frontiers in artificial intelligence
VL  - 5
IS  - NA
PB  - 
DO  - 10.3389/frai.2022.844817
ER  - 

TY  - NA
AU  - Park, Chaeyong; Kim, Jeongwoo; Kim, Dong-Geun; Oh, Seungjae; Choi, Seungmoon
TI  - Vibration-Augmented Buttons: Information Transmission Capacity and Application to Interaction Design
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501849
ER  - 

TY  - NA
AU  - Nie, Liqiang; Jia, Mengzhao; Song, Xuemeng; Wu, Ganglu; Cheng, Harry; Gu, Jian
TI  - SIGIR - Multimodal Activation: Awakening Dialog Robots without Wake Words
PY  - 2021
AB  - When talking to the dialog robots, users have to activate the robot first from the standby mode with special wake words, such as "Hey Siri", which is apparently not user-friendly. The latest generation of dialog robots have been equipped with advanced sensors, like the camera, enabling multimodal activation. In this work, we work towards awaking the robot without wake words. To accomplish this task, we present a Multimodal Activation Scheme (MAS), consisting of two key components: audio-visual consistency detection and semantic talking intention inference. The first one is devised to measure the consistency between the audio and visual modalities in order to figure out weather the heard speech comes from the detected user in front of the camera. Towards this end, two heterogeneous CNN-based networks are introduced to convolutionalize the fine-grained facial landmark features and the MFCC audio features, respectively. The second one is to infer the semantic talking intention of the recorded speech, where the transcript of the speech is recognized and matrix factorization is utilized to uncover the latent human-robot talking topics. We ultimately devise different fusion strategies to unify these two components. To evaluate MAS, we construct a dataset containing 12,741 short videos recorded by 194 invited volunteers. Extensive experiments demonstrate the effectiveness of our scheme.
SP  - 491
EP  - 500
JF  - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3404835.3462964
ER  - 

TY  - NA
AU  - Schoop, Eldon; Huang, Forrest; Hartmann, Bjoern
TI  - CHI - UMLAUT: Debugging Deep Learning Programs using Program Structure and Model Behavior
PY  - 2021
AB  - Training deep neural networks can generate non-descriptive error messages or produce unusual output without any explicit errors at all. While experts rely on tacit knowledge to apply debugging strategies, non-experts lack the experience required to interpret model output and correct Deep Learning (DL) programs. In this work, we identify DL debugging heuristics and strategies used by experts, andIn this work, we categorize the types of errors novices run into when writing ML code, and map them onto opportunities where tools could help. We use them to guide the design of Umlaut. Umlaut checks DL program structure and model behavior against these heuristics; provides human-readable error messages to users; and annotates erroneous model output to facilitate error correction. Umlaut links code, model output, and tutorial-driven error messages in a single interface. We evaluated Umlaut in a study with 15 participants to determine its effectiveness in helping developers find and fix errors in their DL programs. Participants using Umlaut found and fixed significantly more bugs and were able to implement fixes for more bugs compared to a baseline condition.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445538
ER  - 

TY  - JOUR
AU  - Wang, Zihan; Li, Jiarong; Jin, Yuchao; Wang, Jiyu; Yang, Fang; Li, Gang; Ni, Xiaoyue; Ding, Wenbo
TI  - Sensing beyond itself: Multi-functional use of ubiquitous signals towards wearable applications
PY  - 2021
AB  - NA
SP  - 103091
EP  - NA
JF  - Digital Signal Processing
VL  - 116
IS  - NA
PB  - 
DO  - 10.1016/j.dsp.2021.103091
ER  - 

TY  - JOUR
AU  - Ren, Yili; Wang, Zi; Wang, Yichao; Tan, Sheng; Chen, Yingying; Yang, Jie
TI  - GoPose
PY  - 2022
AB  - <jats:p>This paper presents GoPose, a 3D skeleton-based human pose estimation system that uses WiFi devices at home. Our system leverages the WiFi signals reflected off the human body for 3D pose estimation. In contrast to prior systems that need specialized hardware or dedicated sensors, our system does not require a user to wear or carry any sensors and can reuse the WiFi devices that already exist in a home environment for mass adoption. To realize such a system, we leverage the 2D AoA spectrum of the signals reflected from the human body and the deep learning techniques. In particular, the 2D AoA spectrum is proposed to locate different parts of the human body as well as to enable environment-independent pose estimation. Deep learning is incorporated to model the complex relationship between the 2D AoA spectrums and the 3D skeletons of the human body for pose tracking. Our evaluation results show GoPose achieves around 4.7cm of accuracy under various scenarios including tracking unseen activities and under NLoS scenarios.</jats:p>
SP  - 1
EP  - 25
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 2
PB  - 
DO  - 10.1145/3534605
ER  - 

TY  - JOUR
AU  - Liu, Jingyang; Li, Yunzhi; Goel, Mayank
TI  - A semantic-based approach to digital content placement for immersive environments
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The Visual Computer
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/s00371-022-02707-8
ER  - 

TY  - NA
AU  - Wu, Shengzhi; Byrne, Daragh; Du, Ruofei; Steenson, Molly Wright
TI  - "Slurp" Revisited: Using 'system re-presencing' to look back on, encounter, and design with the history of spatial interactivity and locative media
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Designing Interactive Systems Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532106.3533464
ER  - 

TY  - JOUR
AU  - MATSUMOTO, Ayumi; NITTA, Masashi; SUEISHI, Tomohiro; ISHIKAWA, Masatoshi
TI  - Wide High-resolution Projection System Using High-speed Gaze Point Estimation
PY  - 2022
AB  - NA
SP  - 42
EP  - 51
JF  - Transactions of the Society of Instrument and Control Engineers
VL  - 58
IS  - 1
PB  - 
DO  - 10.9746/sicetr.58.42
ER  - 

TY  - NA
AU  - Aoki, Hiroaki; Ohnishi, Ayumi; Isoyama, Naoya; Terada, Tsutomu; Tsukamoto, Masahiko
TI  - AHs - FaceRecGlasses: A Wearable System for Recognizing Self Facial Expressions Using Compact Wearable Cameras
PY  - 2021
AB  - Facial expression images are useful for life-logging because they represent one’s emotions and mental state. However, using a wearable system to capture facial expressions from the front of the user obstructs the field of view. In this paper, we propose FaceRecGlasses, a compact wearable system that constantly records the user’s face and surroundings as images and indexes them with emotions without obstructing the user’s daily life. Our eyeglass-shaped device comprises two compact cameras and three mirrors, which enable the user’s facial expressions and surroundings to be captured constantly. The proposed system outputs a real-time pseudo-face-image by combining the captured facial components with a stored base-face-image. We investigated suitable facial areas to be captured by the proposed system and evaluated the recognition accuracy of the facial expressions captured. The results confirmed accuracies of 87.5%, 66.7%, and 71.4% for neutral emotion, happiness, and surprise, respectively, indicating that this method reproduces these three facial expressions to a high degree and can be applied to indexing of facial images.
SP  - 55
EP  - 65
JF  - Augmented Humans Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3458709.3458983
ER  - 

TY  - DATA
AU  - Baltz, Samuel; Agadjanian, Alexander; Chin, Declan; Curiel, John; DeLuca, Kevin; Dunham, James; Miranda, Jennifer; Phillips, Connor Halloran; Uhlman, Annabel; Wimpy, Cameron; Zárate, Marcos; Stewart, Charles
TI  - American election results at the precinct level.
PY  - 2022
AB  - We describe the creation and quality assurance of a dataset containing nearly all available precinct-level election results from the 2016, 2018, and 2020 American elections. Precincts are the smallest level of election administration, and election results at this granularity are needed to address many important questions. However, election results are individually reported by each state with little standardization or data quality assurance. We have collected, cleaned, and standardized precinct-level election results from every available race above the very local level in almost every state across the last three national election years. Our data include nearly every candidate for president, US Congress, governor, or state legislator, and hundreds of thousands of precinct-level results for judicial races, other statewide races, and even local races and ballot initiatives. In this article we describe the process of finding this information and standardizing it. Then we aggregate the precinct-level results up to geographies that have official totals, and show that our totals never differ from the official nationwide data by more than 0.457%.
SP  - 651
EP  - NA
JF  - Scientific data
VL  - 9
IS  - 1
PB  - 
DO  - 10.1038/s41597-022-01745-0
ER  - 

TY  - NA
AU  - Gleason, Cole; Pavel, Amy; Gururaj, Himalini; Kitani, Kris M.; Bigham, Jeffrey P.
TI  - ASSETS - Making GIFs Accessible
PY  - 2020
AB  - Social media platforms feature short animations known as GIFs, but they are inaccessible to people with vision impairments. Unlike static images, GIFs contain action and visual indications of sound, which can be challenging to describe in alternative text descriptions. We examine a large sample of inaccessible GIFs on Twitter to document how they are used and what visual elements they contain. In interviews with 10 blind Twitter users, we discuss what elements of GIF content should be described and their experiences with GIFs online. The participants compared alternative text descriptions with two other alternative audio formats: (i) the original audio from the GIF source video and (ii) a spoken audio description. We recommend that social media platforms automatically include alt text descriptions for popular GIFs (as Twitter has begun to do), and content producers create audio descriptions to ensure everyone has a rich and emotive experience with GIFs online.
SP  - NA
EP  - NA
JF  - The 22nd International ACM SIGACCESS Conference on Computers and Accessibility
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3373625.3417027
ER  - 

TY  - NA
AU  - Popoveniuc, Bogdan; Vatavu, Radu-Daniel
TI  - Transhumanism as a Philosophical and Cultural Framework for Extended Reality Applied to Human Augmentation
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 13th Augmented Human International Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532525.3532528
ER  - 

TY  - JOUR
AU  - Perelman, Gary; Dubois, Emmanuel; Probst, Alice; Serrano, Marcos
TI  - Visual Transitions around Tabletops in Mixed Reality: Study on a Visual Acquisition Task between Vertical Virtual Displays and Horizontal Tabletops
PY  - 2022
AB  - <jats:p>See-through Head-Mounted Displays (HMDs) offer interesting opportunities to augment the interaction space around screens, especially around horizontal tabletops. In such context, HMDs can display surrounding vertical virtual windows to complement the tabletop content with data displayed in close vicinity. However, the effects of such combination on the visual acquisition of targets in the resulting combined display space have scarcely been explored. In this paper we conduct a study to explore visual acquisitions in such contexts, with a specific focus on the analysis of visual transitions between the horizontal tabletop display and the vertical virtual displays (in front and on the side of the tabletop). To further study the possible visual perception of the tabletop content out of the HMD and its impact on visual interaction, we distinguished two solutions for displaying information on the horizontal tabletop: using the see-through HMD to display virtual content over the tabletop surface (virtual overlay), i.e. the content is only visible inside the HMD’s FoV, or using the tabletop itself (tabletop screen). 12 participants performed visual acquisition tasks involving the horizontal and vertical displays. We measured the time to perform the task, the head movements, the portions of the displays visible in the HMD’s field of view, the physical fatigue and the user’s preference. Our results show that it is faster to acquire virtual targets in the front display than on the side. Results reveal that the use of the virtual overlay on the tabletop slows down the visual acquisition compared to the use of the tabletop screen, showing that users exploit the visual perception of the tabletop content on the peripheral visual space. We were also able to quantify when and to which extent targets on the tabletop can be acquired without being visible within the HMD's field of view when using the tabletop screen, i.e. by looking under the HMD. These results lead to design recommendations for more efficient, comfortable and integrated interfaces combining tabletop and surrounding vertical virtual displays.</jats:p>
SP  - 660
EP  - 679
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - ISS
PB  - 
DO  - 10.1145/3567738
ER  - 

TY  - NA
AU  - Lin, David Chuan-En; Martelaro, Nikolas
TI  - Conference on Designing Interactive Systems - Learning Personal Style from Few Examples
PY  - 2021
AB  - A key task in design work is grasping the client’s implicit tastes. Designers often do this based on a set of examples from the client. However, recognizing a common pattern among many intertwining variables such as color, texture, and layout and synthesizing them into a composite preference can be challenging. In this paper, we leverage the pattern recognition capability of computational models to aid in this task. We offer a set of principles for computationally learning personal style. The principles are manifested in PseudoClient, a deep learning framework that learns a computational model for personal graphic design style from only a handful of examples. In several experiments, we found that PseudoClient achieves a 79.40% accuracy with only five positive and negative examples, outperforming several alternative methods. Finally, we discuss how PseudoClient can be utilized as a building block to support the development of future design applications.
SP  - 1566
EP  - 1578
JF  - Designing Interactive Systems Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3461778.3462115
ER  - 

TY  - NA
AU  - Schmitz, Martin; Riemann, Jan; Müller, Florian; Kreis, Steffen; Mühlhäuser, Max
TI  - CHI - Oh, Snap! A Fabrication Pipeline to Magnetically Connect Conventional and 3D-Printed Electronics
PY  - 2021
AB  - 3D printing has revolutionized rapid prototyping by speeding up the creation of custom-shaped objects. With the rise of multi-material 3D printers, these custom-shaped objects can now be made interactive in a single pass through passive conductive structures. However, connecting conventional electronics to these conductive structures often still requires time-consuming manual assembly involving many wires, soldering or gluing. To alleviate these shortcomings, we propose : a fabrication pipeline and interfacing concept to magnetically connect a 3D-printed object equipped with passive sensing structures to conventional sensing electronics. To this end, utilizes ferromagnetic and conductive 3D-printed structures, printable in a single pass on standard printers. We further present a proof-of-concept capacitive sensing board that enables easy and robust magnetic assembly to quickly create interactive 3D-printed objects. We evaluate by assessing the robustness and quality of the connection and demonstrate its broad applicability by a series of example applications.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445641
ER  - 

TY  - CHAP
AU  - Tsukuda, Yuga; Tagami, Daichi; Sadasue, Masaaki; Suzuki, Shieru; Lu, Jun-Li; Ochiai, Yoichi
TI  - Calmbots: Exploring Madagascar Cockroaches as Living Ubiquitous Interfaces
PY  - 2022
AB  - NA
SP  - 522
EP  - 541
JF  - Lecture Notes in Computer Science
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-05028-2_35
ER  - 

TY  - NA
AU  - Signer, Madlaina; Ion, Alexandra; Sorkine-Hornung, Olga
TI  - CHI - Developable Metamaterials: Mass-fabricable Metamaterials by Laser-Cutting Elastic Structures
PY  - 2021
AB  - We propose a novel design of engineered, structured materials that leverages fast fabrication technologies, pushing them towards mass-fabrication. Specifically, our metamaterial is designed to be laser cut, to approximate the volumetric shape and allow for locally varying compliance. Traditional mechanical metamaterials consist of intricate cells arranged on a 3-dimensional grid, limiting them to 3D printing—which is slow. Our metamaterial is designed for laser cutting, which is drastically faster. Our structures are best described as ruffled strips of thin sheet material, such as paper, plastics, metals, etc. Users can interactively define the ruffles’ anisotropic stiffness directions and local density. Our computational design tool assists users by automatically optimizing the ruffle to fill the shape’s volume, and exporting the flat ruffle design ready for cutting. We demonstrate how such ruffled metamaterials can be utilized for, e.g., custom toys with locally varying compliance, custom packaging material, or lightweight formwork for architectural shells.
SP  - 674
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445666
ER  - 

TY  - NA
AU  - Tu, Jason; Jeyachandra, Angeline Vidhula; Nagesh, Deepthi; Prabhu, Naresh; Starner, Thad
TI  - ISWC - Typing on Tap: Estimating a Finger-Worn One-Handed Chording Keyboard’s Text Entry Rate
PY  - 2021
AB  - The Tap StrapTM enables eyes-free mobile typing using a one-hand device worn on the user’s fingers. Using the standard MacKenzie-Soukoreff text entry phrase set, 12 participants completed 480 minutes of practice with the keyboard on either their dominant or non-dominant hand. Average final typing rate was 22.11 words per minute (WPM), and letter accuracy increased from 85.11% to 91.02%. Non-dominant hand users typed more accurately than dominant after 420 minutes of practice.
SP  - 156
EP  - 158
JF  - 2021 International Symposium on Wearable Computers
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3460421.3480428
ER  - 

TY  - NA
AU  - Gao, Weiyue; Xiang, Wei; Liu, Xuanhui; Wang, Xueyou; Sun, Lingyun
TI  - Impacts of Presenting Extra Information in Short Videos via Text and Voice on User Experience
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 14th International Conference on Quality of Multimedia Experience (QoMEX)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/qomex55416.2022.9900918
ER  - 

TY  - NA
AU  - Sato, Hiroki; Niiyama, Ryuma; Narumi, Koya; Seong, Young ah; Watanabe, Keisuke; Yamamura, Ryosuke; Kakehi, Yasuaki; Kawahara, Yoshihiro
TI  - Demonstrating poimo as Inflatable, Inclusive Mobility Devices with a Soft Input Interface
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Special Interest Group on Computer Graphics and Interactive Techniques Conference Emerging Technologies
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532721.3544020
ER  - 

TY  - NA
AU  - Nishida, Jun; Tanaka, Yudai; Nith, Romain; Lopes, Pedro
TI  - DigituSync: A Dual-User Passive Exoskeleton Glove That Adaptively Shares Hand Gestures
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545630
ER  - 

TY  - NA
AU  - Hori, Ryosuke; Hachiuma, Ryo; Saito, Hideo; Isogawa, Mariko; Mikami, Dan
TI  - Silhouette-Based Synthetic Data Generation For 3D Human Pose Estimation With A Single Wrist-Mounted 360° Camera
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - 2021 IEEE International Conference on Image Processing (ICIP)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/icip42928.2021.9506043
ER  - 

TY  - NA
AU  - Li, Toby Jia-Jun; Chen, Jingya; Xia, Haijun; Mitchell, Tom M.; Myers, Brad A.
TI  - UIST - Multi-Modal Repairs of Conversational Breakdowns in Task-Oriented Dialogs
PY  - 2020
AB  - A major problem in task-oriented conversational agents is the lack of support for the repair of conversational breakdowns. Prior studies have shown that current repair strategies for these kinds of errors are often ineffective due to: (1) the lack of transparency about the state of the system's understanding of the user's utterance; and (2) the system's limited capabilities to understand the user's verbal attempts to repair natural language understanding errors. This paper introduces SOVITE, a new multi-modal speech plus direct manipulation interface that helps users discover, identify the causes of, and recover from conversational breakdowns using the resources of existing mobile app GUIs for grounding. SOVITE displays the system's understanding of user intents using GUI screenshots, allows users to refer to third-party apps and their GUI screens in conversations as inputs for intent disambiguation, and enables users to repair breakdowns using direct manipulation on these screenshots. The results from a remote user study with 10 users using SOVITE in 7 scenarios suggested that SOVITE's approach is usable and effective.
SP  - 1094
EP  - 1107
JF  - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3379337.3415820
ER  - 

TY  - JOUR
AU  - Stellmacher, Carolin; Bonfert, Michael; Kruijff, Ernst; Schöning, Johannes
TI  - Triggermuscle: Exploring Weight Perception for Virtual Reality Through Adaptive Trigger Resistance in a Haptic VR Controller
PY  - 2022
AB  - <jats:p>It is challenging to provide users with a haptic weight sensation of virtual objects in VR since current consumer VR controllers and software-based approaches such as pseudo-haptics cannot render appropriate haptic stimuli. To overcome these limitations, we developed a haptic VR controller named <jats:italic>Triggermuscle</jats:italic> that adjusts its trigger resistance according to the weight of a virtual object. Therefore, users need to adapt their index finger force to grab objects of different virtual weights. Dynamic and continuous adjustment is enabled by a spring mechanism inside the casing of an HTC Vive controller. In two user studies, we explored the effect on weight perception and found large differences between participants for sensing change in trigger resistance and thus for discriminating virtual weights. The variations were easily distinguished and associated with weight by some participants while others did not notice them at all. We discuss possible limitations, confounding factors, how to overcome them in future research and the pros and cons of this novel technology.</jats:p>
SP  - NA
EP  - NA
JF  - Frontiers in Virtual Reality
VL  - 2
IS  - NA
PB  - 
DO  - 10.3389/frvir.2021.754511
ER  - 

TY  - JOUR
AU  - Islam, Muhammad Zubair; Ali, Rashid; Haider, Amir; Kim, Hyung Seok
TI  - QoS Provisioning: Key Drivers and Enablers Toward the Tactile Internet in Beyond 5G Era
PY  - 2022
AB  - The Tactile Internet has become a revolution for Internet technology, greatly improving the transmission of skill sets (audio, video, text, and haptics) over communication channels compared with traditional triple-play data (audio, video, text). It is a strong candidate to support next-generation delay-sensitive and loss-intolerant smart applications. However, stringent requirements for the Tactile Internet, including ultra-low latency, ultra-high reliability, high availability, and ultra-security, present critical challenges to ensure Quality of Service (QoS). Consequently, several approaches have been proposed to meet these QoS requirements. This article reviews QoS provisioning approaches for the Tactile Internet. First, we present key concepts for the fifth-generation and beyond technologies, Tactile Internet, and haptic communication. Second, we discuss the Tactile Internet use cases along with strict QoS requirements. Third, we classify existing solutions, including haptic codecs, control system designs, hybrid schemes, and intelligent prediction models; provide in-depth discussion regarding these approaches to improve QoS for the Tactile Internet applications; and investigate strengths and weaknesses for each proposed solution. Finally, we present open research challenges and discuss potential future research avenues to realize the Tactile Internet services.
SP  - 85720
EP  - 85754
JF  - IEEE Access
VL  - 10
IS  - NA
PB  - 
DO  - 10.1109/access.2022.3197900
ER  - 

TY  - NA
AU  - Yigitbas, Enes; Klauke, Jonas; Gottschalk, Sebastian; Engels, Gregor
TI  - VREUD -- An End-User Development Tool to Simplify the Creation of Interactive VR Scenes
PY  - 2021
AB  - Recent advances in Virtual Reality (VR) technology and the increased availability of VR-equipped devices enable a wide range of consumer-oriented applications. For novice developers, however, creating interactive scenes for VR applications is a complex and cumbersome task that requires high technical knowledge which is often missing. This hinders the potential of enabling novices to create, modify, and execute their own interactive VR scenes. Although recent authoring tools for interactive VR scenes are promising, most of them focus on expert professionals as the target group and neglect the novices with low programming knowledge. To lower the entry barrier, we provide an open-source web-based End-User Development (EUD) tool, called VREUD, that supports the rapid construction and execution of interactive VR scenes. Concerning construction, VREUD enables the specification of the VR scene including interactions and tasks. Furthermore, VREUD supports the execution and immersive experience of the created interactive VR scenes on VR head-mounted displays. Based on a user study, we have analyzed the effectiveness, efficiency, and user satisfaction of VREUD which shows promising results to empower novices in creating their interactive VR scenes.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Lee, Dajin; Oh, Seungjae; Choi, Seungmoon; You, Bum-Jae
TI  - WHC - Vibrotactile Metaphor of Physical Interaction Using Body-Penetrating Phantom Sensations: Stepping on a Virtual Object
PY  - 2021
AB  - During locomotion, people perceive rich haptic information from the floor and the object in contact with their feet. Conventional simulation of such physical interaction in virtual reality is mostly limited to expressing the material or texture of the floor by stimulating only the sole of a foot using vibrotactile stimuli. This paper presents a vibrotactile metaphor that mimics the physical interaction of stepping on a virtual object using body-penetrating phantom sensations between the sole and the instep. For both passive and active perception, we compare the effectiveness between the penetrating illusion and the single stimulation on the sole, with and without visual feedback. Experimental results show that our vibrotactile metaphor is effective for passive perception and less effective when there is active user movement. Our discovery enriches virtual tactile experiences that can be felt with the feet.
SP  - 367
EP  - 372
JF  - 2021 IEEE World Haptics Conference (WHC)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/whc49131.2021.9517144
ER  - 

TY  - NA
AU  - Suzuki, Ryo; Ofek, Eyal; Sinclair, Mike; Leithinger, Daniel; Gonzalez-Franco, Mar
TI  - UIST (Adjunct Volume) - Demonstrating HapticBots: Distributed Encountered-type Haptics for VR with Multiple Shape-changing Mobile Robots
PY  - 2021
AB  - HapticBots introduces a novel encountered-type haptic approach for Virtual Reality (VR) based on multiple tabletop-size shape-changing robots. These robots move on a tabletop and change their height and orientation to haptically render various surfaces and objects on-demand. Compared to previous encountered-type haptic approaches like shape displays or robotic arms, our proposed approach has an advantage in deployability, scalability, and generalizability—these robots can be easily deployed due to their compact form factor. They can support multiple concurrent touch points in a large area thanks to the distributed nature of the robots. We propose and evaluate a novel set of interactions enabled by these robots which include: 1) rendering haptics for VR objects by providing just-in-time touch-points on the user’s hand, 2) simulating continuous surfaces with the concurrent height and position change, and 3) enabling the user to pick up and move VR objects through graspable proxy objects. Finally, we demonstrate HapticBots with various applications, including remote collaboration, education and training, design and 3D modeling, and gaming and entertainment.
SP  - 131
EP  - 133
JF  - The Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3474349.3480202
ER  - 

TY  - NA
AU  - Liu, Jingyang
TI  - Intelligent Environments - Semantic Mapping: A Semantics-based Approach to Virtual Content Placement for Immersive Environments
PY  - 2021
AB  - Semantic Mapping is a semantics-based interactive system that enables intuitive virtual content placement for projection mapping in intelligent environments. Our semantic mapping system embeds semantic information of the environment to provide a user with an easy way to control and place projected virtual items in the physical world. In contrast to traditional projection mapping that involves manual adjustments, this semantic mapping system enables efficient manipulation of virtual content through inputs from users via speech or text. To build the system, we first use a commercial depth camera for scene reconstruction and an end-to-end deep learning framework for semantic segmentation at the instance level. We illustrate the system by developing a prototype for a set of proof-of-concept, room-scale applications. The accuracy study and user study results show that the system can provide users with accurate semantic information for effective virtual content placement.
SP  - 1
EP  - 8
JF  - 2021 17th International Conference on Intelligent Environments (IE)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ie51775.2021.9486580
ER  - 

TY  - NA
AU  - Suzuki, Ryo; Kazi, Rubaiat Habib; Wei, Li-Yi; DiVerdi, Stephen; Li, Wilmot; Leithinger, Daniel
TI  - UIST (Adjunct Volume) - RealitySketch: Embedding Responsive Graphics and Visualizations in AR through Dynamic Sketching
PY  - 2020
AB  - We present RealitySketch, an augmented reality interface for sketching interactive graphics and visualizations. In recent years, an increasing number of AR sketching tools enable users to draw and embed sketches in the real world. However, with the current tools, sketched contents are inherently static, floating in mid air without responding to the real world. This paper introduces a new way to embed dynamic and responsive graphics in the real world. In RealitySketch, the user draws graphical elements on a mobile AR screen and binds them with physical objects in real-time and improvisational ways, so that the sketched elements dynamically move with the corresponding physical motion. The user can also quickly visualize and analyze real-world phenomena through responsive graph plots or interactive visualizations. This paper contributes to a set of interaction techniques that enable capturing, parameterizing, and visualizing real-world motion without pre-defined programs and configurations. Finally, we demonstrate our tool with several application scenarios, including physics education, sports training, and in-situ tangible interfaces.
SP  - 135
EP  - 138
JF  - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3379337.3415892
ER  - 

TY  - JOUR
AU  - Lambrichts, Mannu; Ramakers, Raf; Hodges, Steve; Coppers, Sven; Devine, James
TI  - A Survey and Taxonomy of Electronics Toolkits for Interactive and Ubiquitous Device Prototyping
PY  - 2021
AB  - Over the past two decades, many toolkits for prototyping interactive and ubiquitous electronic devices have been developed. Although their technical specifications are often easy to look up, they vary greatly in terms of design, features and target audience, resulting in very real strengths and weaknesses depending on the intended application. These less technical characteristics are often reported inconsistently, if at all. In this paper we provide a comprehensive survey of interactive and ubiquitous device prototyping toolkits, systematically analysing their characteristics within the framework of a new taxonomy that we present. In addition to the specific characteristics we cover, we introduce a way to evaluate toolkits more holistically, covering user needs such as 'ease of construction' and 'ease of moving from prototype to product' rather than features. We also present results from an online survey which offers new insights on how the surveyed users prioritize these characteristics during prototyping, and what techniques they use to move beyond prototyping. We hope our analysis will be valuable for others in the community who need to build and potentially scale out prototypes as part of their research. We end by identifying gaps that have not yet been addressed by existing offerings and discuss opportunities for future research into electronics prototyping toolkits.
SP  - 1
EP  - 24
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 2
PB  - 
DO  - 10.1145/3463523
ER  - 

TY  - JOUR
AU  - Ye, Xupeng
TI  - A Survey on Simulation for Weight Perception in Virtual Reality
PY  - 2021
AB  - Virtual reality (VR) technology can provide users with an immersive experience as if they are in the real world, which can be applied in the fields of entertainment, education and scientific research, etc. In order to improve the sense of presence and immersion in VR, the design of multimodal feedback is an important component. In particular, the simulation of weight of virtual objects poses many challenges due to the limitations of hardware and software. Many researchers focused on this issue in various ways. These methods are mainly divided into two categories: device-based simulation and software-based simulation. This paper investigates the focus of software-based simulation, particularly for the virtual feedback methods proposed by researchers in recent years. We introduce the background of these proposed methods, technical implementation principles, application scenarios, the advantages and disadvantages of these simulation methods, and the evaluation criteria. We also propose the future challenges and the development of simulation methods for weight perception of virtual objects in VR.
SP  - 1
EP  - 24
JF  - Journal of Computer and Communications
VL  - 9
IS  - 9
PB  - 
DO  - 10.4236/jcc.2021.99001
ER  - 

TY  - NA
AU  - Wang, Jian; Liu, Lingjie; Xu, Weipeng; Sarkar, Kripasindhu; Theobalt, Christian
TI  - Estimating Egocentric 3D Human Pose in Global Space
PY  - 2021
AB  - Egocentric 3D human pose estimation using a single fisheye camera has become popular recently as it allows capturing a wide range of daily activities in unconstrained environments, which is difficult for traditional outside-in motion capture with external cameras. However, existing methods have several limitations. A prominent problem is that the estimated poses lie in the local coordinate system of the fisheye camera, rather than in the world coordinate system, which is restrictive for many applications. Furthermore, these methods suffer from limited accuracy and temporal instability due to ambiguities caused by the monocular setup and the severe occlusion in a strongly distorted egocentric perspective. To tackle these limitations, we present a new method for egocentric global 3D body pose estimation using a single head-mounted fish-eye camera. To achieve accurate and temporally stable global poses, a spatio-temporal optimization is performed over a sequence of frames by minimizing heatmap reprojection errors and enforcing local and global body motion priors learned from a mocap dataset. Experimental results show that our approach outperforms state-of-the-art methods both quantitatively and qualitatively.
SP  - NA
EP  - NA
JF  - 2021 IEEE/CVF International Conference on Computer Vision (ICCV)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/iccv48922.2021.01130
ER  - 

TY  - NA
AU  - Wang, Xinrong; Fang, Xinyue; Zheng, Xinyj; Deng, Xuemei; Li, Yong; Wang, Mei
TI  - Brain Oscillatory Representations of Vibrotactile Parameters: An EEG Study
PY  - 2022
AB  - In the BCI community, haptic feedback allows us to interact with the world around us and, at the same time, perceive these interactions. For the development and maturation of neurophysiology related to haptic feedback, it is requisite to conduct more in-depth researches. To this end, we explored brain oscillatory representations of vibrotactile parameters. We utilized amplitude-modulated vibrotactile stimuli, which have four envelope frequency levels and four amplitude levels. Relevant brain oscillations in five frequency bands and ten channels were measured by noninvasive EEG technique, and they were represented in baseline-based power spectral density (PSD) forms. Results, expressed in interaction effect maps and P-value topographic maps mainly, showed that there were significant interaction effects among envelop frequency, amplitude, frequency band, and electrode position. In particular, when envelope frequency (Fe)&#x003D; 40 Hz, from alpha band 1 to beta band 1, for all four amplitude levels, brain oscillations over the ipsilateral sensorimotor cortex decreased gradually. Additionally, a slight decrease of brain activation in the contralateral frontal regions was found in the two higher levels of amplitude. When amplitude (A)&#x003D; 0.8 Grms, from alpha band 1 to beta band 1, for all four envelope frequency levels, brain oscillations over the bilateral sensorimotor cortex decreased gradually. In addition, a increase of brain oscillation in the frontal and parietal regions was found in the two higher envelope frequency levels. Results contribute to a deeper physiological understanding for physical vibrotactile parameters.
SP  - NA
EP  - NA
JF  - 2022 5th International Conference on Computing and Informatics (ICCI)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/icci54321.2022.9756106
ER  - 

TY  - NA
AU  - Shimobayashi, Hideki; Sasaki, Tomoya; Horie, Arata; Arakawa, Riku; Kashino, Zendai; Inami, Masahiko
TI  - AHs - Independent Control of Supernumerary Appendages Exploiting Upper Limb Redundancy
PY  - 2021
AB  - In the field of physical augmentation, researchers have attempted to extend human capabilities by expanding the number of human appendages. To fully realize the potential of having an additional appendage, supernumerary appendages should be independently controllable without interfering with the functionality of existing appendages. Herein, we propose a novel approach for controlling supernumerary appendages by exploiting upper limb redundancy. We present a headphone-style visual sensing device and a recognition system to estimate shoulder movement. Through a set of user experiments, we evaluate the feasibility of our system and reveal the potential of independent control using upper limb redundancy. Our results indicate that participants are able to intentionally give commands through their shoulder motions. Finally, we demonstrate the wide range of supernumerary appendage control applications that our novel approach enables and discuss future prospects for our work.
SP  - 19
EP  - 30
JF  - Augmented Humans Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3458709.3458980
ER  - 

TY  - JOUR
AU  - Pratticò, Filippo Gabriele; De Lorenzis, Federico; Calandra, Davide; Cannavo, Alberto; Lamberti, Fabrizio
TI  - Exploring simulation-based virtual reality as a mock-up tool to support the design of first responders training
PY  - 2021
AB  - Intervention by First Responders (FRs) is essential in disaster response, and their preparation greatly benefits from continuous updates. However, the design of effective training experiences targeted to FRs can be very demanding from the viewpoint of a Training Provisioner (TP). Virtual Reality (VR) may have a key role to play in enhancing and facilitating this task. In fact, VR technology has already proven to be very helpful in the field of emergency training, as well as its use as a powerful design and mock-up tool in many other contexts. In this work, the application of VR as a mock-up tool supporting TPs in the arrangement and validation of a training experience, either real or virtual, is explored. In particular, a case study is considered concerning the training of an FR for hydro-geological risks. Within this context, the proposed approach is compared against dramaturgy prototyping, a method commonly used for the design of experiential courses. Results indicate that the adoption of a VR-based mock-up tool (VRMT) can provide TPs with good insights on the arrangement of the training and precious indications on how to actually map this information onto real-world exercises.
SP  - 7527
EP  - NA
JF  - Applied Sciences
VL  - 11
IS  - 16
PB  - 
DO  - 10.3390/app11167527
ER  - 

TY  - CHAP
AU  - Fanini, Bruno; Demetrescu, Emanuel; Bucciero, Alberto; Chirivi, Alessandra; Giuri, Francesco; Ferrari, Ivan; Delbarba, Nicola
TI  - Building Blocks for Multi-dimensional WebXR Inspection Tools Targeting Cultural Heritage
PY  - 2022
AB  - AbstractData exploration and inspection within semantically enriched multi-dimensional contexts, may benefit of immersive VR presentation when proper 3D user interfaces are adopted. WebXR represents a great opportunity to investigate, experiment, develop and assess advanced multi-dimensional interactive tools for Cultural Heritage, making them accessible through a common web browser. We present and describe the potential of WebXR and a set of building blocks for crafting such immersive data inspection tools, exploiting recent web standards and spatial user interfaces. We describe the current state of the EMviq tool - developed within SSHOC European project - and how it is taking advantage of these components for online immersive sessions. The EMviq tool allows to visually inspect and query an Extended Matrix dataset, allowing to query and explore all the information within the knowledge graph relating to the interpretative datasets - in this paper applied to the case studies of the Roman theatre of Catania and Montebelluna smithy. The main functionalities discussed are spatio-temporal exploration, search and selection of stratigraphic units, and the presentation of metadata and paradata related to the data provenance (both objective and interpretative).KeywordsWebXRWeb3DGraph-DBImmersive VRSemantic inspection
SP  - 373
EP  - 390
JF  - Extended Reality
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-15553-6_26
ER  - 

TY  - BOOK
AU  - Stellmacher, Carolin
TI  - VR Workshops - Haptic-Enabled Buttons Through Adaptive Trigger Resistance
PY  - 2021
AB  - While commercial controllers for virtual reality (VR) offer a variety of components to register user input, their ability to generate meaningful haptic feedback during the interaction lags behind. This prevents users from experiencing the virtual world through their haptic sense. For example, grabbing a light virtual object feels identical to grabbing a heavy virtual object. In this workshop paper, we enrich an established input component available in any commercial VR controller with appropriate haptic rendering capabilities. As a proof of concept, we present our haptic VR controller Triggermuscle and its adaptive trigger to simulate weight in VR. The trigger dynamically adapts its resistance according to the weight of a grabbed virtual object: The heavier the virtual object, the higher the trigger resistance and the more force users need to apply. Our system is built into the casing of an HTC Vive controller and connects the original trigger component to an extension spring for variable resistance. We envision for the future, that VR input devices can evolve more into input-output technologies and provide meaningful and versatile haptic feedback.
SP  - 201
EP  - 204
JF  - 2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vrw52623.2021.00044
ER  - 

TY  - NA
AU  - Aigner, Roland; Pointner, Andreas; Preindl, Thomas; Danner, Rainer; Haller, Michael J.
TI  - CHI - TexYZ: Embroidering Enameled Wires for Three Degree-of-Freedom Mutual Capacitive Sensing
PY  - 2021
AB  - In this paper, we present TexYZ, a method for rapid and effortless manufacturing of textile mutual capacitive sensors using a commodity embroidery machine. We use enameled wire as a bobbin thread to yield textile capacitors with high quality and consistency. As a consequence, we are able to leverage the precision and expressiveness of projected mutual capacitance for textile electronics, even when size is limited. Harnessing the assets of machine embroidery, we implement and analyze five distinct electrode patterns, examine the resulting electrical features with respect to geometrical attributes, and demonstrate the feasibility of two promising candidates for small-scale matrix layouts. The resulting sensor patches are further evaluated in terms of capacitance homogeneity, signal-to-noise ratio, sensing range, and washability. Finally, we demonstrate two use case scenarios, primarily focusing on continuous input with up to three degrees-of-freedom.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445479
ER  - 

TY  - JOUR
AU  - Li, Jingyi; Mayer, Alexandra; Butz, Andreas
TI  - Towards a Design Space of Haptics in Everyday Virtual Reality across Different Spatial Scales
PY  - 2021
AB  - Virtual Reality (VR) has become a consumer-grade technology, especially with the advent of standalone headsets working independently from a powerful computer. Domestic VR mainly uses the visual and auditory senses since VR headsets make this accessible. Haptic feedback, however, has the potential to increase immersion substantially. So far, it is mostly used in laboratory settings with specialized haptic devices. Especially for domestic VR, there is underexplored potential in exploiting physical elements of the often confined space in which it is used. In a literature review (n = 20), we analyzed VR interaction using haptic feedback with or without physical limitations. From this, we derive a design space for VR haptics across three spatial scales (seated, standing, and walking). In our narrow selection of papers, we found inspirations for future work and will discuss two example scenarios. Our work gives a current overview of haptic VR solutions and highlights strategies for adapting laboratory solutions to an everyday context.
SP  - 36
EP  - NA
JF  - Multimodal Technologies and Interaction
VL  - 5
IS  - 7
PB  - 
DO  - 10.3390/mti5070036
ER  - 

TY  - NA
AU  - Miyashita, Homei
TI  - UIST (Adjunct Volume) - TTTV (Taste the TV): Taste Presentation Display for “Licking the Screen” using a Rolling Transparent Sheet and a Mixture of Liquid Sprays
PY  - 2021
AB  - Reproducing the taste of food and beverages as a media technology is an emerging problem of commercial value and entertainment utility. An already developed taste reproduction system uses electrolyte containing gels controlled by electric current to reproduce taste by ion-phoresis. In this study, an alternative taste reproduction mechanism was proposed that sprays a mixture of liquids on a rolling transparent sheet placed on a screen that displays the image of the food item under consideration for reproduction of its taste.
SP  - 37
EP  - 40
JF  - The Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3474349.3480223
ER  - 

TY  - BOOK
AU  - Ritchie, Jackie; Bontilao, Joselle; Kennelly, Sarah; Topliss, Jack; Dunn, Jessica; Renaud, Andre; Huber, Tim; de Gast, Barro W; Piumsomboon, Thammathip
TI  - AsianCHI@CHI - COMFlex: An Adaptive Haptic Interface with Shape-Changing and Weight-Shifting Mechanism for Immersive Virtual Reality
PY  - 2021
AB  - This work explores shape-changing and weight-shifting mechanisms for haptic interfaces to simulate various shapes and sizes in Virtual Reality (VR) for the industrial product design process. The COMFlex system offers haptic feedback in the form of a weight distribution changing (COM) and shape-changing (Flex) device while perceiving a visual representation in VR. Any state changes to the virtual representation are reflected by the COMFlex system, allowing live dynamic feedback to the user. We share initial findings from experimenting with COMFlex in several use cases for our follow up design improvements. Finally, future work is discussed, including physical changes to the device and potential applications.
SP  - 210
EP  - 214
JF  - Asian CHI Symposium 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3429360.3468214
ER  - 

TY  - NA
AU  - Coccoli, Mauro; Galluccio, Ilenia; Torre, Ilaria; Amenduni, Francesca; Cattaneo, Alberto; Clarke, Christopher
TI  - Advanced Visual Interfaces for Augmented Video
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 2022 International Conference on Advanced Visual Interfaces
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3531073.3535253
ER  - 

TY  - JOUR
AU  - Kim, Huhn; Baek, Mi-Seon
TI  - Moment Controller: VR Controller raises Awareness of the Difference in Weight between Virtual Objects
PY  - 2021
AB  - NA
SP  - 133
EP  - 151
JF  - Archives of Design Research
VL  - 34
IS  - 2
PB  - 
DO  - 10.15187/adr.2021.05.34.2.133
ER  - 

TY  - JOUR
AU  - Fletcher, Mark D.
TI  - Can Haptic Stimulation Enhance Music Perception in Hearing-Impaired Listeners?
PY  - 2021
AB  - Cochlear implants (CIs) have been remarkably successful at restoring hearing in severely-to-profoundly hearing-impaired individuals. However, users often struggle to deconstruct complex auditory scenes with multiple simultaneous sounds, which can result in reduced music enjoyment and impaired speech understanding in background noise. Hearing aid users often have similar issues, though these are typically less acute. Several recent studies have shown that haptic stimulation can enhance CI listening by giving access to sound features that are poorly transmitted through the electrical CI signal. This "electro-haptic stimulation" improves melody recognition and pitch discrimination, as well as speech-in-noise performance and sound localization. The success of this approach suggests it could also enhance auditory perception in hearing-aid users and other hearing-impaired listeners. This review focuses on the use of haptic stimulation to enhance music perception in hearing-impaired listeners. Music is prevalent throughout everyday life, being critical to media such as film and video games, and often being central to events such as weddings and funerals. It represents the biggest challenge for signal processing, as it is typically an extremely complex acoustic signal, containing multiple simultaneous harmonic and inharmonic sounds. Signal-processing approaches developed for enhancing music perception could therefore have significant utility for other key issues faced by hearing-impaired listeners, such as understanding speech in noisy environments. This review first discusses the limits of music perception in hearing-impaired listeners and the limits of the tactile system. It then discusses the evidence around integration of audio and haptic stimulation in the brain. Next, the features, suitability, and success of current haptic devices for enhancing music perception are reviewed, as well as the signal-processing approaches that could be deployed in future haptic devices. Finally, the cutting-edge technologies that could be exploited for enhancing music perception with haptics are discussed. These include the latest micro motor and driver technology, low-power wireless technology, machine learning, big data, and cloud computing. New approaches for enhancing music perception in hearing-impaired listeners could substantially improve quality of life. Furthermore, effective haptic techniques for providing complex sound information could offer a non-invasive, affordable means for enhancing listening more broadly in hearing-impaired individuals.
SP  - 723877
EP  - 723877
JF  - Frontiers in neuroscience
VL  - 15
IS  - NA
PB  - 
DO  - 10.3389/fnins.2021.723877
ER  - 

TY  - NA
AU  - Yang, Humphrey; Johnson, Tate; Zhong, Ke; Patel, Dinesh; Olson, Gina; Majidi, Carmel; Islam, Mohammad; Yao, Lining
TI  - ReCompFig: Designing Dynamically Reconfigurable Kinematic Devices Using Compliant Mechanisms and Tensioning Cables
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502065
ER  - 

TY  - CHAP
AU  - Deng, Heng; Lin, Jian
TI  - 4D Printing: 3D Printing of Responsive and Programmable Materials
PY  - 2022
AB  - NA
SP  - 213
EP  - 237
JF  - 3D Bioprinting and Nanotechnology in Tissue Engineering and Regenerative Medicine
VL  - NA
IS  - NA
PB  - 
DO  - 10.1016/b978-0-12-824552-1.00012-8
ER  - 

TY  - NA
AU  - Elsayed, Hesham; Kartono, Kenneth; Schön, Dominik; Schmitz, Martin; Mühlhäuser, Max; Weigel, Martin
TI  - Understanding Perspectives for Single- and Multi-Limb Movement Guidance in Virtual 3D Environments
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 28th ACM Symposium on Virtual Reality Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3562939.3565635
ER  - 

TY  - NA
AU  - Bhat, Shariq Farooq; Alhashim, Ibraheem; Wonka, Peter
TI  - CVPR - AdaBins: Depth Estimation Using Adaptive Bins
PY  - 2021
AB  - We address the problem of estimating a high quality dense depth map from a single RGB input image. We start out with a baseline encoder-decoder convolutional neural network architecture and pose the question of how the global processing of information can help improve overall depth estimation. To this end, we propose a transformer-based architecture block that divides the depth range into bins whose center value is estimated adaptively per image. The final depth values are estimated as linear combinations of the bin centers. We call our new building block AdaBins. Our results show a decisive improvement over the state-of-the-art on several popular depth datasets across all metrics. We also validate the effectiveness of the proposed block with an ablation study and provide the code and corresponding pre-trained weights of the new state-of-the-art model.
SP  - 4009
EP  - 4018
JF  - 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/cvpr46437.2021.00400
ER  - 

TY  - NA
AU  - Masson, Damien; Vermeulen, Jo; Fitzmaurice, George; Matejka, Justin
TI  - Supercharging Trial-and-Error for Learning Complex Software Applications
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501895
ER  - 

TY  - NA
AU  - Ikarashi, Yuka; Ragan-Kelley, Jonathan; Fukusato, Tsukasa; Kato, Jun; Igarashi, Takeo
TI  - VL/HCC - Guided Optimization for Image Processing Pipelines
PY  - 2021
AB  - Writing high-performance image processing code is challenging and labor-intensive. To address this, we propose a programming support method called “guided optimization.” Guided optimization provides programmers a set of valid optimization options and interactive feedback about their current choices, which enables them to comprehend and efficiently optimize image processing code without the time-consuming trial-and-error process of traditional text editors. We implemented a proof-of-concept system, Roly-poly, which integrates guided optimization, program visualization, and schedule cost estimation to support the comprehension and development of efficient image processing code. We conducted a user study with novice Halide programmers and confirmed that Roly-poly and its guided optimization was informative, increased productivity, and resulted in higher-performing schedules in less time.
SP  - 1
EP  - 5
JF  - 2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vl/hcc51201.2021.9576341
ER  - 

TY  - NA
AU  - Ushiyama, Keigo; Takahashi, Akifumi; Kajimoto, Hiroyuki
TI  - CHI Extended Abstracts - Modulation of a Hand-held Object's Property through Proprioceptive Stimulation during Active Arm Movement: Proprioceptive Modulation of a Hand-held Object's Property
PY  - 2021
AB  - The purpose of this study was to investigate whether stimulation of the proprioceptors in the arm during active movement can affect not only the proprioception of the arm but also the perception of the hand-held object. If it is possible to control the perception of a hand-held object through stimulation to the body, it can be applied to virtual-reality interfaces and controllers, which can be used in a wide range of situations. In the experiment, proprioceptive stimulation was based on the kinesthetic illusion induced by vibratory stimulation of muscle spindles and skin stretch near the joint. Participants were given a context in which they grasped an object and actively moved. They were asked to evaluate the perception of the object and the arm as the phase between movement and stimulation, and the conditions of stimuli were changed. Consequently, it was found that the perception of not only the arm but also the hand-held object could be changed, although there were large individual differences.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451834
ER  - 

TY  - NA
AU  - Sun, Wei; Li, Franklin Mingzhe; Steeper, Benjamin; Xu, Songlin; Tian, Feng; Zhang, Cheng
TI  - TeethTap: Recognizing Discrete Teeth Gestures Using Motion and Acoustic Sensing on an Earpiece
PY  - 2021
AB  - Teeth gestures become an alternative input modality for different situations and accessibility purposes. In this paper, we present TeethTap, a novel eyes-free and hands-free input technique, which can recognize up to 13 discrete teeth tapping gestures. TeethTap adopts a wearable 3D printed earpiece with an IMU sensor and a contact microphone behind both ears, which works in tandem to detect jaw movement and sound data, respectively. TeethTap uses a support vector machine to classify gestures from noise by fusing acoustic and motion data, and implements K-Nearest-Neighbor (KNN) with a Dynamic Time Warping (DTW) distance measurement using motion data for gesture classification. A user study with 11 participants demonstrated that TeethTap could recognize 13 gestures with a real-time classification accuracy of 90.9% in a laboratory environment. We further uncovered the accuracy differences on different teeth gestures when having sensors on single vs. both sides. Moreover, we explored the activation gesture under real-world environments, including eating, speaking, walking and jumping. Based on our findings, we further discussed potential applications and practical challenges of integrating TeethTap into future devices.
SP  - 161
EP  - 169
JF  - 26th International Conference on Intelligent User Interfaces
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3397481.3450645
ER  - 

TY  - NA
AU  - Ko, Donghyeon; Shin, Yeeun; Shin, Junbeom; Hong, Jiwoo; Lee, Woohun
TI  - ChromoFilament: Designing a Thermochromic Filament for Displaying Malleable States
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Designing Interactive Systems Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532106.3533479
ER  - 

TY  - JOUR
AU  - Ruiyuan, Wang; Zhihua, Li; Shi, Jiyong; Holmes, Melvin; Wang, Xinyu; Zhang, Junjun; Zhai, Xiaodong; Xiaowei, Huang; Zou, Xiaobo
TI  - Color 3D printing of pulped yam utilizing a natural pH sensitive pigment
PY  - 2021
AB  - NA
SP  - 102062
EP  - NA
JF  - Additive Manufacturing
VL  - 46
IS  - NA
PB  - 
DO  - 10.1016/j.addma.2021.102062
ER  - 

TY  - NA
AU  - Sima, Karel; Navratil, Jiri; Hladikova, Julie; Bouzek, Stanislav; Hamacek, Ales
TI  - Design and Characterization of Embroidered Electroacoustic Transducer
PY  - 2022
AB  - This paper is focused on designing and characterization of embroidered electroacoustic transducer placed on the magnet. This type of transducer can be used as a feedback or notification element in an advanced smart textile system. Multiple transducer designs and threads were used in the experiment. Results from measuring of acoustic level have showed, that embroidered electroacoustic transducer can be used as a full-featured speaker for the feedback system. The results have showed the ability to play simple sounds and melodies through this electroacoustic transducer.
SP  - NA
EP  - NA
JF  - 2022 45th International Spring Seminar on Electronics Technology (ISSE)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/isse54558.2022.9812821
ER  - 

TY  - NA
AU  - Kong, Andy; Ahuja, Karan; Goel, Mayank; Harrison, Chris
TI  - ICMI - EyeMU Interactions: Gaze + IMU Gestures on Mobile Devices
PY  - 2021
AB  - As smartphone screens have grown in size, single-handed use has become more cumbersome. Interactive targets that are easily seen can be hard to reach, particularly notifications and upper menu bar items. Users must either adjust their grip to reach distant targets, or use their other hand. In this research, we show how gaze estimation using a phone’s user-facing camera can be paired with IMU-tracked motion gestures to enable a new, intuitive, and rapid interaction technique on handheld phones. We describe our proof-of-concept implementation and gesture set, built on state-of-the-art techniques and capable of self-contained execution on a smartphone. In our user study, we found a mean euclidean gaze error of 1.7 cm and a seven-class motion gesture classification accuracy of 97.3%.
SP  - 577
EP  - 585
JF  - Proceedings of the 2021 International Conference on Multimodal Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3462244.3479938
ER  - 

TY  - JOUR
AU  - Siegert, Ingo; Weißkirchen, Norman; Wendemuth, Andreas
TI  - Acoustic-Based Automatic Addressee Detection for Technical Systems: A Review
PY  - 2022
AB  - <jats:sec><jats:title>Objective</jats:title><jats:p>Acoustic addressee detection is a challenge that arises in human group interactions, as well as in interactions with technical systems. The research domain is relatively new, and no structured review is available. Especially due to the recent growth of usage of voice assistants, this topic received increased attention. To allow a natural interaction on the same level as human interactions, many studies focused on the acoustic analyses of speech. The aim of this survey is to give an overview on the different studies and compare them in terms of utilized features, datasets, as well as classification architectures, which has so far been not conducted.</jats:p></jats:sec><jats:sec><jats:title>Methods</jats:title><jats:p>The survey followed the Preferred Reporting Items for Systematic reviews and Meta-Analysis (PRISMA) guidelines. We included all studies which were analyzing acoustic and/or acoustic characteristics of speech utterances to automatically detect the addressee. For each study, we describe the used dataset, feature set, classification architecture, performance, and other relevant findings.</jats:p></jats:sec><jats:sec><jats:title>Results</jats:title><jats:p>1,581 studies were screened, of which 23 studies met the inclusion criteria. The majority of studies utilized German or English speech corpora. Twenty-six percent of the studies were tested on in-house datasets, where only limited information is available. Nearly 40% of the studies employed hand-crafted feature sets, the other studies mostly rely on <jats:italic>Interspeech ComParE 2013</jats:italic> feature set or <jats:italic>Log-FilterBank Energy</jats:italic> and <jats:italic>Log Energy of Short-Time Fourier Transform</jats:italic> features. 12 out of 23 studies used deep-learning approaches, the other 11 studies used classical machine learning methods. Nine out of 23 studies furthermore employed a classifier fusion.</jats:p></jats:sec><jats:sec><jats:title>Conclusion</jats:title><jats:p>Speech-based automatic addressee detection is a relatively new research domain. Especially by using vast amounts of material or sophisticated models, device-directed speech is distinguished from non-device-directed speech. Furthermore, a clear distinction between in-house datasets and pre-existing ones can be drawn and a clear trend toward pre-defined larger feature sets (with partly used feature selection methods) is apparent.</jats:p></jats:sec>
SP  - NA
EP  - NA
JF  - Frontiers in Computer Science
VL  - 4
IS  - NA
PB  - 
DO  - 10.3389/fcomp.2022.831784
ER  - 

TY  - CHAP
AU  - Bailly, Gilles; Malacria, Sylvain
TI  - Command Selection
PY  - 2022
AB  - NA
SP  - 1
EP  - 35
JF  - Handbook of Human Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-319-27648-9_19-1
ER  - 

TY  - JOUR
AU  - Aizenman, Avi M.; Koulieris, George A.; Gibaldi, Agostino; Sehgal, Vibhor; Levi, Dennis M.; Banks, Martin S.
TI  - The Statistics of Eye Movements and Binocular Disparities during VR Gaming: Implications for Headset Design
PY  - 2023
AB  - <jats:p>The human visual system evolved in environments with statistical regularities. Binocular vision is adapted to these such that depth perception and eye movements are more precise, faster, and performed comfortably in environments consistent with the regularities. We measured the statistics of eye movements and binocular disparities in virtual-reality (VR) -gaming environments and found that they are quite different from those in the natural environment. Fixation distance and direction are more restricted in VR, and fixation distance is farther. The pattern of disparity across the visual field is less regular in VR and does not conform to a prominent property of naturally occurring disparities. From this we predict that double vision is more likely in VR than in the natural environment. We also determined the optimal screen distance to minimize discomfort due to the vergence-accommodation conflict, and the optimal nasal-temporal positioning of head-mounted display (HMD) screens to maximize binocular field of view. Finally, in a user study we investigated how VR content affects comfort and performance. Content that is more consistent with the statistics of the natural world yields less discomfort than content that is not. Furthermore, consistent content yields slightly better performance than inconsistent content.</jats:p>
SP  - 1
EP  - 15
JF  - ACM Transactions on Graphics
VL  - 42
IS  - 1
PB  - 
DO  - 10.1145/3549529
ER  - 

TY  - NA
AU  - Twigg-Smith, Hannah; O'Leary, Jasper Tran; Peek, Nadya
TI  - CHI - Tools, Tricks, and Hacks: Exploring Novel Digital Fabrication Workflows on #PlotterTwitter
PY  - 2021
AB  - As digital fabrication machines become widespread, online communities have provided space for diverse practitioners to share their work, troubleshoot, and socialize. These communities pioneer increasingly novel fabrication workflows, and it is critical that we understand and conceptualize these workflows beyond traditional manufacturing models. To this end, we conduct a qualitative study of #PlotterTwitter, an online community developing custom hardware and software tools to create artwork with computer-controlled drawing machines known as plotters. We documented and analyzed emergent themes where the traditional interpretation of digital fabrication workflows fails to capture important nuances and nascent directions. We find that #PlotterTwitter makers champion creative exploration of interwoven digital and physical materials over a predictable series of steps. We discuss how this challenges long-running views of digital fabrication and propose design implications for future frameworks and toolkits to account for this breadth of practice.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445653
ER  - 

TY  - NA
AU  - Endow, Shreyosi; Torres, César I.
TI  - Conference on Designing Interactive Systems - “I’m Better Off on my Own”: Understanding How a Tutorial’s Medium Affects Physical Skill Development
PY  - 2021
AB  - The shift towards distance learning brought forth by the pandemic has highlighted the shortcomings of teaching physical skills at a distance. With the emergence of new augmented and connected mediums, new opportunities arise for transferring physical skills that have resisted traditional documentation methods. However, there lacks a framework that allows tutorial authors to capitalize on a new medium’s unique affordances rather than remediating existing tutorial conventions. Our work analyzes a body of tutorials rendered in various mediums for centering clay on a pottery wheel — a foundational skill that exemplifies the difficulties of physical skill transfer. Through the lens of McLuhan’s “The Medium is the Message” we synthesize a taxonomy of medium conventions and themes derived from analyzing a body of centering tutorials and observation of how a tutorial’s medium affects how learners develop physical skills. We leverage our findings to motivate design recommendations to inform how new mediums can support material practices.
SP  - 1313
EP  - 1323
JF  - Designing Interactive Systems Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3461778.3462066
ER  - 

TY  - JOUR
AU  - Manni, Alessandro; Oriti, Damiano; Sanna, Andrea; De Pace, Francesco; Manuri, Federico
TI  - Snap2cad: 3D indoor environment reconstruction for AR/VR applications using a smartphone device
PY  - 2021
AB  - NA
SP  - 116
EP  - 124
JF  - Computers & Graphics
VL  - 100
IS  - NA
PB  - 
DO  - 10.1016/j.cag.2021.07.014
ER  - 

TY  - NA
AU  - Holcomb, Amelia; Tong, Bill; Penny, Megan; Keshav, Srinivasan
TI  - MobiSys - Measuring forest carbon with mobile phones
PY  - 2021
AB  - Tree trunk diameter, currently measured during manual forest inventories, is a key input to tree carbon storage calculations. We designan app running on a smartphone equipped with a time-of-flight sensor that allows efficient, low-cost, and accurate measurement of trunk diameter, even in the face of natural leaf and branch occlusion. The algorithm runs in near real-time on the phone, allowing user interaction to improve the quality of the results. We evaluate the app in realistic settings and find that in a corpus of 55 sample tree images, it estimates trunk diameter with mean error of 7.8%.
SP  - 495
EP  - 496
JF  - Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3458864.3466916
ER  - 

TY  - NA
AU  - Zheng, Clement; Yong, Zhen Zhou; Lin, Hongnan; Oh, HyunJoo; Yen, Ching Chiuan
TI  - Shape-Haptics: Planar & Passive Force Feedback Mechanisms for Physical Interfaces
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501829
ER  - 

TY  - NA
AU  - Peng, Yi-Hao; Jang, JiWoong; Bigham, Jeffrey P.; Pavel, Amy
TI  - CHI - Say It All: Feedback for Improving Non-Visual Presentation Accessibility
PY  - 2021
AB  - Presenters commonly use slides as visual aids for informative talks. When presenters fail to verbally describe the content on their slides, blind and visually impaired audience members lose access to necessary content, making the presentation difficult to follow. Our analysis of 90 presentation videos revealed that 72% of 610 visual elements (e.g., images, text) were insufficiently described. To help presenters create accessible presentations, we introduce Presentation A11y, a system that provides real-time and post-presentation accessibility feedback. Our system analyzes visual elements on the slide and the transcript of the verbal presentation to provide element-level feedback on what visual content needs to be further described or even removed. Presenters using our system with their own slide-based presentations described more of the content on their slides, and identified 3.26 times more accessibility problems to fix after the talk than when using a traditional slide-based presentation interface. Integrating accessibility feedback into content creation tools will improve the accessibility of informational content for all.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445572
ER  - 

TY  - JOUR
AU  - Arakawa, Riku; Yakura, Hiromu; Mollyn, Vimal; Nie, Suzanne; Russell, Emma; DeMeo, Dustin P.; Reddy, Haarika A.; Maytin, Alexander K.; Carroll, Bryan T.; Lehman, Jill Fain; Goel, Mayank
TI  - PrISM-Tracker
PY  - 2022
AB  - <jats:p>A user often needs training and guidance while performing several daily life procedures, e.g., cooking, setting up a new appliance, or doing a COVID test. Watch-based human activity recognition (HAR) can track users' actions during these procedures. However, out of the box, state-of-the-art HAR struggles from noisy data and less-expressive actions that are often part of daily life tasks. This paper proposes PrISM-Tracker, a procedure-tracking framework that augments existing HAR models with (1) graph-based procedure representation and (2) a user-interaction module to handle model uncertainty. Specifically, PrISM-Tracker extends a Viterbi algorithm to update state probabilities based on time-series HAR outputs by leveraging the graph representation that embeds time information as prior. Moreover, the model identifies moments or classes of uncertainty and asks the user for guidance to improve tracking accuracy. We tested PrISM-Tracker in two procedures: latte-making in an engineering lab study and wound care for skin cancer patients at a clinic. The results showed the effectiveness of the proposed algorithm utilizing transition graphs in tracking steps and the efficacy of using simulated human input to enhance performance. This work is the first step toward human-in-the-loop intelligent systems for guiding users while performing new and complicated procedural tasks.</jats:p>
SP  - 1
EP  - 27
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 4
PB  - 
DO  - 10.1145/3569504
ER  - 

TY  - NA
AU  - Palani, Srishti; Zhou, Yingyi; Zhu, Sheldon; Dow, Steven P.
TI  - InterWeave: Presenting Search Suggestions in Context Scaffolds Information Search and Synthesis
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545696
ER  - 

TY  - NA
AU  - Piyavichayanon, Chanapol; Koga, Masanobu; Hayashi, Eiji; Chumkamon, Sakmongkon
TI  - Collision-Aware AR Telemanipulation Using Depth Mesh
PY  - 2022
AB  - Remotely operating a robot in Augmented Reality (AR) is a challenging problem due to the limited information about the environment around the robot. The current AR teleoperation interface lacks the collision checking between the virtual robot model and the environment. This work aims to overcome that problem by using depth mesh generation to reconstruct the environment from a single pair of RGB and Depth images. By presenting the generated mesh with the virtual manipulator model in AR, we introduce three collision-aware features, i.e., collision checking, AR guidance, and ray casting distance calculation, to support the operator in the manipulation task. The reconstruction can be done instantly on the smartphone, allowing the system to be used on mobile AR applications. We evaluate our system with the pick-and-place task. The accuracy of the reconstruction is enough for the user to succeed in the operation. In addition, the collision-aware features reduce the task completion time, lower workload, and enhance the system&#x2019;s usability.
SP  - NA
EP  - NA
JF  - 2022 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/aim52237.2022.9863385
ER  - 

TY  - NA
AU  - Cheng, Yifei; Yan, Yukang; Yi, Xin; Shi, Yuanchun; Lindlbauer, David
TI  - UIST - SemanticAdapt: Optimization-based Adaptation of Mixed Reality Layouts Leveraging Virtual-Physical Semantic Connections
PY  - 2021
AB  - We present an optimization-based approach that automatically adapts Mixed Reality (MR) interfaces to different physical environments. Current MR layouts, including the position and scale of virtual interface elements, need to be manually adapted by users whenever they move between environments, and whenever they switch tasks. This process is tedious and time consuming, and arguably needs to be automated for MR systems to be beneficial for end users. We contribute an approach that formulates this challenge as a combinatorial optimization problem and automatically decides the placement of virtual interface elements in new environments. To achieve this, we exploit the semantic association between the virtual interface elements and physical objects in an environment. Our optimization furthermore considers the utility of elements for users’ current task, layout factors, and spatio-temporal consistency to previous layouts. All those factors are combined in a single linear program, which is used to adapt the layout of MR interfaces in real time. We demonstrate a set of application scenarios, showcasing the versatility and applicability of our approach. Finally, we show that compared to a naive adaptive baseline approach that does not take semantic associations into account, our approach decreased the number of manual interface adaptations by 33%.
SP  - 282
EP  - 297
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474750
ER  - 

TY  - NA
AU  - Schrapel, Maximilian; Etgeton, Philipp; Rohs, Michael
TI  - CHI Extended Abstracts - SpectroPhone: Enabling Material Surface Sensing with Rear Camera and Flashlight LEDs
PY  - 2021
AB  - We present SpectroPhone, a surface material sensing approach based on the rear camera of a smartphone and external white LED light sources. Warm and cool white LEDs, as used for dual or quad flashlights in smartphones, differ in their spectral distribution in the red and blue range. Warm and cool white LEDs in combination can produce a characteristic spectral response curve, when their light is reflected from a surface. We show that with warm and cool white LEDs and the rear-camera of a smartphone 30 different materials can be distinguished with an accuracy of 99 %. Based on a dataset consisting of 13500 images of material surfaces taken at different LED light intensities, we report recognition rates of support vector machines with different parameters.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451753
ER  - 

TY  - NA
AU  - Yang, John; Bhalgat, Yash; Chang, Simyung; Porikli, Fatih; Kwak, Nojun
TI  - Dynamic Iterative Refinement for Efficient 3D Hand Pose Estimation.
PY  - 2021
AB  - While hand pose estimation is a critical component of most interactive extended reality and gesture recognition systems, contemporary approaches are not optimized for computational and memory efficiency. In this paper, we propose a tiny deep neural network of which partial layers are recursively exploited for refining its previous estimations. During its iterative refinements, we employ learned gating criteria to decide whether to exit from the weight-sharing loop, allowing per-sample adaptation in our model. Our network is trained to be aware of the uncertainty in its current predictions to efficiently gate at each iteration, estimating variances after each loop for its keypoint estimates. Additionally, we investigate the effectiveness of end-to-end and progressive training protocols for our recursive structure on maximizing the model capacity. With the proposed setting, our method consistently outperforms state-of-the-art 2D/3D hand pose estimation approaches in terms of both accuracy and efficiency for widely used benchmarks.
SP  - NA
EP  - NA
JF  - arXiv: Computer Vision and Pattern Recognition
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Nakagaki, Ken; Tappa, Jordan L; Zheng, Yi; Forman, Jack; Leong, Joanne; Koenig, Sven; Ishii, Hiroshi
TI  - (Dis)Appearables: A Concept and Method for Actuated Tangible UIs to Appear and Disappear based on Stages
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501906
ER  - 

TY  - NA
AU  - Liu, Xingyu; Carrington, Patrick; Chen, Xiang 'Anthony'; Pavel, Amy
TI  - CHI - What Makes Videos Accessible to Blind and Visually Impaired People
PY  - 2021
AB  - User-generated videos are an increasingly important source of information online, yet most online videos are inaccessible to blind and visually impaired (BVI) people. To find videos that are accessible, or understandable without additional description of the visual content, BVI people in our formative studies reported that they used a time-consuming trial-and-error approach: clicking on a video, watching a portion, leaving the video, and repeating the process. BVI people also reported video accessibility heuristics that characterize accessible and inaccessible videos. We instantiate 7 of the identified heuristics (2 audio-related, 2 video-related, and 3 audio-visual) as automated metrics to assess video accessibility. We collected a dataset of accessibility ratings of videos by BVI people and found that our automatic video accessibility metrics correlated with the accessibility ratings (Adjusted R2 = 0.642). We augmented a video search interface with our video accessibility metrics and predictions. BVI people using our augmented video search interface selected an accessible video more efficiently than when using the original search interface. By integrating video accessibility metrics, video hosting platforms could help people surface accessible videos and encourage content creators to author more accessible products, improving video accessibility for all.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445233
ER  - 

TY  - CHAP
AU  - Minagawa, Tatsuya; Ochiai, Yoichi
TI  - HCI (19) - A Case Study of Augmented Physical Interface by Foot Access with 3D Printed Attachment.
PY  - 2021
AB  - We propose an attachment creation framework that allows foot access to existing physical interfaces designed to use hands such as doorknobs. The levers, knobs, and switches of furniture and electronic devices are designed for the human hand. These interfaces may not be accessible for hygienic and physical reasons. Due to the high cost of parts and initial installation, sensing or automation is not preferable. Therefore, there is a need for a low-cost way to access physical interfaces without hands. We have enabled foot access by extending the hand-accessible interface with 3D-printed attachments. Finally, we proposed a mechanism (component set) that transmits movement from a foot-accessed pedal to an interface with attachments. And we attached it to the doorknob, water faucet, and lighting switch interface. A case study was conducted to verify the system’s effectiveness, which consisted of 3D-printed attachments and pedals.
SP  - 315
EP  - 332
JF  - Design, User Experience, and Usability: Design for Diversity, Well-being, and Social Development
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-78224-5_22
ER  - 

TY  - JOUR
AU  - Ariansyah, Dedy; Erkoyuncu, John Ahmet; Eimontaite, Iveta; Johnson, Teegan L.; Oostveen, Anne-Marie; Fletcher, Sarah R.; Sharples, Sarah
TI  - A head mounted augmented reality design practice for maintenance assembly: Toward meeting perceptual and cognitive needs of AR users.
PY  - 2021
AB  - Head Mounted Display (HMD) based Augmented Reality (AR) is being increasingly used in manufacturing and maintenance. However, limited research has been done to understand user interaction with AR interfaces, which may lead to poor usability, risk of occupational hazards, and low acceptance of AR systems. This paper uses a theoretically-driven approach to interaction design to investigate the impact of different AR modalities in terms of information mode (i.e. video vs. 3D animation) and interaction modality (i.e. hand-gesture vs. voice command) on user performance, workload, eye gaze behaviours, and usability during a maintenance assembly task. The results show that different information modes have distinct impacts compared to paper-based maintenance, in particular, 3D animation led to a 14% improvement over the video instructions in task completion time. Moreover, insights from eye gaze behaviours such as number of fixations and transition between Areas of Interest (AOIs) revealed the differences in attention switching and task comprehension difficulty with the choice of AR modalities. While, subjective user perceptions highlight some ergonomic issues such as misguidance and overreliance, which must be considered and addressed from the joint cognitive systems' (JCSs) perspective and in line with the predictions derived from the Multiple Resources Model.
SP  - 103597
EP  - 103597
JF  - Applied ergonomics
VL  - 98
IS  - NA
PB  - 
DO  - 10.1016/j.apergo.2021.103597
ER  - 

TY  - NA
AU  - Yang, Humphrey; Johnson, Tate; Zhong, Ke; Patel, Dinesh; Olson, Gina; Majidi, Carmel; Islam, Mohammad; Yao, Lining
TI  - Demonstrating ReCompFig: Designing Dynamically Reconfigurable Kinematic Devices Using Compliant Mechanisms and Tensioning Cables
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519890
ER  - 

TY  - NA
AU  - Roberts, Jasmine; Mernacaj, John; Chambers, Suzanne; Ayalon, Dror; King, Errol
TI  - CHI PLAY (Companion) - Lines of Play: Using Vector Tools to Place Game Objects in Augmented Reality
PY  - 2020
AB  - 'Lines of Play' is a domino art application showcasing recent advancements in augmented reality (AR) technology. Unlike previous mobile AR applications that were limited to horizontal and vertical object placement, these game objects interact with real objects in the player's environment with surface-level resolution. Features of the player's environment provide kinematic constraints (on collision) and serve as obstructions both visually (occlusion) and during gameplay. Using single camera depth information, players can use familiar vector drawing tools to rapidly create and modify lines, rings, paths, and turns of domino tiles. We thereby provide a method for placing a plurality of gaming objects by converting raycasted anchor points into paths of game objects. This opens up novel possibilities of authoring tools specially adapted for AR game development or game-integrated level editing.
SP  - 30
EP  - 32
JF  - Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3383668.3419860
ER  - 

TY  - JOUR
AU  - Choi, Seokmin; Gao, Yang; Jin, Yincheng; Kim, Se jun; Li, Jiyang; Xu, Wenyao; Jin, Zhanpeng
TI  - PPGface
PY  - 2022
AB  - <jats:p>Recognition of facial expressions has been widely explored to represent people's emotional states. Existing facial expression recognition systems primarily rely on external cameras which make it less accessible and efficient in many real-life scenarios to monitor an individual's facial expression in a convenient and unobtrusive manner. To this end, we propose PPGface, a ubiquitous, easy-to-use, user-friendly facial expression recognition platform that leverages earable devices with built-in PPG sensor. PPGface understands the facial expressions through the dynamic PPG patterns resulting from facial muscle movements. With the aid of the accelerometer sensor, PPGface can detect and recognize the user's seven universal facial expressions and relevant body posture unobtrusively. We conducted an user study (N=20) using multimodal ResNet to evaluate the performance of PPGface, and showed that PPGface can detect different facial expressions with 93.5 accuracy and 0.93 fl-score. In addition, to explore the robustness and usability of our proposed platform, we conducted several comprehensive experiments under real-world settings. Overall results of this work validate a great potential to be employed in future commodity earable devices.</jats:p>
SP  - 1
EP  - 32
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 2
PB  - 
DO  - 10.1145/3534597
ER  - 

TY  - CHAP
AU  - Li, Guangchuan; Liu, Yue; Song, Weitao; Wang, Cong; Wang, Yongtian
TI  - ICIG (2) - A New Dataset and Recognition for Egocentric Microgesture Designed by Ergonomists.
PY  - 2021
AB  - Virtual and Augmented reality (VR/AR) are widely deployed in industrial, medical, educational, and entertaining fields. The design of interactive interfaces has an impact on usability, comfort, and efficiency. Hand controllers and gestures are popularly used in VR/AR devices. However, users may suffer from overloading on the upper extremities while raising the hand or controller. Therefore, we released a microgesture library with 19 microgestures designed by ergonomists. Users can perform microgestures for an extended duration by resting the forearm on the tables to reduce the load on the upper extremity. Additionally, we collected a microgesture dataset of 2900 samples and utilized the C3D model to recognize the microgesture dataset. Finally, we achieved a recognition accuracy of 93.4% on the microgestures dataset.
SP  - 80
EP  - 89
JF  - Lecture Notes in Computer Science
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-87358-5_7
ER  - 

TY  - JOUR
AU  - Steed, Anthony; Ofek, Eyal; Sinclair, Mike; Gonzalez-Franco, Mar
TI  - A mechatronic shape display based on auxetic materials.
PY  - 2021
AB  - Shape displays enable people to touch simulated surfaces. A common architecture of such devices uses a mechatronic pin-matrix. Besides their complexity and high cost, these matrix displays suffer from sharp edges due to the discreet representation which reduces their ability to render a large continuous surface when sliding the hand. We propose using an engineered auxetic material actuated by a smaller number of motors. The material bends in multiple directions, feeling smooth and rigid to touch. A prototype implementation uses nine actuators on a 220 mm square section of material. It can display a range of surface curvatures under the palm of a user without aliased edges. In this work we use an auxetic skeleton to provide rigidity on a soft material and demonstrate the potential of this class of surface through user experiments. Though shape-changing devices are promising for future haptic displays, existing designs fail to provide smooth surfaces for the user during tactile exploration. Here, the authors utilize flexible auxetic structures to realize shape displays with smooth surfaces and different Gaussian curvatures.
SP  - 4758
EP  - NA
JF  - Nature communications
VL  - 12
IS  - 1
PB  - 
DO  - 10.1038/s41467-021-24974-0
ER  - 

TY  - JOUR
AU  - Liu, Jiazhou; Prouzeau, Arnaud; Ens, Barrett; Dwyer, Tim
TI  - Effects of Display Layout on Spatial Memory for Immersive Environments
PY  - 2022
AB  - <jats:p>In immersive environments, positioning data visualisations around the user in a wraparound layout has been advocated as advantageous over flat arrangements more typical of traditional screens. However, other than limiting the distance users must walk, there is no clear design rationale behind this common practice, and little research on the impact of wraparound layouts on visualisation tasks. The ability to remember the spatial location of elements of visualisations within the display space is crucial to support visual analytical tasks, especially those that require users to shift their focus or perform comparisons. This ability is influenced by the user's spatial memory but how spatial memory is affected by different display layouts remains unclear. In this paper, we perform two user studies to evaluate the effects of three layouts with varying degrees of curvature around the user (flat-wall, semicircular-wraparound, and circular-wraparound) on a visuo-spatial memory task in a virtual environment. The results show that participants are able to recall spatial patterns with greater accuracy and report more positive subjective ratings using flat than circular-wraparound layouts. While we didn't find any significant performance differences between the flat and semicircular-wraparound layouts, participants overwhelmingly preferred the semicircular-wraparound layout suggesting it is a good compromise between the two extremes of display curvature.</jats:p>
SP  - 468
EP  - 488
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - ISS
PB  - 
DO  - 10.1145/3567729
ER  - 

TY  - NA
AU  - Peng, Yi-Hao; Jang, JiWoong; Bigham, Jeffrey P.; Pavel, Amy
TI  - Say It All: Feedback for Improving Non-Visual Presentation Accessibility
PY  - 2021
AB  - Presenters commonly use slides as visual aids for informative talks. When presenters fail to verbally describe the content on their slides, blind and visually impaired audience members lose access to necessary content, making the presentation difficult to follow. Our analysis of 90 presentation videos revealed that 72% of 610 visual elements (e.g., images, text) were insufficiently described. To help presenters create accessible presentations, we introduce Presentation A11y, a system that provides real-time and post-presentation accessibility feedback. Our system analyzes visual elements on the slide and the transcript of the verbal presentation to provide element-level feedback on what visual content needs to be further described or even removed. Presenters using our system with their own slide-based presentations described more of the content on their slides, and identified 3.26 times more accessibility problems to fix after the talk than when using a traditional slide-based presentation interface. Integrating accessibility feedback into content creation tools will improve the accessibility of informational content for all.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Natalie, Rosiana; Tseng, Joshua; Loh, Jolene; Yi-Ren Chan, Ian Luke; Tan, Huei Suen; Jarjue, Ebrima H; Kacorri, Hernisa; Hara, Kotaro
TI  - The Efficacy of Collaborative Authoring of Video Scene Descriptions.
PY  - 2021
AB  - The majority of online video contents remain inaccessible to people with visual impairments due to the lack of audio descriptions to depict the video scenes. Content creators have traditionally relied on professionals to author audio descriptions, but their service is costly and not readily-available. We investigate the feasibility of creating more cost-effective audio descriptions that are also of high quality by involving novices. Specifically, we designed, developed, and evaluated ViScene, a web-based collaborative audio description authoring tool that enables a sighted novice author and a reviewer either sighted or blind to interact and contribute to scene descriptions (SDs)-text that can be transformed into audio through text-to-speech. Through a mixed-design study with <i>N</i> = 60 participants, we assessed the quality of SDs created by sighted novices with feedback from both sighted and blind reviewers. Our results showed that with ViScene novices could produce content that is Descriptive, Objective, Referable, and Clear at a cost of <i>i.e.,</i> US$2.81pvm to US$5.48pvm, which is 54% to 96% lower than the professional service. However, the descriptions lacked in other quality dimensions (<i>e.g.,</i> learning, a measure of how well an SD conveys the video's intended message). While professional audio describers remain the gold standard, for content creators who cannot afford it, ViScene offers a cost-effective alternative, ultimately leading to a more accessible medium.
SP  - NA
EP  - NA
JF  - ASSETS. Annual ACM Conference on Assistive Technologies
VL  - 17
IS  - NA
PB  - 
DO  - 10.1145/3441852.3471201
ER  - 

TY  - NA
AU  - Zheng, Ce; Wu, Wenhan; Yang, Taojiannan; Zhu, Sijie; Chen, Chen; Liu, Ruixu; Shen, Ju; Kehtarnavaz, Nasser; Shah, Mubarak
TI  - Deep Learning-Based Human Pose Estimation: A Survey
PY  - 2020
AB  - Human pose estimation aims to locate the human body parts and build human body representation (e.g., body skeleton) from input data such as images and videos. It has drawn increasing attention during the past decade and has been utilized in a wide range of applications including human-computer interaction, motion analysis, augmented reality, and virtual reality. Although the recently developed deep learning-based solutions have achieved high performance in human pose estimation, there still remain challenges due to insufficient training data, depth ambiguities, and occlusion. The goal of this survey paper is to provide a comprehensive review of recent deep learning-based solutions for both 2D and 3D pose estimation via a systematic analysis and comparison of these solutions based on their input data and inference procedures. More than 240 research papers since 2014 are covered in this survey. Furthermore, 2D and 3D human pose estimation datasets and evaluation metrics are included. Quantitative performance comparisons of the reviewed methods on popular datasets are summarized and discussed. Finally, the challenges involved, applications, and future research directions are concluded. We also provide a regularly updated project page: \url{this https URL}
SP  - NA
EP  - NA
JF  - arXiv: Computer Vision and Pattern Recognition
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Kudo, Yoshiki; Tang, Anthony; Fujita, Kazuyuki; Endo, Isamu; Takashima, Kazuki; Kitamura, Yoshifumi
TI  - Towards Balancing VR Immersion and Bystander Awareness
PY  - 2021
AB  - Head-mounted displays (HMDs) increase immersion into virtual worlds. The problem is that this limits headset users' awareness of bystanders: headset users cannot attend to bystanders' presence and activities. We call this the HMD boundary. We explore how to make the HMD boundary permeable by comparing different ways of providing informal awareness cues to the headset user about bystanders. We adapted and implemented three visualization techniques (Avatar View, Radar and Presence++) that share bystanders' location and orientation with headset users. We conducted a hybrid user and simulation study with three different types of VR content (high, medium, low interactivity) with twenty participants to compare how these visualization techniques allow people to maintain an awareness of bystanders, and how they affect immersion (compared to a baseline condition). Our study reveals that a see-through avatar representation of bystanders was effective, but led to slightly reduced immersion in the VR content. Based on our findings, we discuss how future awareness visualization techniques can be designed to mitigate the reduction of immersion for the headset user.
SP  - 1
EP  - 22
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 5
IS  - ISS
PB  - 
DO  - 10.1145/3486950
ER  - 

TY  - JOUR
AU  - Takahashi, Ryo; Yukita, Wakako; Sasatani, Takuya; Yokota, Tomoyuki; Someya, Takao; Kawahara, Yoshihiro
TI  - Twin Meander Coil
PY  - 2021
AB  - <jats:p>Energy-efficient and unconstrained wearable sensing platforms are essential for ubiquitous healthcare and activity monitoring applications. This paper presents Twin Meander Coil for wirelessly connecting battery-free on-body sensors to a textile-based reader knitted into clothing. This connection is based on passive inductive telemetry (PIT), wherein an external reader coil collects data from passive sensor coils via the magnetic field. In contrast to standard active sensing techniques, PIT does not require the reader to power up the sensors. Thus, the reader can be fabricated using a lossy conductive thread and industrial knitting machines. Furthermore, the sensors can superimpose information such as ID, touch, rotation, and pressure on its frequency response. However, conventional PIT technology needs a strong coupling between the reader and the sensor, requiring the reader to be small to the same extent as the sensors' size. Thus, applying this technology to body-scale sensing systems is challenging. To enable body-scale readout, Twin Meander Coil enhances the sensitivity of PIT technology by dividing the body-scale meander-shaped reader coils into two parts and integrating them so that they support the readout of each other. To demonstrate its feasibility, we built a prototype with a knitting machine, evaluated its sensing ability, and demonstrated several applications.</jats:p>
SP  - 1
EP  - 21
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 4
PB  - 
DO  - 10.1145/3494996
ER  - 

TY  - BOOK
AU  - Yao, Powen; Lympouridis, Vangelis; Zyda, Michael
TI  - VR Workshops - Virtual Equipment System: Face Mask and Voodoo Doll for User Privacy and Self-Expression Options in Virtual Reality
PY  - 2021
AB  - Current trends in immersive technologies suggest an increase in capturing user’s data to drive interactions and avatar representations. With growing numbers of data types being collected, users need an easy way to view and control their privacy settings. In this demo, we present a method for users to adjust options related to privacy settings, user data collection, and self-expression through the use of 3D user interface metaphors such as a mask and a voodoo doll.
SP  - 747
EP  - 748
JF  - 2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vrw52623.2021.00256
ER  - 

TY  - NA
AU  - Xu, Nancy; Masling, Sam; Du, Michael; Campagna, Giovanni; Heck, Larry; Landay, James A.; Lam, Monica S.
TI  - NAACL-HLT - Grounding Open-Domain Instructions to Automate Web Support Tasks
PY  - 2021
AB  - Grounding natural language instructions on the web to perform previously unseen tasks enables accessibility and automation. We introduce a task and dataset to train AI agents from open-domain, step-by-step instructions originally written for people. We build RUSS (Rapid Universal Support Service) to tackle this problem. RUSS consists of two models: First, a BERT-LSTM with pointers parses instructions to WebLang, a domain-specific language we design for grounding natural language on the web. Then, a grounding model retrieves the unique IDs of any webpage elements requested in the WebLang. RUSS may interact with the user through a dialogue (e.g. ask for an address) or execute a web operation (e.g. click a button) inside the web runtime. To augment training, we synthesize natural language instructions mapped to WebLang. Our dataset consists of 80 different customer service problems from help websites, with a total of 741 step-by-step instructions and their corresponding actions. RUSS achieves 76.7% end-to-end accuracy predicting agent actions from single instructions. It outperforms state-of-the-art models that directly map instructions to actions without WebLang. Our user study shows that RUSS is preferred by actual users over web navigation.
SP  - 1022
EP  - 1032
JF  - Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies
VL  - NA
IS  - NA
PB  - 
DO  - 10.18653/v1/2021.naacl-main.80
ER  - 

TY  - NA
AU  - Teng, Shan-Yuan; Li, Pengyu; Nith, Romain; Fonseca, Joshua; Lopes, Pedro
TI  - CHI - Touch&Fold: A Foldable Haptic Actuator for Rendering Touch in Mixed Reality
PY  - 2021
AB  - We propose a nail-mounted foldable haptic device that provides tactile feedback to mixed reality (MR) environments by pressing against the user's fingerpad when a user touches a virtual object. What is novel in our device is that it quickly tucks away when the user interacts with real-world objects. Its design allows it to fold back on top of the user's nail when not in use, keeping the user's fingerpad free to, for instance, manipulate handheld tools and other objects while in MR. To achieve this, we engineered a wireless and self-contained haptic device, which measures 24×24×41 mm and weighs 9.5 g. Furthermore, our foldable end-effector also features a linear resonant actuator, allowing it to render not only touch contacts (i.e., pressure) but also textures (i.e., vibrations). We demonstrate how our device renders contacts with MR surfaces, buttons, low- and high-frequency textures. In our first user study, we found that participants perceived our device to be more realistic than a previous haptic device that also leaves the fingerpad free (i.e., fingernail vibration). In our second user study, we investigated the participants’ experience while using our device in a real-world task that involved physical objects. We found that our device allowed participants to use the same finger to manipulate handheld tools, small objects, and even feel textures and liquids, without much hindrance to their dexterity, while feeling haptic feedback when touching MR interfaces.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445099
ER  - 

TY  - NA
AU  - Lim, Hyunchul; Lin, David M.; Tweneboah, Jessica; Zhang, Cheng
TI  - UIST - HandyTrak: Recognizing the Holding Hand on a Commodity Smartphone from Body Silhouette Images
PY  - 2021
AB  - Understanding which hand a user holds a smartphone with can help improve the mobile interaction experience. For instance, the layout of the user interface (UI) can be adapted to the holding hand. In this paper, we present HandyTrak, an AI-powered software system that recognizes the holding hand on a commodity smartphone using body silhouette images captured by the front-facing camera. The silhouette images are processed and sent to a customized user-dependent deep learning model (CNN) to infer how the user holds the smartphone (left, right, or both hands). We evaluated our system on each participant’s smartphone at five possible front camera positions in a user study with ten participants under two hand positions (in the middle and skewed) and three common usage cases (standing, sitting, and resting against a desk). The results showed that HandyTrak was able to continuously recognize the holding hand with an average accuracy of 89.03% (SD: 8.98%) at a 2 Hz sampling rate. We also discuss the challenges and opportunities to deploy HandyTrak on different commodity smartphones and potential applications in real-world scenarios.
SP  - 1210
EP  - 1220
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474817
ER  - 

TY  - NA
AU  - Endo, Isamu; Takashima, Kazuki; Inoue, Maakito; Fujita, Kazuyuki; Kiyokawa, Kiyoshi; Kitamura, Yoshifumi
TI  - UIST - ModularHMD: A Reconfigurable Mobile Head-Mounted Display Enabling Ad-hoc Peripheral Interactions with the Real World
PY  - 2021
AB  - We propose ModularHMD, a new mobile head-mounted display concept, which adopts a modular mechanism and allows a user to perform ad-hoc peripheral interaction with real-world devices or people during VR experiences. ModularHMD is comprised of a central HMD and three removable module devices installed in the periphery of the HMD cowl. Each module has four main states: occluding, extended VR view, video see-through (VST), and removed/reused. Among different combinations of module states, a user can quickly setup the necessary HMD forms, functions, and real-world visions for ad-hoc peripheral interactions without removing the headset. For instance, an HMD user can see her surroundings by switching a module into the VST mode. She can also physically remove a module to obtain direct peripheral visions of the real world. The removed module can be reused as an instant interaction device (e.g., touch keyboards) for subsequent peripheral interactions. Users can end the peripheral interaction and revert to a full VR experience by re-mounting the module. We design ModularHMD’s configuration and peripheral interactions with real-world objects and people. We also implement a proof-of-concept prototype of ModularHMD to validate its interactions capabilities through a user study. Results show that ModularHMD is an effective solution that enables both immersive VR and ad-hoc peripheral interactions.
SP  - 100
EP  - 117
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474738
ER  - 

TY  - NA
AU  - Ikarashi, Yuka; Ragan-Kelley, Jonathan; Fukusato, Tsukasa; Kato, Jun; Igarashi, Takeo
TI  - Guided Optimization for Image Processing Pipelines
PY  - 2021
AB  - Writing high-performance image processing code is challenging and labor-intensive. The Halide programming language simplifies this task by decoupling high-level algorithms from "schedules" which optimize their implementation. However, even with this abstraction, it is still challenging for Halide programmers to understand complicated scheduling strategies and productively write valid, optimized schedules. To address this, we propose a programming support method called "guided optimization." Guided optimization provides programmers a set of valid optimization options and interactive feedback about their current choices, which enables them to comprehend and efficiently optimize image processing code without the time-consuming trial-and-error process of traditional text editors. We implemented a proof-of-concept system, Roly-poly, which integrates guided optimization, program visualization, and schedule cost estimation to support the comprehension and development of efficient Halide image processing code. We conducted a user study with novice Halide programmers and confirmed that Roly-poly and its guided optimization was informative, increased productivity, and resulted in higher-performing schedules in less time.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Rauschmayr, Nathalie; Kama, Sami; Kim, Muhyun; Choi, Miyoung; Kenthapadi, Krishnaram
TI  - Profiling Deep Learning Workloads at Scale using Amazon SageMaker
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3534678.3539036
ER  - 

TY  - JOUR
AU  - Fages, Arthur; Fleury, Cédric; Tsandilas, Theophanis
TI  - Understanding Multi-View Collaboration between Augmented Reality and Remote Desktop Users
PY  - 2022
AB  - <jats:p>Establishing an effective collaboration between augmented-reality (AR) and remote desktop users is a challenge because collaborators do not share a common physical space and equipment. Yet, such asymmetrical collaboration configurations are common today for many design tasks, due to the geographical distance of people or unusual circumstances such as a lockdown. We conducted a first study to investigate trade-offs of three remote representations of an AR workspace: a fully virtual representation, a first-person view, and an external view. Building on our findings, we designed ARgus, a multi-view video-mediated communication system that combines these representations through interactive tools for navigation, previewing, pointing, and annotation. We report on a second user study that observed how 12 participants used ARgus to provide remote instructions for an AR furniture arrangement task. Participants extensively used its view transition tools, while the system reduced their reliance on verbal instructions.</jats:p>
SP  - 1
EP  - 27
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - CSCW2
PB  - 
DO  - 10.1145/3555607
ER  - 

TY  - NA
AU  - Tao, Ye; Chen, Yu; Fang, Jian; Lin, Jinpeng; Geng, Jingchun; Fang, Ziqi; Chen, Cejun; Yang, Cheng; Zhang, Fan; Sun, Lingyun; Wang, Guanyun
TI  - UIST (Adjunct Volume) - infOrigami: A Computer-aided Design Method for Introducing Traditional Perforated Boneless Lantern Craft to Everyday Interfaces
PY  - 2021
AB  - The traditional perforated boneless lantern craft is a three-dimensional (3D) lamp fabrication method in which paper sheets are folded without any skeleton, and often accompanied by hole-like patterns. It has been extensively applied throughout history using various means and is favored because of its low cost and environmental friendliness. However, the traditional craft requires a complicated manual production process and accumulated craft expertise, which limits its aesthetics and daily use-value. We propose a computer-aided design method to customize a 3D lamp with decorative patterns from paper pieces. The key idea is to establish an automatic workflow for producing 3D objects with visual information that is similar to the lantern tradition but without overloaded manual efforts. Our user tests and results demonstrate the potential for DIY everyday interfaces for creating personalized aesthetics, enhancing the visualization of information, and promoting multi-person handicraft activity.
SP  - 55
EP  - 59
JF  - The Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3474349.3480228
ER  - 

TY  - NA
AU  - Tollola, C.
TI  - Procedural animations in interactive art experiences - A state of the art review.
PY  - 2021
AB  - The state of the art review broadly oversees the use of novel research utilized in the creation of virtual environments applied in interactive art experiences, with a specific focus on the application of procedural animation in spatially augmented reality (SAR) exhibitions. These art exhibitions frequently combine sensory displays that appeal, replace, and augment the visual, auditory and touch or haptic senses. We analyze and break down art-technology related innovations in the last three years, and thoroughly identify the most recent and vibrant applications of interactive art experiences in the review of numerous installation applications, studies, and events. Display mediums such as virtual reality, augmented reality, mixed reality, and robotics are overviewed in the context of art experiences such as visual art museums, park or historic site tours, live concerts, and theatre. We explore research and extrapolate how recent innovations can lead to different applications that will be seen in the future.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Lin, Richard; Ramesh, Rohit; Dutta, Prabal; Hartmann, Bjoern; Mehta, Ankur
TI  - Computational Support for Multiplicity in Hierarchical Electronics Design
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Symposium on Computational Fabrication
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3559400.3561997
ER  - 

TY  - JOUR
AU  - Jewitt, Carey; Price, Sara; Steimle, Jürgen; Huisman, Gijs; Golmohammadi, Lili; Pourjafarian, Narges; Frier, William; Howard, Thomas; Askari, Sima Ipakchian; Ornati, Michela; Paneels, Sabrina; Weda, Judith
TI  - Manifesto for Digital Social Touch in Crisis
PY  - 2021
AB  - This qualitative exploratory research paper presents a Manifesto for Digital Social Touch in Crisis - a provocative call to action to designers, developers and researchers to rethink and reimagine social touch through a deeper engagement with the social and sensory aspects of touch. This call is motivated by concerns that social touch is in a crisis signaled by a decline in social touch over the past 2 decades, the problematics of inappropriate social touch, and the well documented impact of a lack of social touch on communication, relationships, and well-being and health. These concerns shape how social touch enters the digital realm and raise questions for how and when the complex space of social touch is mediated by technologies, as well the societal implications. The paper situates the manifesto in the key challenges facing haptic designers and developers identified through a series of interdisciplinary collaborative workshops with participants from computer science, design, engineering, HCI and social science from both within industry and academia, and the research literature on haptics. The features and purpose of the manifesto form are described, along with our rationale for its use, and the method of the manifesto development. The starting points, opportunities and challenges, dominant themes and tensions that shaped the manifesto statements are then elaborated on. The paper shows the potential of the manifesto form to bridge between HCI, computer science and engineers, and social scientists on the topic of social touch.
SP  - 754050
EP  - NA
JF  - Frontiers of Computer Science
VL  - 2021
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Han, Yi; Wang, Wenhao; Chen, Nanxi; Zhong, Yi; Zhou, Ruichun; Yan, Haoyu; Wang, Jun; Bai, Yulei
TI  - A 5G-Based VR Application for Efficient Port Management
PY  - 2022
AB  - <jats:p>In recent years, the throughput of cargo ports has increased rapidly. It is urgent to improve the operating efficiency of ports for its increasing demands. Both industry and academia have shown great interest in adopting 5G and Virtual Reality (VR) technologies to improve the efficiency and safety of industrial operations. However, such technologies have not been well explored in port operations. This paper proposes a 5G-based VR smart port to support intelligent management for five typical port operations. The overall architecture of the smart port and its key processes, major advantages, and limitations are discussed in this paper. An application of the proposed smart port system is demonstrated. The performance study based on network Quality of Service (QoS) and Quality of user Experience (QoE) proves the feasibility of the proposed architecture. The architecture supports efficient interaction in real-time, making comprehensive decisions, and staff training. The smart port architecture is suitable for tasks of high working intensity and can dramatically increase operational efficiency.</jats:p>
SP  - 101
EP  - 101
JF  - World Electric Vehicle Journal
VL  - 13
IS  - 6
PB  - 
DO  - 10.3390/wevj13060101
ER  - 

TY  - JOUR
AU  - Liang, Chen; Yu, Chun; Qin, Yue; Wang, Yuntao; Shi, Yuanchun
TI  - DualRing: Enabling Subtle and Expressive Hand Interaction with Dual IMU Rings
PY  - 2021
AB  - We present DualRing, a novel ring-form input device that can capture the state and movement of the user's hand and fingers. With two IMU rings attached to the user's thumb and index finger, DualRing can sense not only the absolute hand gesture relative to the ground but also the relative pose and movement among hand segments. To enable natural thumb-to-finger interaction, we develop a high-frequency AC circuit for on-body contact detection. Based on the sensing information of DualRing, we outline the interaction space and divide it into three sub-spaces: within-hand interaction, hand-to-surface interaction, and hand-to-object interaction. By analyzing the accuracy and performance of our system, we demonstrate the informational advantage of DualRing in sensing comprehensive hand gestures compared with single-ring-based solutions. Through the user study, we discovered the interaction space enabled by DualRing is favored by users for its usability, efficiency, and novelty.
SP  - 1
EP  - 27
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 3
PB  - 
DO  - 10.1145/3478114
ER  - 

TY  - NA
AU  - Stemasov, Evgeny; Wagner, Tobias; Gugenheimer, Jan; Rukzio, Enrico
TI  - ShapeFindAR: Exploring In-Situ Spatial Search for Physical Artifact Retrieval using Mixed Reality
PY  - 2022
AB  - Personal fabrication is made more accessible through repositories like Thingiverse, as they replace modeling with retrieval. However, they require users to translate spatial requirements to keywords, which paints an incomplete picture of physical artifacts: proportions or morphology are non-trivially encoded through text only. We explore a vision of in-situ spatial search for (future) physical artifacts, and present ShapeFindAR, a mixed-reality tool to search for 3D models using in-situ sketches blended with textual queries. With ShapeFindAR, users search for geometry, and not necessarily precise labels, while coupling the search process to the physical environment (e.g., by sketching in-situ, extracting search terms from objects present, or tracing them). We developed ShapeFindAR for HoloLens 2, connected to a database of 3D-printable artifacts. We specify in-situ spatial search, describe its advantages, and present walkthroughs using ShapeFindAR, which highlight novel ways for users to articulate their wishes, without requiring complex modeling tools or profound domain knowledge.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517682
ER  - 

TY  - JOUR
AU  - Ahn, Sun Joo (Grace); Kim, Jooyoung; Kim, Jaemin
TI  - The future of advertising research in virtual, augmented, and extended realities
PY  - 2022
AB  - NA
SP  - 1
EP  - 9
JF  - International Journal of Advertising
VL  - NA
IS  - NA
PB  - 
DO  - 10.1080/02650487.2022.2137316
ER  - 

TY  - NA
AU  - Gall, Alexander; Gröller, Eduard; Heinzl, Christoph
TI  - ImNDT: Immersive Workspace for the Analysis of Multidimensional Material Data From Non-Destructive Testing
PY  - 2021
AB  - An analysis of large multidimensional volumetric data as generated by non-destructive testing (NDT) techniques, e.g., X-ray computed tomography (XCT), can hardly be evaluated using standard 2D visualization techniques on desktop monitors. The analysis of fiber-reinforced polymers (FRPs) is currently a time-consuming and cognitively demanding task, as FRPs have a complex spatial structure, consisting of several hundred thousand fibers, each having more than twenty different extracted features. This paper presents ImNDT, a novel visualization system, which offers material experts an immersive exploration of multidimensional secondary data of FRPs. Our system is based on a virtual reality (VR) head-mounted device (HMD) to enable fluid and natural explorations through embodied navigation, the avoidance of menus, and manual mode switching. We developed immersive visualization and interaction methods tailored to the characterization of FRPs, such as a Model in Miniature, a similarity network, and a histo-book. An evaluation of our techniques with domain experts showed advantages in discovering structural patterns and similarities. Especially novices can strongly benefit from our intuitive representation and spatial rendering.
SP  - NA
EP  - NA
JF  - Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3489849.3489851
ER  - 

TY  - NA
AU  - Ens, Barrett; Cordeil, Maxime; North, Chris; Dwyer, Tim; Besançon, Lonni; Prouzeau, Arnaud; Liu, Jiazhou; Cunningham, Andrew; Drogemuller, Adam; Satriadi, Kadek Ananta; Thomas, Bruce H
TI  - Immersive Analytics 2.0: Spatial and Embodied Sensemaking
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3503726
ER  - 

TY  - CONF
AU  - Natalie, Rosiana; Loh, Jolene; Tan, Huei Suen; Tseng, Joshua; Chan, Ian Luke Yi-Ren; Jarjue, Ebrima; Kacorri, Hernisa; Hara, Kotaro
TI  - ASSETS - The Efficacy of Collaborative Authoring of Video Scene Descriptions
PY  - 2021
AB  - The majority of online video contents remain inaccessible to people with visual impairments due to the lack of audio descriptions to depict the video scenes. Content creators have traditionally relied on professionals to author audio descriptions, but their service is costly and not readily-available. We investigate the feasibility of creating more cost-effective audio descriptions that are also of high quality by involving novices. Specifically, we designed, developed, and evaluated ViScene, a web-based collaborative audio description authoring tool that enables a sighted novice author and a reviewer either sighted or blind to interact and contribute to scene descriptions (SDs)—text that can be transformed into audio through text-to-speech. Through a mixed-design study with N = 60 participants, we assessed the quality of SDs created by sighted novices with feedback from both sighted and blind reviewers. Our results showed that with ViScene novices could produce content that is Descriptive, Objective, Referable, and Clear at a cost of i.e., US$2.81pvm to US$5.48pvm, which is 54% to 96% lower than the professional service. However, the descriptions lacked in other quality dimensions (e.g., learning, a measure of how well an SD conveys the video’s intended message). While professional audio describers remain the gold standard, for content creators who cannot afford it, ViScene offers a cost-effective alternative, ultimately leading to a more accessible medium.
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - CONF
AU  - Natalie, Rosiana; Loh, Jolene; Tan, Huei Suen; Tseng, Joshua; Kacorri, Hernisa; Hara, Kotaro
TI  - ASSETS - Uncovering Patterns in Reviewers’ Feedback to Scene Description Authors
PY  - 2021
AB  - Audio descriptions (ADs) can increase access to videos for blind people. Researchers have explored different mechanisms for generating ADs, with some of the most recent studies involving paid novices; to improve the quality of their ADs, novices receive feedback from reviewers. However, reviewer feedback is not instantaneous. To explore the potential for real-time feedback through automation, in this paper, we analyze 1,120 comments that 40 sighted novices received from a sighted or a blind reviewer. We find that feedback patterns tend to fall under four themes: (i) Quality; commenting on different AD quality variables, (ii) Speech Act; the utterance or speech action that the reviewers used, (iii) Required Action; the recommended action that the authors should do to improve the AD, and (iv) Guidance; the additional help that the reviewers gave to help the authors. We discuss which of these patterns could be automated within the review process as design implications for future AD collaborative authoring systems.
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Danry, Valdemar; Pataranutaporn, Pat; Mueller, Florian; Maes, Pattie; Leigh, Sang-won
TI  - On Eliciting a Sense of Self when Integrating with Computers
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Augmented Humans 2022
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3519391.3519414
ER  - 

TY  - JOUR
AU  - Hassan, Waseem; Raza, Ahsan; Abdullah, Muhammad; Hashem, Mohammad Shadman; Jeon, Seokhee
TI  - HapWheel: Bringing In-Car Controls to Driver's Fingertips by Embedding Ubiquitous Haptic Displays into a Steering Wheel
PY  - 2022
AB  - Recently, there has been an excessive congestion occurring in the driving environment because of the presence of modern gadgets inside the car and increased traffic on the roads, which has resulted in a higher demand for the visual and cognitive senses. This prompted the need to reduce the demand to make driving experience safer and more comfortable. Consequently, a novel steering wheel design for in-car controls is presented in this paper. The new design introduces dual ubiquitous touch panels embedded in the steering wheel for interaction with in-car controls and haptic feedback as positive reinforcement upon successful execution of an in-car control. There are eight different functionalities that can be controlled using the embedded touch panels. The proposed system is compared with a standard car regarding its efficacy using the NASA task load index (NASA-TLX) evaluation technique. The results showed that the proposed system significantly reduced the drivers’ visual, cognitive, and manual workload.
SP  - 18526
EP  - 18534
JF  - IEEE Transactions on Intelligent Transportation Systems
VL  - 23
IS  - 10
PB  - 
DO  - 10.1109/tits.2022.3160496
ER  - 

TY  - JOUR
AU  - Liu, Li; Schoen, Andrew J; Henrichs, Curt; Li, Jingshan; Mutlu, Bilge; Zhang, Yajun; Radwin, Robert G
TI  - Human Robot Collaboration for Enhancing Work Activities.
PY  - 2022
AB  - <AbstractText Label="OBJECTIVE" NlmCategory="OBJECTIVE">Trade-offs between productivity, physical workload (PWL), and mental workload (MWL) were studied when integrating collaborative robots (cobots) into existing manual work by optimizing the allocation of tasks.</AbstractText> <AbstractText Label="BACKGROUND" NlmCategory="BACKGROUND">As cobots become more widely introduced in the workplace and their capabilities greatly improved, there is a need to consider how they can best help their human partners.</AbstractText> <AbstractText Label="METHODS" NlmCategory="METHODS">A theoretical data-driven analysis was conducted using the O*NET Content Model to evaluate 16 selected jobs for associated work context, skills, and constraints. Associated work activities were ranked by potential for substitution by a cobot. PWL and MWL were estimated using variables from the O*Net database that represent variables for the Strain Index and NASA-TLX. An algorithm was developed to optimize work activity assignment to cobots and human workers according to their most suited abilities.</AbstractText> <AbstractText Label="RESULTS" NlmCategory="RESULTS">Human workload for some jobs decreased while workload for some jobs increased after cobots were reassigned tasks, and residual human capacity was used to perform job activities designated the most important to increase productivity. The human workload for other jobs remained unchanged.</AbstractText> <AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">The changes in human workload from the introduction of cobots may not always be beneficial for the human worker unless trade-offs are considered.<b>Application</b>: The framework of this study may be applied to existing jobs to identify the relationship between productivity and worker tolerances that integrate cobots into specific tasks.</AbstractText>
SP  - 187208221077722
EP  - 001872082210777
JF  - Human factors
VL  - NA
IS  - NA
PB  - 
DO  - 10.1177/00187208221077722
ER  - 

TY  - BOOK
AU  - Komamizu, Takahiro; Ito, Shoi; Ogawa, Yasuhiro; Toyama, Katsuhiko
TI  - MIPR - FPX-G: First Person Exploration for Graph
PY  - 2021
AB  - Data exploration is a fundamental user task in the information seeking process. In data exploration, users have ambiguous information needs, and they traverse across the data for gathering information. In this paper, a novel data exploration system, called FPX-G, is proposed that uses virtual reality (VR) technology. VR-based data exploration (or immersive analytics) is a recent trend in data analytics, and the existing work approaches involve aggregated information in an interactive and 3D manner. However, exploration for individual pieces of data scarcely has been approached. Traditional data exploration is done on 2D displays, therefore space is limited, and there is no depth. FPX-G fully utilizes 3D space to make individual piece of data visible in the user’s line of sight. In this paper, the data structure in FPX-G is designed as a graph, and the data exploration process is modeled as graph traversal. To utilize the capability of VR, FPX-G provides a first person view-based interface from which users can look at individual pieces of data and can walk through the data (like walking in a library). In addition to the walking mechanism, to deal with limited physical space in a room, FPX-G introduces eye-tracking technology for traversing data through a graph. A simulation-based evaluation reveals that FPX-G provides a significantly efficient interface for exploring data compared with the traditional 2D interface.
SP  - 70
EP  - 76
JF  - 2021 IEEE 4th International Conference on Multimedia Information Processing and Retrieval (MIPR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/mipr51284.2021.00018
ER  - 

TY  - NA
AU  - Meier, Manuel; Streli, Paul; Fender, Andreas; Holz, Christian
TI  - VR - TaplD: Rapid Touch Interaction in Virtual Reality using Wearable Sensing
PY  - 2021
AB  - Current Virtual Reality systems typically use cameras to capture user input from controllers or free-hand mid-air interaction. In this paper, we argue that this is a key impediment to productivity scenarios in VR, which require continued interaction over prolonged periods of time-a requirement that controller or free-hand input in mid-air does not satisfy. To address this challenge, we bring rapid touch interaction on surfaces to Virtual Reality-the input modality that users have grown used to on phones and tablets for continued use. We present TapID, a wrist-based inertial sensing system that complements headset-tracked hand poses to trigger input in VR. TapID embeds a pair of inertial sensors in a flexible strap, one at either side of the wrist; from the combination of registered signals, TapID reliably detects surface touch events and, more importantly, identifies the finger used for touch. We evaluated TapID in a series of user studies on event-detection accuracy (F1 = 0.997) and hand-agnostic finger-identification accuracy (within-user: F1 = 0.93; across users: F1 = 0.91 after 10 refinement taps and F1 = 0.87 without refinement) in a seated table scenario. We conclude with a series of applications that complement hand tracking with touch input and that are uniquely enabled by TapID, including UI control, rapid keyboard typing and piano playing, as well as surface gestures.
SP  - 519
EP  - 528
JF  - 2021 IEEE Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr50410.2021.00076
ER  - 

TY  - NA
AU  - Li, Jiannan; Lyu, Jiahe; Sousa, Maurício; Balakrishnan, Ravin; Tang, Anthony; Grossman, Tovi
TI  - UIST - Route Tapestries: Navigating 360° Virtual Tour Videos Using Slit-Scan Visualizations
PY  - 2021
AB  - An increasingly popular way of experiencing remote places is by viewing 360° virtual tour videos, which show the surrounding view while traveling through an environment. However, finding particular locations in these videos can be difficult because current interfaces rely on distorted frame previews for navigation. To alleviate this usability issue, we propose Route Tapestries, continuous orthographic-perspective projection of scenes along camera routes. We first introduce an algorithm for automatically constructing Route Tapestries from a 360° video, inspired by the slit-scan photography technique. We then present a desktop video player interface using a Route Tapestry timeline for navigation. An online evaluation using a target-seeking task showed that Route Tapestries allowed users to locate targets 22% faster than with YouTube-style equirectangular previews and reduced the failure rate by 75% compared to a more conventional row-of-thumbnail strip preview. Our results highlight the value of reducing visual distortion and providing continuous visual contexts in previews for navigating 360°virtual tour videos.
SP  - 223
EP  - 238
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474746
ER  - 

TY  - JOUR
AU  - Ye, Yuping; Song, Zhan; Zhao, Juan
TI  - High-fidelity 3D real-time facial animation using infrared structured light sensing system
PY  - 2022
AB  - NA
SP  - 46
EP  - 58
JF  - Computers & Graphics
VL  - 104
IS  - NA
PB  - 
DO  - 10.1016/j.cag.2022.03.007
ER  - 

TY  - NA
AU  - Lee, Lik Hang; Braud, Tristan; Zhou, Pengyuan; Wang, Lin; Xu, Dianlei; Lin, Zijun; Kumar, Abhishek; Bermejo, Carlos; Hui, Pan
TI  - All One Needs to Know about Metaverse: A Complete Survey on Technological Singularity, Virtual Ecosystem, and Research Agenda
PY  - 2021
AB  - Since the popularisation of the Internet in the 1990s, the cyberspace has kept evolving. We have created various computer-mediated virtual environments including social networks, video conferencing, virtual 3D worlds (e.g., VR Chat), augmented reality applications (e.g., Pokemon Go), and Non-Fungible Token Games (e.g., Upland). Such virtual environments, albeit non-perpetual and unconnected, have bought us various degrees of digital transformation. The term `metaverse' has been coined to further facilitate the digital transformation in every aspect of our physical lives. At the core of the metaverse stands the vision of an immersive Internet as a gigantic, unified, persistent, and shared realm. While the metaverse may seem futuristic, catalysed by emerging technologies such as Extended Reality, 5G, and Artificial Intelligence, the digital `big bang' of our cyberspace is not far away. This survey paper presents the first effort to offer a comprehensive framework that examines the latest metaverse development under the dimensions of state-of-the-art technologies and metaverse ecosystems, and illustrates the possibility of the digital `big bang'. First, technologies are the enablers that drive the transition from the current Internet to the metaverse. We thus examine eight enabling technologies rigorously - Extended Reality, User Interactivity (Human-Computer Interaction), Artificial Intelligence, Blockchain, Computer Vision, IoT and Robotics, Edge and Cloud computing, and Future Mobile Networks. In terms of applications, the metaverse ecosystem allows human users to live and play within a self-sustaining, persistent, and shared realm. Therefore, we discuss six user-centric factors -- Avatar, Content Creation, Virtual Economy, Social Acceptability, Security and Privacy, and Trust and Accountability. Finally, we propose a concrete research agenda for the development of the metaverse.
SP  - NA
EP  - NA
JF  - arXiv: Computers and Society
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Li, Ke; Zhang, Ruidong; Liang, Bo; Guimbretière, François; Zhang, Cheng
TI  - EarIO
PY  - 2022
AB  - <jats:p>This paper presents EarIO, an AI-powered acoustic sensing technology that allows an earable (e.g., earphone) to continuously track facial expressions using two pairs of microphone and speaker (one on each side), which are widely available in commodity earphones. It emits acoustic signals from a speaker on an earable towards the face. Depending on facial expressions, the muscles, tissues, and skin around the ear would deform differently, resulting in unique echo profiles in the reflected signals captured by an on-device microphone. These received acoustic signals are processed and learned by a customized deep learning pipeline to continuously infer the full facial expressions represented by 52 parameters captured using a TruthDepth camera. Compared to similar technologies, it has significantly lower power consumption, as it can sample at 86 Hz with a power signature of 154 mW. A user study with 16 participants under three different scenarios, showed that EarIO can reliably estimate the detailed facial movements when the participants were sitting, walking or after remounting the device. Based on the encouraging results, we further discuss the potential opportunities and challenges on applying EarIO on future ear-mounted wearables.</jats:p>
SP  - 1
EP  - 24
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 2
PB  - 
DO  - 10.1145/3534621
ER  - 

TY  - JOUR
AU  - Mingozzi, Alessio; Conti, Andrea; Aleotti, Filippo; Poggi, Matteo; Mattoccia, Stefano
TI  - Monitoring Social Distancing With Single Image Depth Estimation
PY  - 2022
AB  - The recent pandemic emergency raised many challenges regarding the countermeasures aimed at containing the virus spread, and constraining the minimum distance between people resulted in one of the most effective strategies. Thus, the implementation of autonomous systems capable of monitoring the so-called <italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">social distance</i> gained much interest. In this paper, we aim to address this task leveraging a single RGB frame without additional depth sensors. In contrast to existing single-image alternatives failing when ground localization is not available, we rely on single image depth estimation to perceive the 3D structure of the observed scene and estimate the distance between people. During the setup phase, a straightforward calibration procedure, leveraging a scale-aware SLAM algorithm available even on consumer smartphones, allows us to address the scale ambiguity affecting single image depth estimation. We validate our approach through indoor and outdoor images employing a calibrated LiDAR + RGB camera asset. Experimental results highlight that our proposal enables sufficiently reliable estimation of the inter-personal distance to monitor social distancing effectively. This fact confirms that despite its intrinsic ambiguity, if appropriately driven single image depth estimation can be a viable alternative to other depth perception techniques, more expensive and not always feasible in practical applications. Our evaluation also highlights that our framework can run reasonably fast and comparably to competitors, even on pure CPU systems. Moreover, its practical deployment on low-power systems is around the corner.
SP  - 1290
EP  - 1301
JF  - IEEE Transactions on Emerging Topics in Computational Intelligence
VL  - 6
IS  - 6
PB  - 
DO  - 10.1109/tetci.2022.3171769
ER  - 

TY  - CHAP
AU  - Choi, Wonhyuk; Vazirani, Michel; Santolucito, Mark
TI  - Program Synthesis for Musicians: A Usability Testbed for Temporal Logic Specifications
PY  - 2021
AB  - In recent years, program synthesis research has made significant progress in creating user-friendly tools for Programming by example (PBE) and Programming by demonstration (PBD) environments. However, program synthesis from logical specifications, such as reactive synthesis, still faces large challenges in widespread adoption. In order to bring reactive synthesis to a wider audience, more research is necessary to explore different interface options. We present The SynthSynthesizer, a music-based tool for designing and testing specification interfaces. The tool enables researchers to prototype different interfaces for reactive synthesis and run user studies on them. The tool is accessible to both researchers and users by running on a browser on top of a docker-containerized synthesis toolchain. We show sample implementations with the tool by creating dropdown interfaces, and by running a user study with 21 users.
SP  - 47
EP  - 61
JF  - Programming Languages and Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-89051-3_4
ER  - 

TY  - CONF
AU  - Herskovitz, Jaylin; Wu, Jason; White, Samuel; Pavel, Amy; Reyes, Gabriel; Guo, Anhong; Bigham, Jeffrey P.
TI  - ASSETS - Making Mobile Augmented Reality Applications Accessible
PY  - 2020
AB  - Augmented Reality (AR) technology creates new immersive experiences in entertainment, games, education, retail, and social media. AR content is often primarily visual and it is challenging to enable access to it non-visually due to the mix of virtual and real-world content. In this paper, we identify common constituent tasks in AR by analyzing existing mobile AR applications for iOS, and characterize the design space of tasks that require accessible alternatives. For each of the major task categories, we create prototype accessible alternatives that we evaluate in a study with 10 blind participants to explore their perceptions of accessible AR. Our study demonstrates that these prototypes make AR possible to use for blind users and reveals a number of insights to move forward. We believe our work sets forth not only exemplars for developers to create accessible AR applications, but also a roadmap for future research to make AR comprehensively accessible.
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Ibrahim, Hanaa I. F.; Khaled, Heba; Seada, Noha A.; Faheem, Hossam
TI  - Binary Descriptors for Dense Stereo Matching
PY  - 2021
AB  - Dense local stereo matching is traditionally based on initial cost evaluation using a simple metric Dense local stereo matching is traditionally based on initial cost evaluation using a simple metric followed by sophisticated support aggregation. There is a high potential of replacing these simple metrics by robust binary descriptors. However, the available studies focus on comparing descriptors for sparse matching rather than the dense case of extracting a descriptor per each pixel. Therefore, this paper studies the design decisions of well-established binary descriptors such as BRIEF (Binary Robust Independent Elementary Features), ORB (Oriented FAST and rotated BRIEF), BRISK (Binary Robust Invariant Scalable Keypoints) and FREAK (Fast Retina Keypoint) to decide which one is more suitable for the dense matching case. The expremental results shows that agregation is required for use with binary descriptors to handle edges. Also, BRIEF produced the smoothnest disparity map if geometric transformations is not present. Whereas, FREAK and BRISK achieved the least overall error percentage across all regions. The lastest Middlebury Stereo benchmark is utilized in the experiments.
SP  - 124
EP  - 139
JF  - International Journal of Intelligent Computing and Information Sciences
VL  - 21
IS  - 2
PB  - 
DO  - 10.21608/ijicis.2021.63324.1073
ER  - 

TY  - NA
AU  - Cmentowski, Sebastian; Krekhov, Andrey; Zenner, André; Kucharski, Daniel; Krüger, Jens
TI  - VR - Towards Sneaking as a Playful Input Modality for Virtual Environments
PY  - 2021
AB  - Using virtual reality setups, users can fade out of their surroundings and dive fully into a thrilling and appealing virtual environment. The success of such immersive experiences depends heavily on natural and engaging interactions with the virtual world. As developers tend to focus on intuitive hand controls, other aspects of the broad range of full-body capabilities are easily left vacant. One repeatedly overlooked input modality is the user's gait. Even though users may walk physically to explore the environment, it usually does not matter how they move. However, gait-based interactions, using the variety of information contained in human gait, could offer interesting benefits for immersive experiences. For instance, stealth VR-games could profit from this additional range of interaction fidelity in the form of a sneaking-based input modality. In our work, we explore the potential of sneaking as a playful input modality for virtual environments. Therefore, we discuss possible sneaking-based gameplay mechanisms and develop three technical approaches, including precise foot-tracking and two abstraction levels. Our evaluation reveals the potential of sneaking-based inter-actions in IVEs, offering unique challenges and thrilling gameplay. For these interactions, precise tracking of individual footsteps is unnecessary, as a more abstract approach focusing on the players' intention offers the same experience while providing better comprehensible feedback. Based on these findings, we discuss the broader potential and individual strengths of our gait-centered interactions.
SP  - 473
EP  - 482
JF  - 2021 IEEE Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr50410.2021.00071
ER  - 

TY  - NA
AU  - Cools, Robbe; Esteves, Augusto; Simeone, Adalberto L.
TI  - Blending Spaces: Cross-Reality Interaction Techniques for Object Transitions Between Distinct Virtual and Augmented Realities
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar55827.2022.00069
ER  - 

TY  - NA
AU  - Herskovitz, Jaylin; Wu, Jason; White, Samuel; Pavel, Amy; Reyes, Gabriel; Guo, Anhong; Bigham, Jeffrey P.
TI  - Making Mobile Augmented Reality Applications Accessible
PY  - 2020
AB  - Augmented Reality (AR) technology creates new immersive experiences in entertainment, games, education, retail, and social media. AR content is often primarily visual and it is challenging to enable access to it non-visually due to the mix of virtual and real-world content. In this paper, we identify common constituent tasks in AR by analyzing existing mobile AR applications for iOS, and characterize the design space of tasks that require accessible alternatives. For each of the major task categories, we create prototype accessible alternatives that we evaluate in a study with 10 blind participants to explore their perceptions of accessible AR. Our study demonstrates that these prototypes make AR possible to use for blind users and reveals a number of insights to move forward. We believe our work sets forth not only exemplars for developers to create accessible AR applications, but also a roadmap for future research to make AR comprehensively accessible.
SP  - NA
EP  - NA
JF  - The 22nd International ACM SIGACCESS Conference on Computers and Accessibility
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3373625.3417006
ER  - 

TY  - NA
AU  - Wang, Yuntao; Ding, Jiexin; Chatterjee, Ishan; Salemi Parizi, Farshid; Zhuang, Yuzhou; Yan, Yukang; Patel, Shwetak; Shi, Yuanchun
TI  - FaceOri: Tracking Head Position and Orientation Using Ultrasonic Ranging on Earphones
PY  - 2022
AB  - Face orientation can often indicate users' intended interaction target. In this paper, we propose FaceOri, a novel face tracking technique based on acoustic ranging using earphones. FaceOri can leverage the speaker on a commodity device to emit an ultrasonic chirp, which is picked up by the set of microphones on the user's earphone, and then processed to calculate the distance from each microphone to the device. These measurements are used to derive the user's face orientation and distance with respect to the device. We conduct a ground truth comparison and user study to evaluate FaceOri's performance. The results show that the system can determine whether the user orients to the device at a 93.5% accuracy within a 1.5 meters range. Furthermore, FaceOri can continuously track the user's head orientation with a median absolute error of 10.9 mm in the distance, 3.7 degrees in yaw, and 5.8 degrees in pitch. FaceOri can allow for convenient hands-free control of devices and produce more intelligent context-aware interaction.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517698
ER  - 

TY  - NA
AU  - Tao, Yujie; Teng, Shan-Yuan; Lopes, Pedro
TI  - UIST - Altering Perceived Softness of Real Rigid Objects by Restricting Fingerpad Deformation
PY  - 2021
AB  - We propose a haptic device that alters the perceived softness of real rigid objects without requiring to instrument the objects. Instead, our haptic device works by restricting the user's fingerpad lateral deformation via a hollow frame that squeezes the sides of the fingerpad. This causes the fingerpad to become bulgier than it originally was—when users touch an object's surface with their now-restricted fingerpad, they feel the object to be softer than it is. To illustrate the extent of softness illusion induced by our device, touching the tip of a wooden chopstick will feel as soft as a rubber eraser. Our haptic device operates by pulling the hollow frame using a motor. Unlike most wearable haptic devices, which cover up the user's fingerpad to create force sensations, our device creates softness while leaving the center of the fingerpad free, which allows the users to feel most of the object they are interacting with. This makes our device a unique contribution to altering the softness of everyday objects, creating “buttons” by softening protrusions of existing appliances or tangibles, or even, altering the softness of handheld props for VR. Finally, we validated our device through two studies: (1) a psychophysics study showed that the device brings down the perceived softness of any object between 50A-90A to around 40A (on Shore A hardness scale); and (2) a user study demonstrated that participants preferred our device for interactive applications that leverage haptic props, such as making a VR prop feel softer or making a rigid 3D printed remote control feel softer on its button.
SP  - 985
EP  - 996
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474800
ER  - 

TY  - NA
AU  - Gunasekaran, Tamil Selvan; Hajika, Ryo; Haigh, Chloe Dolma Si Ying; Pai, Yun Suen; Lottridge, Danielle; Billinghurst, Mark
TI  - CHI Extended Abstracts - Adapting Fitts’ Law and N-Back to Assess Hand Proprioception
PY  - 2021
AB  - Proprioception is the body’s ability to sense the position and movement of each limb, as well as the amount of effort exerted onto or by them. Methods to assess proprioception have been introduced before, yet there is little to no study on assessing the degree of proprioception on body parts for use cases like gesture recognition wearable computing. We propose the use of Fitts’ law coupled with the N-Back task to evaluate proprioception of the hand. We evaluate 15 distinct points at the back of the hand and assess the musing extended 3D Fitts’ law. Our results show that the index of difficulty of tapping point from thumb to pinky increases gradually with a linear regression factor of 0.1144. Additionally, participants perform the tap before performing the N-Back task. From these results, we discuss the fundamental limitations and suggest how Fitts’ law can be further extended to assess proprioception
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451699
ER  - 

TY  - JOUR
AU  - Wang, Ziqi; Song, Peng; Pauly, Mark
TI  - MOCCA: modeling and optimizing cone-joints for complex assemblies
PY  - 2021
AB  - We present a computational framework for modeling and optimizing complex assemblies using cone joints. Cone joints are integral joints that generalize traditional single-direction joints such as mortise and tenon joints to support a general cone of directions for assembly. This additional motion flexibility not just reduces the risk of deadlocking for complex joint arrangements, but also simplifies the assembly process, in particular for automatic assembly by robots. On the other hand, compared to planar contacts, cone joints restrict relative part movement for improved structural stability. Cone joints can be realized in the form of curved contacts between associated parts, which have demonstrated good mechanical properties such as reduced stress concentration. To find the best trade-off between assemblability and stability, we propose an optimization approach that first determines the optimal motion cone for each part contact and subsequently derives a geometric realization of each joint to match this motion cone. We demonstrate that our approach can optimize cone joints for assemblies with a variety of geometric forms, and highlight several application examples.
SP  - 1
EP  - 14
JF  - ACM Transactions on Graphics
VL  - 40
IS  - 4
PB  - 
DO  - 10.1145/3450626.3459680
ER  - 

TY  - NA
AU  - Aso, Kohei; Hwang, Dong-Hyun; Koike, Hideki
TI  - AHs - Portable 3D Human Pose Estimation for Human-Human Interaction using a Chest-Mounted Fisheye Camera
PY  - 2021
AB  - We propose a system that estimates the 3D body pose of other parties using a single RGB chest-mounted ultra-wide fisheye camera. Although the fisheye camera can capture a wide field of view, it is difficult to apply image processing for perspective images because of its strong distortion. In our method, the input fisheye image is converted to an equirectangular image to detect another person and their 2D keypoints, and then convert them to a 3D pose. In order to adapt to the distortion of equirectangular images, we generate a synthetic dataset and fine-tune the model. We also estimate the location of the other person so that we can reconstruct the absolute camera-centered global pose. We evaluate the accuracy on real-world data and show that the fine-tuned model performs best.
SP  - 116
EP  - 120
JF  - Augmented Humans Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3458709.3458986
ER  - 

TY  - NA
AU  - Xu, Nancy; Masling, Sam; Du, Michael; Campagna, Giovanni; Heck, Larry; Landay, James A.; Lam, Monica S.
TI  - Grounding Open-Domain Instructions to Automate Web Support Tasks.
PY  - 2021
AB  - Grounding natural language instructions on the web to perform previously unseen tasks enables accessibility and automation. We introduce a task and dataset to train AI agents from open-domain, step-by-step instructions originally written for people. We build RUSS (Rapid Universal Support Service) to tackle this problem. RUSS consists of two models: First, a BERT-LSTM with pointers parses instructions to ThingTalk, a domain-specific language we design for grounding natural language on the web. Then, a grounding model retrieves the unique IDs of any webpage elements requested in ThingTalk. RUSS may interact with the user through a dialogue (e.g. ask for an address) or execute a web operation (e.g. click a button) inside the web runtime. To augment training, we synthesize natural language instructions mapped to ThingTalk. Our dataset consists of 80 different customer service problems from help websites, with a total of 741 step-by-step instructions and their corresponding actions. RUSS achieves 76.7% end-to-end accuracy predicting agent actions from single instructions. It outperforms state-of-the-art models that directly map instructions to actions without ThingTalk. Our user study shows that RUSS is preferred by actual users over web navigation.
SP  - NA
EP  - NA
JF  - arXiv: Computation and Language
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Fletcher, Mark D.; Verschuur, Carl
TI  - Electro-Haptic Stimulation: A New Approach for Improving Cochlear-Implant Listening.
PY  - 2021
AB  - Cochlear implants (CIs) have been remarkably successful at restoring speech perception for severely to profoundly deaf individuals. Despite their success, several limitations remain, particularly in CI users' ability to understand speech in noisy environments, locate sound sources, and enjoy music. A new multimodal approach has been proposed that uses haptic stimulation to provide sound information that is poorly transmitted by the implant. This augmenting of the electrical CI signal with haptic stimulation (electro-haptic stimulation; EHS) has been shown to improve speech-in-noise performance and sound localization in CI users. There is also evidence that it could enhance music perception. We review the evidence of EHS enhancement of CI listening and discuss key areas where further research is required. These include understanding the neural basis of EHS enhancement, understanding the effectiveness of EHS across different clinical populations, and the optimization of signal-processing strategies. We also discuss the significant potential for a new generation of haptic neuroprosthetic devices to aid those who cannot access hearing-assistive technology, either because of biomedical or healthcare-access issues. While significant further research and development is required, we conclude that EHS represents a promising new approach that could, in the near future, offer a non-invasive, inexpensive means of substantially improving clinical outcomes for hearing-impaired individuals.
SP  - 581414
EP  - 581414
JF  - Frontiers in neuroscience
VL  - 15
IS  - NA
PB  - 
DO  - 10.3389/fnins.2021.581414
ER  - 

TY  - NA
AU  - Hamanishi, Natsuki; Rekimoto, Jun
TI  - AHs - Motion-specific browsing method by mapping to a circle for personal video Observation with Head-Mounted Displays
PY  - 2021
AB  - Understanding the temporal changes of movement and posture in two-dimensional (2D) videos is not easy, leading users to repeat observations to understand them. However, the video interface relying on timeline representations, which depend on one’s memory, makes it hard more than necessary for a user to observe movements because they lack original motion information. Therefore, we propose a Motion Seek Circle as a user interface for Head-Mounted Displays. They visualize the motion in a video on a circle in three-dimensional space, representing temporal and spatial changes with trails and humanoid models. This automatically generated circle combined with a 2D video provides a visual overview of the movement. Our user test and study show proof of concept in a personal training context. Results indicate the proposed method is easily learnable for untrained people. By creating a visual overview of movements, we intend to solve traditional video-learning difficulties.
SP  - 240
EP  - 250
JF  - Augmented Humans Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3458709.3458959
ER  - 

TY  - JOUR
AU  - Zhang, Ruidong; Chen, Mingyang; Steeper, Benjamin; Li, Yaxuan; Yan, Zihan; Chen, Yizhuo; Tao, Songyun; Chen, Tuochao; Lim, Hyunchul; Zhang, Cheng
TI  - SpeeChin
PY  - 2021
AB  - <jats:p>This paper presents SpeeChin, a smart necklace that can recognize 54 English and 44 Chinese silent speech commands. A customized infrared (IR) imaging system is mounted on a necklace to capture images of the neck and face from under the chin. These images are first pre-processed and then deep learned by an end-to-end deep convolutional-recurrent-neural-network (CRNN) model to infer different silent speech commands. A user study with 20 participants (10 participants for each language) showed that SpeeChin could recognize 54 English and 44 Chinese silent speech commands with average cross-session accuracies of 90.5% and 91.6%, respectively. To further investigate the potential of SpeeChin in recognizing other silent speech commands, we conducted another study with 10 participants distinguishing between 72 one-syllable nonwords. Based on the results from the user studies, we further discuss the challenges and opportunities of deploying SpeeChin in real-world applications.</jats:p>
SP  - 1
EP  - 23
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 4
PB  - 
DO  - 10.1145/3494987
ER  - 

TY  - NA
AU  - Yigitbas, Enes; Klauke, Jonas; Gottschalk, Sebastian; Engels, Gregor
TI  - VL/HCC - VREUD - An End-User Development Tool to Simplify the Creation of Interactive VR Scenes
PY  - 2021
AB  - Recent advances in Virtual Reality (VR) technology and the increased availability of VR-equipped devices enable a wide range of consumer-oriented applications. For novice developers, however, creating interactive scenes for VR applications is a complex and cumbersome task that requires high technical knowledge which is often missing. This hinders the potential of enabling novices to create, modify, and execute their own interactive VR scenes. Although recent authoring tools for interactive VR scenes are promising, most of them focus on expert professionals as the target group and neglect the novices with low programming knowledge. To lower the entry barrier, we provide an open-source web-based End-User Development (EUD) tool, called VREUD, that supports the rapid construction and execution of interactive VR scenes. Concerning construction, VREUD enables the specification of the VR scene including interactions and tasks. Furthermore, VREUD supports the execution and immersive experience of the created interactive VR scenes on VR head-mounted displays. Based on a user study, we have analyzed the effectiveness, efficiency, and user satisfaction of VREUD which shows promising results to empower novices in creating their interactive VR scenes.
SP  - 1
EP  - 10
JF  - 2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vl/hcc51201.2021.9576372
ER  - 

TY  - JOUR
AU  - Leake, Mackenzie; Bernstein, Gilbert; Davis, Abe; Agrawala, Maneesh
TI  - A mathematical foundation for foundation paper pieceable quilts
PY  - 2021
AB  - Foundation paper piecing is a popular technique for constructing fabric patchwork quilts using printed paper patterns. But, the construction process imposes constraints on the geometry of the pattern and the order in which the fabric pieces are attached to the quilt. Manually designing foundation paper pieceable patterns that meet all of these constraints is challenging. In this work we mathematically formalize the foundation paper piecing process and use this formalization to develop an algorithm that can automatically check if an input pattern geometry is foundation paper pieceable. Our key insight is that we can represent the geometric pattern design using a certain type of dual hypergraph where nodes represent faces and hyperedges represent seams connecting two or more nodes. We show that determining whether the pattern is paper pieceable is equivalent to checking whether this hypergraph is acyclic, and if it is acyclic, we can apply a leaf-plucking algorithm to the hypergraph to generate viable sewing orders for the pattern geometry. We implement this algorithm in a design tool that allows quilt designers to focus on producing the geometric design of their pattern and let the tool handle the tedious task of determining whether the pattern is foundation paper pieceable.
SP  - 1
EP  - 14
JF  - ACM Transactions on Graphics
VL  - 40
IS  - 4
PB  - 
DO  - 10.1145/3450626.3459853
ER  - 

TY  - NA
AU  - Tsai, Hsin-Ruey; Tsai, Chieh; Liao, Yu-So; Chiang, Yi-Ting; Zhang, Zhong-Yi
TI  - FingerX: Rendering Haptic Shapes of Virtual Objects Augmented by Real Objects using Extendable and Withdrawable Supports on Fingers
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517489
ER  - 

TY  - NA
AU  - Romat, Hugo; Marquardt, Nicolai; Hinckley, Ken; Henry Riche, Nathalie
TI  - Style Blink: Exploring Digital Inking of Structured Information via Handcrafted Styling as a First-Class Object
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501988
ER  - 

TY  - NA
AU  - Ihorn, Shasta; Siu, Yue-Ting; Bodi, Aditya; Narins, Lothar; Castanon, Jose M.; Kant, Yash; Das, Abhishek; Yoon, Ilmi; Fazli, Pooyan
TI  - NarrationBot and InfoBot: A Hybrid System for Automated Video Description
PY  - 2021
AB  - Video accessibility is crucial for blind and low vision users for equitable engagements in education, employment, and entertainment. Despite the availability of professional and amateur services and tools, most human-generated descriptions are expensive and time consuming. Moreover, the rate of human-generated descriptions cannot match the speed of video production. To overcome the increasing gaps in video accessibility, we developed a hybrid system of two tools to 1) automatically generate descriptions for videos and 2) provide answers or additional descriptions in response to user queries on a video. Results from a mixed-methods study with 26 blind and low vision individuals show that our system significantly improved user comprehension and enjoyment of selected videos when both tools were used in tandem. In addition, participants reported no significant difference in their ability to understand videos when presented with autogenerated descriptions versus human-revised autogenerated descriptions. Our results demonstrate user enthusiasm about the developed system and its promise for providing customized access to videos. We discuss the limitations of the current work and provide recommendations for the future development of automated video description tools.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Su, Wei; Liu, Yuehu; Li, Shasha; Cai, Zerun
TI  - Proprioception-Driven Wearer Pose Estimation for Egocentric Video
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 26th International Conference on Pattern Recognition (ICPR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/icpr56361.2022.9956092
ER  - 

TY  - NA
AU  - Atarashi, Yui
TI  - CHI Extended Abstracts - Instrumeteor: Authoring tool for Guitar Performance Video
PY  - 2021
AB  - To show off their playing, musicians publish musical performance videos on streaming services. In order to find out typical characteristics of guitar performance videos, we carried out a quantitative survey of guitar performance videos. Then, we discuss key problems of creating effects informed by the survey. According to the discussion, authoring videos with typical effects takes a long time even for experienced users because they typically need to combine multiple video tracks (e.g., lyrics and videos shot from multiple angles) into a single track. They need to synchronize all tracks with the musical piece and set transitions between them at the right timing, aware of the musical structure. This paper presents Instrumeteor, an authoring tool for musical performance videos. First, it automatically analyzes the musical structure in the tracks to align them on a single timeline. Second, it implements typical video effects informed by the survey. In this way, our tool reduces manual work and unleashes the musicians’ creativity.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451521
ER  - 

TY  - JOUR
AU  - Leake, Mackenzie; Bernstein, Gilbert; Davis, Abe; Agrawala, Maneesh
TI  - A mathematical foundation for foundation paper pieceable quilts
PY  - 2021
AB  - NA
SP  - 1
EP  - 14
JF  - ACM Transactions on Graphics
VL  - 40
IS  - 4
PB  - 
DO  - 10.1145/3476576.3476616
ER  - 

TY  - NA
AU  - Lao, Cheryl; Xia, Haijun; Wigdor, Daniel; Chevalier, Fanny
TI  - SUI - Attribute Spaces: Supporting Design Space Exploration in Virtual Reality
PY  - 2021
AB  - Exploring the design space of configurations for objects in virtual scenes is a challenge within virtual reality authoring tools due to the lack of visualization capabilities, non-destructive operations, suggestions, and flexibility. This work introduces Attribute Spaces, tools for visualizing and manipulating object attributes in virtual reality during 3D content generation. Attribute Spaces enable designers to systematically explore design spaces by supporting rapid comparisons between design alternatives and offering design suggestions. Custom combinations of attributes can be grouped and manipulated simultaneously for several objects. The grouping supports the creation of custom operation combinations that can be used as tools to edit multiple attribute, as well as snapshots of promising design decisions for later review. In an evaluation of Attribute Spaces by 3D design experts, our approach was found to enhance users’ understanding of their design space exploration progress and showed promise for integration into existing 3D workflows.
SP  - NA
EP  - NA
JF  - Symposium on Spatial User Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3485279.3485290
ER  - 

TY  - NA
AU  - Johnstone, Ross; McDonnell, Neil; Williamson, Julie R.
TI  - When Virtuality Surpasses Reality: Possible Futures of Ubiquitous XR
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3516396
ER  - 

TY  - JOUR
AU  - Liu, Yilin; Zhang, Shijia; Gowda, Mahanth; Nelakuditi, Srihari
TI  - Leveraging the Properties of mmWave Signals for 3D Finger Motion Tracking for Interactive IoT Applications
PY  - 2022
AB  - <jats:p> mmWave signals form a critical component of 5G and next-generation wireless networks, which are also being increasingly considered for sensing the environment around us to enable ubiquitous IoT applications. In this context, this paper leverages the properties of mmWave signals for tracking 3D finger motion for interactive IoT applications. While conventional vision-based solutions break down under poor lighting, occlusions, and also suffer from privacy concerns, mmWave signals work under typical occlusions and non-line-of-sight conditions, while being privacy-preserving. In contrast to prior works on mmWave sensing that focus on predefined gesture classification, this work performs continuous 3D finger motion tracking. Towards this end, we first observe via simulations and experiments that the small size of fingers coupled with specular reflections do not yield stable mmWave reflections. However, we make an interesting observation that focusing on the forearm instead of the fingers can provide stable reflections for 3D finger motion tracking. Muscles that activate the fingers extend through the forearm, whose motion manifests as vibrations on the forearm. By analyzing the variation in phases of reflected mmWave signals from the forearm, this paper designs <jats:italic>mm4Arm,</jats:italic> a system that tracks 3D finger motion. Nontrivial challenges arise due to the high dimensional search space, complex vibration patterns, diversity across users, hardware noise, etc. mm4Arm exploits anatomical constraints in finger motions and fuses them with machine learning architectures based on encoder-decoder and ResNets in enabling accurate tracking. A systematic performance evaluation with 10 users demonstrates a median error of 5.73° (location error of 4.07 mm) with robustness to multipath and natural variation in hand position/orientation. The accuracy is also consistent under non-line-of-sight conditions and clothing that might occlude the forearm. <jats:italic>mm4Arm</jats:italic> runs on smartphones with a latency of 19 <jats:italic>ms</jats:italic> and low energy overhead. </jats:p>
SP  - 1
EP  - 28
JF  - Proceedings of the ACM on Measurement and Analysis of Computing Systems
VL  - 6
IS  - 3
PB  - 
DO  - 10.1145/3570613
ER  - 

TY  - NA
AU  - Emerson, Leah; Lipinski, Riley; Shirey, Heather; Malloy, Theresa; Marrinan, Thomas
TI  - ISMAR Adjunct - Enabling Collaborative Interaction with 360° Panoramas between Large-scale Displays and Immersive Headsets
PY  - 2021
AB  - Head mounted displays (HMDs) can provide users with an immersive virtual reality (VR) experience, but often are limited to viewing a single environment or data set at a time. In this paper, we describe a system of networked applications whereby co-located users in the real world can use a large-scale display wall to collaborate and share data with immersed users wearing HMDs. Our work focuses on the sharing of 360° surround-view panoramic images and contextual annotations. The large-scale display wall affords non-immersed users the ability to view a multitude of contextual information and the HMDs afford the ability for users to immerse themselves in a virtual scene. The asymmetric virtual reality collaboration between immersed and non-immersed individuals can lead to deeper under-standing and the feeling of a shared experience. We will highlight a series of use cases – two digital humanities projects that capture real locations using a 360° camera, and one scientific discovery project that uses computer generated 360° surround-view panoramas. In all cases, groups can benefit from both the immersive capabilities of HMDs and the collaborative affordances of large-scale display walls, and a unified experience is created for all users.
SP  - 183
EP  - 188
JF  - 2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar-adjunct54149.2021.00045
ER  - 

TY  - JOUR
AU  - Wang, Cheng Yao; Zhou, Qian; Fitzmaurice, George; Anderson, Fraser
TI  - VideoPoseVR: Authoring Virtual Reality Character Animations with Online Videos
PY  - 2022
AB  - <jats:p>We present VideoPoseVR, a video-based animation authoring workflow using online videos to author character animations in VR. It leverages the state-of-the-art deep learning approach to reconstruct 3D motions from online videos, caption the motions, and store them in a motion dataset. Creators can import the videos, search in the dataset, modify the motion timeline, and combine multiple motions from videos to author character animations in VR. We implemented a proof-of-concept prototype and conducted a user study to evaluate the feasibility of the video-based authoring approach as well as gather initial feedback of the prototype. The study results suggest that VideoPoseVR was easy to learn for novice users to author animations and enable rapid exploration of prototyping for applications such as entertainment, skills training, and crowd simulations.</jats:p>
SP  - 448
EP  - 467
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - ISS
PB  - 
DO  - 10.1145/3567728
ER  - 

TY  - NA
AU  - Chi, Peggy; Frey, Nathan; Panovich, Katrina; Essa, Irfan
TI  - UIST - Automatic Instructional Video Creation from a Markdown-Formatted Tutorial
PY  - 2021
AB  - We introduce HowToCut, an automatic approach that converts a Markdown-formatted tutorial into an interactive video that presents the visual instructions with a synthesized voiceover for narration. HowToCut extracts instructional content from a multimedia document that describes a step-by-step procedure. Our method selects and converts text instructions to a voiceover. It makes automatic editing decisions to align the narration with edited visual assets, including step images, videos, and text overlays. We derive our video editing strategies from an analysis of 125 web tutorials and apply Computer Vision techniques to the assets. To enable viewers to interactively navigate the tutorial, HowToCut’s conversational UI presents instructions in multiple formats upon user commands. We evaluated our automatically-generated video tutorials through user studies (N=20) and validated the video quality via an online survey (N=93). The evaluation shows that our method was able to effectively create informative and useful instructional videos from a web tutorial document for both reviewing and following.
SP  - 677
EP  - 690
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474778
ER  - 

TY  - NA
AU  - Kim, Myung Jin; Ryu, Neung; Chang, Wooje; Pahud, Michel; Sinclair, Mike; Bianchi, Andrea
TI  - SpinOcchio: Understanding Haptic-Visual Congruency of Skin-Slip in VR with a Dynamic Grip Controller
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517724
ER  - 

TY  - NA
AU  - Nazarova, Elena; Sautenkov, Oleg; Cabrera, Miguel Altamirano; Tirado, Jonathan; Serpiva, Valerii; Rakhmatulin, Viktor; Tsetserukou, Dzmitry
TI  - CobotAR: Interaction with Robots using Omnidirectionally Projected Image and DNN-based Gesture Recognition.
PY  - 2021
AB  - Several technological solutions supported the creation of interfaces for Augmented Reality (AR) multi-user collaboration in the last years. However, these technologies require the use of wearable devices. We present CobotAR - a new AR technology to achieve the Human-Robot Interaction (HRI) by gesture recognition based on Deep Neural Network (DNN) - without an extra wearable device for the user. The system allows users to have a more intuitive experience with robotic applications using just their hands. The CobotAR system assumes the AR spatial display created by a mobile projector mounted on a 6 DoF robot. The proposed technology suggests a novel way of interaction with machines to achieve safe, intuitive, and immersive control mediated by a robotic projection system and DNN-based algorithm. We conducted the experiment with several parameters assessment during this research, which allows the users to define the positives and negatives of the new approach. The mental demand of CobotAR system is twice less than Wireless Gamepad and by 16\% less than Teach Pendant.
SP  - NA
EP  - NA
JF  - arXiv: Robotics
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Raman, Arun; Kumar, Viraj
TI  - Programming Pedagogy and Assessment in the Era of AI/ML: A Position Paper
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - COMPUTE 2022
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3561833.3561843
ER  - 

TY  - JOUR
AU  - Wang, Ziqi; Song, Peng; Pauly, Mark
TI  - State of the Art on Computational Design of Assemblies with Rigid Parts
PY  - 2021
AB  - NA
SP  - 633
EP  - 657
JF  - Computer Graphics Forum
VL  - 40
IS  - 2
PB  - 
DO  - 10.1111/cgf.142660
ER  - 

TY  - NA
AU  - Le, Viet-Duc; Hoang, Van-Nam; Nguyen, Tien-Thanh; Le, Van-Hung; Tran, Thanh-Hai; Vu, Hai; Le, Thi-Lan
TI  - MAPR - A Unified Deep Framework for Hand Pose Estimation and Dynamic Hand Action Recognition from First-Person RGB Videos
PY  - 2021
AB  - Understanding hand action from the first-person video has emerged recently thanks to its wide potential applications such as hand rehabilitation, augmented reality. The majority of works mainly reply on RGB images. Compared with RGB images, hand joints have certain advantages as they are robust to illuminations and appearance variation. However, previous works for hand action recognition usually employed hand joints that are manually determined. This paper presents a unified framework for both hand pose estimation and hand action recognition from first-person RGB images. First, our framework estimates 3D hand joints from every RGB image using a combination of Resnet and a Graphical convolutional network. Then, an adaptation of a SOTA method PA-ResGCN for the human skeleton is proposed for hand action recognition from estimated hand joints. Our framework takes advantage of efficient graphical networks to model graph-like human hand structure in both phases: hand pose estimation and hand action recognition. We evaluate the proposed framework on the First Person Hand Action Benchmark (FPHAB). The experiments show that the proposed framework outperforms different SOTA methods on both hand pose estimation and hand action recognition tasks.
SP  - 1
EP  - 6
JF  - 2021 International Conference on Multimedia Analysis and Pattern Recognition (MAPR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/mapr53640.2021.9585280
ER  - 

TY  - NA
AU  - Lyu, Zhuoyue; Li, Jiannan; Wang, Bryan
TI  - AIive: Interactive Visualization and Sonification of Neural Network in Virtual Reality
PY  - 2021
AB  - Artificial Intelligence (AI), especially Neural Network (NN), has become increasingly popular. However, people usually treat AI as a tool, focusing on improving outcome, accuracy, and performance while paying less attention to the representation of AI itself. We present AIive, an interactive visualization of AI in Virtual Reality (VR) that brings AI "alive". AIive enables users to manipulate the parameters of NN with virtual hands and provides auditory feedback for the real-time values of loss, accuracy, and hyperparameters. Thus, AIive contributes an artistic and intuitive way to represent AI by integrating visualization, sonification, and direct manipulation in VR, potentially targeting a wide range of audiences.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Li, Ang; Liu, Jiazhou; Cordeil, Max; Ens, Barrett
TI  - Initial Evaluation of Immersive Gesture Exploration with GestureExplorer
PY  - 2022
AB  - This paper presents GestureExplorer, which features versatile immersive visualisations to grant the user free control over their perspective, allowing them to gain a better understanding of gestures. It provides multiple data visualisation views, and interactive features to support analysis and exploration of gesture datasets. A pair of iterative user studies provides initial feedback from several participants, including experts on immersive visualisation, and demonstrates the potential of GestureExplorer for providing a useful and engaging experience for exploring gesture data.
SP  - NA
EP  - NA
JF  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vrw55335.2022.00141
ER  - 

TY  - JOUR
AU  - Matsuda, Nathan; Wheelwright, Brian; Hegland, Joel; Lanman, Douglas
TI  - VR social copresence with light field displays
PY  - 2021
AB  - <jats:p> As virtual reality (VR) devices become increasingly commonplace, asymmetric interactions between people with and without headsets are becoming more frequent. Existing video pass-through VR headsets solve one side of these asymmetric interactions by showing the user a live reconstruction of the outside world. This paper further advocates for <jats:italic>reverse pass-through VR</jats:italic> , wherein a three-dimensional view of the user's face and eyes is presented to any number of outside viewers in a perspective-correct manner using a light field display. Tying together research in social telepresence and copresence, autostereoscopic displays, and facial capture, reverse pass-through VR enables natural eye contact and other important non-verbal cues in a wider range of interaction scenarios, providing a path to potentially increase the utility and social acceptability of VR headsets in shared and public spaces. </jats:p>
SP  - 1
EP  - 13
JF  - ACM Transactions on Graphics
VL  - 40
IS  - 6
PB  - 
DO  - 10.1145/3478513.3480481
ER  - 

TY  - NA
AU  - Gonzalez-Franco, Mar; Sinclair, Mike; Ofek, Eyal
TI  - SAP - Asymmetry of Grasp in Haptic Perception
PY  - 2020
AB  - In this paper we present evidence that human perception of grasp might be most dependent on the information retrieved during the inward latch rather than the release of objects. This research is motivated by a number of haptic simulations and devices and grounded in perception science. We ran a user study (n=12) with two devices one capable of delivering compliant simulations for both grip and release (CLAW), i.e. symmetric device; the other only capable of delivering adaptive grip simulations (CapstanCrunch), i.e. asymmetric device. We fund that both performed similarly well for realism scores in a grasping task with objects of different stiffness. That similar performance was despite CapstanCrunch release was delivered by a constant spring independently of the compliance of the object. Our results show preliminary evidence that when simulating haptic grasp the release might be less important. And we propose a new theory of asymmetry of grasp in haptic perception.
SP  - NA
EP  - NA
JF  - ACM Symposium on Applied Perception 2020
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3385955.3407934
ER  - 

TY  - NA
AU  - Eguchi, Soya; Nagura, Yasuo; Tanaka, Hiroya
TI  - Realistic Rendering Tool for Pseudo-Structural Coloring with Multi-Color Extrusion of FFF 3D Printing
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - SIGGRAPH Asia 2022 Posters
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3550082.3564179
ER  - 

TY  - JOUR
AU  - YILMAZ, Faruk; METE, Anı Hande; FİDAN TÜRKÖN, Buse; İNCE, Özgür
TI  - Sağlık Hizmetlerinin Geleceğinde Metaverse Ekosistemi ve Teknolojileri: Uygulamalar, Fırsatlar ve Zorluklar
PY  - 2022
AB  - COVID-19 pandemisinin yol açtığı kısıtlamalar insanlığın bu gerçeğe uygun bir yaşam biçimi geliştirmesini zorunlu kılmıştır. Özellikle zorunlu ihtiyaçların karşılanması gereken bir sektör olan sağlık hizmetlerinde teknoloji kullanımı bu gereksinime bağlı olarak artış göstermiştir. Bu durum hem insan ihtiyaçlarının güvenle karşılanabileceği hem de fiziksel temas söz konusu olmadan insanların iletişim kurabileceği sanal bir evren olarak Metaverse kavramına olan ilgiyi artırmıştır. Bu çalışmanın amacı pek çok sektörde köklü değişimlere yol açması beklenen Metaverse kavramının sağlık hizmetlerinin geleceğine nasıl yön vereceğinin, sunduğu fırsatların ve barındırdığı zorlukların değerlendirilmesidir. Bu kapsamda Metaverse teknoloji bileşenleri olarak ele alınan genişletilmiş gerçeklik, yapay zeka, blok zincir, bilgisayarlı görü, kullanıcı etkileşimi, ağ, sınır bilişim, robotik ve nesnelerin interneti (IoT) gibi teknolojilerin sağlık hizmetlerindeki mevcut uygulamalarına yer verilmiştir. İlgili teknolojilerin Metaverse entegrasyonu ile birlikte uzaktan sunulabilecek sağlık hizmetleri için damgalama korkusu yaşayan ruh sağlığı ve cinsel yolla bulaşan hastalıkları bulunan hastalar, ileri yaşlılar ve çocuklar potansiyel hedef grupları olarak öngörülmüştür. Metaverse’ün sağlık turizmi, insan kaynağı, sağlık hizmetlerinde tedavi etkinliği, eğitim, hasta memnuniyeti ve veri yönetimi gibi pek çok konuda potansiyel fırsatlar ve avantajlar sunması beklenmektedir. Bununla birlikte Metaverse teknolojilerinin kullanım maliyeti, mahremiyet ihlalleri, veri gizliliği ve güvenliği ile bireylerin bu teknolojileri yoğun olarak kullanması sonucunda ortaya çıkabilecek sanal bağımlılık, sosyal izolasyon, davranış bozuklukları, artan kaygı ve stres gibi zorluklar da çalışmada değerlendirilmiştir.
SP  - NA
EP  - NA
JF  - Eurasian Journal of Health Technology Assessment
VL  - NA
IS  - NA
PB  - 
DO  - 10.52148/ehta.1082705
ER  - 

TY  - JOUR
AU  - Zhao, Yiqin; Ma, Chongyang; Huang, Haibin; Guo, Tian
TI  - LITAR
PY  - 2022
AB  - <jats:p>An accurate understanding of omnidirectional environment lighting is crucial for high-quality virtual object rendering in mobile augmented reality (AR). In particular, to support reflective rendering, existing methods have leveraged deep learning models to estimate or have used physical light probes to capture physical lighting, typically represented in the form of an environment map. However, these methods often fail to provide visually coherent details or require additional setups. For example, the commercial framework ARKit uses a convolutional neural network that can generate realistic environment maps; however the corresponding reflective rendering might not match the physical environments. In this work, we present the design and implementation of a lighting reconstruction framework called LITAR that enables realistic and visually-coherent rendering. LITAR addresses several challenges of supporting lighting information for mobile AR.</jats:p> <jats:p>First, to address the spatial variance problem, LITAR uses two-field lighting reconstruction to divide the lighting reconstruction task into the spatial variance-aware near-field reconstruction and the directional-aware far-field reconstruction. The corresponding environment map allows reflective rendering with correct color tones. Second, LITAR uses two noise-tolerant data capturing policies to ensure data quality, namely guided bootstrapped movement and motion-based automatic capturing. Third, to handle the mismatch between the mobile computation capability and the high computation requirement of lighting reconstruction, LITAR employs two novel real-time environment map rendering techniques called multi-resolution projection and anchor extrapolation. These two techniques effectively remove the need of time-consuming mesh reconstruction while maintaining visual quality. Lastly, LITAR provides several knobs to facilitate mobile AR application developers making quality and performance trade-offs in lighting reconstruction. We evaluated the performance of LITAR using a small-scale testbed experiment and a controlled simulation. Our testbed-based evaluation shows that LITAR achieves more visually coherent rendering effects than ARKit. Our design of multi-resolution projection significantly reduces the time of point cloud projection from about 3 seconds to 14.6 milliseconds. Our simulation shows that LITAR, on average, achieves up to 44.1% higher PSNR value than a recent work Xihe on two complex objects with physically-based materials.</jats:p>
SP  - 1
EP  - 29
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 3
PB  - 
DO  - 10.1145/3550291
ER  - 

TY  - NA
AU  - Heller, Florian; Todi, Kashyap; Luyten, Kris
TI  - MobileHCI - An Interactive Design Space for Wearable Displays
PY  - 2021
AB  - The promise of on-body interactions has led to widespread development of wearable displays. They manifest themselves in highly variable shapes and form, and are realized using technologies with fundamentally different properties. Through an extensive survey of the field of wearable displays, we characterize existing systems based on key qualities of displays and wearables, such as location on the body, intended viewers or audience, and the information density of rendered content. We present the results of this analysis in an open, web-based interactive design space that supports exploration and refinement along various parameters. The design space, which currently encapsulates 129 cases of wearable displays, aims to inform researchers and practitioners on existing solutions and designs, and enable the identification of gaps and opportunities for novel research and applications. Further, it seeks to provide them with a thinking tool to deliberate on how the displayed content should be adapted based on key design parameters. Through this work, we aim to facilitate progress in wearable displays, informed by existing solutions, by providing researchers with an interactive platform for discovery and reflection.
SP  - 4
EP  - NA
JF  - Proceedings of the 23rd International Conference on Mobile Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3447526.3472034
ER  - 

TY  - JOUR
AU  - Kuipers, Tim; Su, Renbo; Wu, Jun; Wang, Charlie C. L.
TI  - ITIL: Interlaced Topologically Interlocking Lattice for continuous dual-material extrusion
PY  - 2022
AB  - Abstract Material Extrusion (MEX) systems with dual-material capability can unlock interesting applications where flexible and rigid materials are combined. When chemically incompatible materials are concerned the adhesion between the two might be insufficient. Therefore researchers typically rely on dovetail type interlocking geometries in order to affix two bodies mechanically. However, dovetail type interlocking introduces extrusion discontinuities and relies on the material’s resistance to deformation, which is difficult to model. We propose a simple and effective 3D lattice consisting of interlaced horizontal beams in vertically alternating directions which interlock topologically: the interlaced topologically interlocking lattice (ITIL). It ensures continuous extrusion and ensures an interlock even for highly flexible materials. We develop analytical models for optimizing the ultimate tensile strength of the ITIL lattice in two different orientations relative to the interface: straight and diagonal. The analytical models are applied to polypropylene (PP) and polylactic acid (PLA) and verified by finite elements method (FEM) simulations and physical tensile experiments. In the diagonal orientation ITIL can obtain 82% of the theoretical upper bound of 8 . 6 MPa . ITIL seems to perform comparably to dovetail interlocking designs, while it lends itself to application to non-vertical interfaces. Optimizing the lattice for non-vertical interfaces, however, remains future work.
SP  - 102495
EP  - NA
JF  - Additive Manufacturing
VL  - 50
IS  - NA
PB  - 
DO  - 10.1016/j.addma.2021.102495
ER  - 

TY  - BOOK
AU  - Pazhayedath, Priyanka; Belchior, Pedro; Prates, Rafael; Silveira, Filipe; Lopes, Daniel Simões; Cools, Robbe; Esteves, Augusto; Simeone, Adalberto L.
TI  - VR Workshops - Exploring Bi-Directional Pinpointing Techniques for Cross-Reality Collaboration
PY  - 2021
AB  - Virtual Reality (VR) technology enables users to immerse themselves in artificial worlds. However, it isolates users from the outside world and impedes them from collaborating with other users who might be outside of the VR experience and vice-versa. We implemented two systems where we explore how such an external user in the real world can interact across realities with a user immersed in virtual reality, either locally or remotely, in order to to share pinpoint locations. In the first we investigate three cross-reality techniques for the external user to draw the attention of their VR counterpart on specific objects present in the virtual environment (Voice, Highlight, and Arrow). Participants performed better overall and preferred the Arrow technique, followed by the Highlight technique. In the second system we expand on these two techniques to explore an even starker cross-reality interaction between users in VR and users interacting via a tablet computer to direct each other to pinpoint objects in the scene. We adapted the previous two techniques and implemented two others (Vision cone, Pointing) that support bi-directional communication between users. When it comes to bi-directional pinpointing, VR users still showed preference for the Arrow technique (now described as Pointing in Giant mode), while mobile users were split between the Vision cone and the Highlight techniques.
SP  - 264
EP  - 270
JF  - 2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vrw52623.2021.00055
ER  - 

TY  - CHAP
AU  - Kuang, Lisheng; Marchal, Maud; Aggravi, Marco; Giordano, Paolo Robuffo; Pacchierotti, Claudio
TI  - Design of a 2-DoF Haptic Device for Motion Guidance
PY  - 2022
AB  - <jats:title>Abstract</jats:title><jats:p>We present a 2-degrees-of-freedom (2-DoF) haptic device, which can be either used as a grounded or a hand-held device. It is composed of two platforms moving with respect to each other, actuated by two servomotors housed in one of structures. The device implements a rigid coupling mechanism between the two platforms, based on a three-legged 3-4R constrained parallel linkage, with the two servomotors actuating two of these legs. The device can apply position/kinesthetic haptic feedback to the user hand(s). This paper presents the device and its kinematics, together with a human subjects experiment where we evaluate its capabilities to provide meaningful directional information.</jats:p>
SP  - 198
EP  - 206
JF  - Haptics: Science, Technology, Applications
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-06249-0_23
ER  - 

TY  - NA
AU  - Han, Changyo; Takahashi, Ryo; Yahagi, Yuchi; Naemura, Takeshi
TI  - CHI Extended Abstracts - 3D Printing Firm Inflatables with Internal Tethers
PY  - 2021
AB  - This paper presents a technique for 3D printing firm inflatables with consumer-grade fused-deposition modeling (FDM) 3D printers and flexible filaments. By printing bridges inside the inflatable to tie its walls, internal tethers can retain the shape of the surfaces when inflated. This internal structure gives extra stiffness to the inflatables while retaining them lightweight and portable; the inflatables can be squished down to reduce the volume and inflated back to a sturdy state. Compared to conventional drop-stitch fabrics, the length of internal tethers can be easily varied owing to 3D printing, allowing us to fabricate angled surfaces as well as parallel surfaces. We evaluate the physical properties of the 3D-printed inflatables with internal tethers made with diverse printing parameters. Finally, we demonstrate the feasibility of our technique in custom inflatable design with example applications.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451613
ER  - 

TY  - NA
AU  - Elvitigala, Don Samitha; Huber, Jochen; Nanayakkara, Suranga
TI  - AHs - Augmented Foot: A Comprehensive Survey of Augmented Foot Interfaces
PY  - 2021
AB  - Augmented foot interfaces have been studied since the beginning of wearable computers. The worlds’ first wearable computer was an instrumented shoe that consisted of a toe operated switch with a wireless module. Since then, academic research and commercial products on augmented foot interfaces are booming with novel interfaces every year. This paper surveys the body of work on augmented foot interfaces and shows the current trends and guidelines for future augmented foot interfaces. We contribute a classification of over 100 academic papers and commercially-available products. We discuss the integration of augmented foot interfaces, interaction schemes and application domains. Finally, we contribute a set of design considerations to scaffold future research of augmented foot interfaces based on the classification and inspired by the surveyed work.
SP  - 228
EP  - 239
JF  - Augmented Humans Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3458709.3458958
ER  - 

TY  - NA
AU  - Xiang, Shicheng; Chen, Xiao; Zhou, Jun
TI  - BMSB - An Efficient Method for Boosting Human Pose Estimation
PY  - 2021
AB  - Most existing human pose estimation approaches fall into designing new network architectures or tend to apply deeper layers. Most of the methods are time-consuming, and lightweight plug-in for improving human pose estimation to the existing network gets little investigation. In this paper, we propose a lightweight plug-in module to boost the performance of human pose estimation named PoseReNed. PoseReNet is a network with three branches that are designed to tackle the attenuation caused by occluded keypoints or different scales of the keypoints. Generally, small-scale keypoints are more difficult to detect, and we observe that different channels of the output feature map have different attributes to the performance of estimation. We apply a channel attention mechanism to re-weight the channel to trade-off among different scales of the keypoints. By aggregating multiscale output feature maps, the pose estimation performance can be improved. Serving as a model-agnostic plug-in, PoseReNet brings about significant performance boost to existing human pose estimation models. Extensive experiments show that PoseReNet can effectively improve precision on COCO and MPII.
SP  - 1
EP  - 6
JF  - 2021 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/bmsb53066.2021.9547183
ER  - 

TY  - NA
AU  - Jung, Sungchul; Wu, Yuanjie; McKee, Ryan; Lindeman, Robert W.
TI  - All Shook Up: The Impact of Floor Vibration in Symmetric and Asymmetric Immersive Multi-user VR Gaming Experiences
PY  - 2022
AB  - This paper investigates the influence of floor-vibration tactile feedback on immersed users. Under symmetric and asymmetric tactile sensory cue conditions, we explore how multi-user Virtual Reality (VR) experiences are impacted by these cues in terms of illusion and coherence. Based on the reported positive impact of tactile cues in solo VR experiences, we posit that if context-matched perceptual tactile feedback is exchanged between users, they will report a significantly enhanced VR experience compared to not receiving the sensory stimuli, even within the same immersive VR experience. With our custom-built, computer-controlled vibration floor, we implemented a cannonball shooting game for two physically-separated players. In the VR game, the two players shoot cannonballs to destroy their opponent&#x2019;s protective wall and cannon, while the programmed floor platform generates vertical vibrations depending on the experimental condition. We used a mixed-factorial design with four conditions for each pair of participants: 1) both A and B had vibration, and 2) neither A nor B had vibration (the Symmetric group), or 3) A had vibration, but B did not, and 4) B had vibration, but A did not (the Asymmetric group). We collected subjective and objective data for variables previously shown to be related to levels of illusion, coherence, and usability, including Presence, Co-Presence, Social Presence, Plausibility Illusion, Engagement, Embodiment, Coherence, Gaming Performance, and Overall Preference. A total of 39 pairs of participants were involved in the study. We found statistically significant differences for the vibration conditions on Co-Presence, Social Presence, Engagement, and Coherence, and for the symmetric conditions on the Plausibility Illusion and Coherence, but only with trivial or small effect sizes. The results indicate that vibration provided to a pair of game players in immersive VR can significantly enhance the VR experience, but sensory symmetry does not guarantee improved gaming performance.
SP  - NA
EP  - NA
JF  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr51125.2022.00095
ER  - 

TY  - NA
AU  - Fang, Chiao; Chan, Vivian Hsinyueh; Cheng, Lung-Pan
TI  - Flaticulation: Laser Cutting Joints with Articulated Angles
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545695
ER  - 

TY  - NA
AU  - Wu, Nan; Lin, Felix Xiaozhu; Qian, Feng; Han, Bo
TI  - Hybrid mobile vision for emerging applications
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 23rd Annual International Workshop on Mobile Computing Systems and Applications
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3508396.3512876
ER  - 

TY  - NA
AU  - Fukuda, Atsushi
TI  - CHI Extended Abstracts - Onomatangiplay : A Game Experience with a Tangible Auditory User Interface Created by Representing Game Effects with a Real-world Sound Source
PY  - 2021
AB  - Since the advent of augmented reality, video game representations have been extended beyond the display. Many studies have used real objects to assist in the presentation of visual and haptic information, resulting in video games that are integrated with reality. Researchers often use tangibles UIs as a method to extend visual and haptic information presentation, but they commonly use speakers for auditory information presentation, and tangibles UIs dealing with real objects have few applications except for some music applications. In this study, we developed a device that presents game sound effects using real object sound sources. By assigning a real object sound source to each of the game sound effects, not only can auditory information be presented instead of speakers, but also a tangible UI can be realized where the user can access the video game by touching the sound source. We named this tangible UI as Tangible-Auditory User Interface (t-AUI), referring to GUI, and CLI. The production of t-AUI will enable the application of tangible UI to sound generating devices such as holding down and blocking the output of video game sound effects with hands, and reproducing sound effects with real objects for video game operation.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451853
ER  - 

TY  - NA
AU  - Li, Toby Jia-Jun; Lu, Yuwen; Clark, Jaylexia; Chen, Meng; Cox, Victor; Jiang, Meng; Yang, Yang; Kay, Tamara; Wood, Danielle; Brockman, Jay
TI  - A Bottom-Up End-User Intelligent Assistant Approach to Empower Gig Workers against AI Inequality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 Symposium on Human-Computer Interaction for Work
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3533406.3533418
ER  - 

TY  - CHAP
AU  - Feng, Brandon Y.; Zhang, Yinda; Tang, Danhang; Du, Ruofei; Varshney, Amitabh
TI  - PRIF: Primary Ray-Based Implicit Function
PY  - 2022
AB  - NA
SP  - 138
EP  - 155
JF  - Lecture Notes in Computer Science
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-20062-5_9
ER  - 

TY  - JOUR
AU  - Rogeau, Nicolas; Latteur, Pierre; Weinand, Yves
TI  - An integrated design tool for timber plate structures to generate joints geometry, fabrication toolpath, and robot trajectories
PY  - 2021
AB  - Abstract This paper presents an integrated design tool for structures composed of engineered timber panels that are connected by traditional wood joints. Recent advances in computational architecture have permitted to automate the fabrication and assembly of such structures using Computer Numerical Control (CNC) machines and industrial robotic arms. While several large-scale demonstrators have been realized, most developed algorithms are closed-source or project-oriented. The lack of a general framework makes it difficult for architects, engineers and designers to effectively manipulate this innovative construction system. Therefore, this research aims at developing a holistic design tool targeting a wide range of architectural applications. Main achievements include: (1) a new data structure to deal with modular assemblies, (2) an analytical parametrization of the geometry of five timber joints, (3) a method to generate CNC toolpath while integrating fabrication constraints, and (4) a method to automatically compute robot trajectories for a given stack of timber plates.
SP  - 103875
EP  - NA
JF  - Automation in Construction
VL  - 130
IS  - NA
PB  - 
DO  - 10.1016/j.autcon.2021.103875
ER  - 

TY  - JOUR
AU  - Lee, Hyoseung; Oh, Seungjae; Choi, Seungmoon
TI  - Data-Driven Rendering of Motion Effects for Walking Sensations in Different Gaits.
PY  - 2022
AB  - Motion effects are a vital component in 4D interactive applications, where special physical effects, such as motion, vibration, and wind, are provided with audiovisual stimuli. In 4D films and VR games, the scenes that show human locomotion appear frequently, and motion effects emphasizing such movements can enhance the viewers' immersive experiences. This paper proposes a data-driven framework for automatic generation of the motion effects that provide users with walking sensations. Measurements are made using the motion sensors attached to the human body during locomotion in different gaits, e.g., walking, running, and stumping. The captured data are processed and converted to multiple degree-of-freedom commands to a motion platform. We demonstrate that the data-driven motion commands can be represented in a greatly lower-dimensional space by principal component analysis. This finding leads to an algorithm for the synthesis of new motion commands that can elicit the target gait's walking sensations. The perceptual performance of our method is validated by two user studies. This work contributes to investigating the feasibility of mimicking walking sensations using a motion platform based on human locomotion data and developing an automatic generation algorithm of motion effects conveying the impressions of different gaits.
SP  - 547
EP  - 559
JF  - IEEE transactions on haptics
VL  - 15
IS  - 3
PB  - 
DO  - 10.1109/toh.2022.3176964
ER  - 

TY  - NA
AU  - Kitayama, Fumiya; Kondo, Ryou
TI  - Development of Linear Oscillatory Actuator with 4-poles and 8-poles Movers
PY  - 2021
AB  - Recently, inertia force generators with linear oscillatory actuators have been reported to reduce undesirable vibrations in automobiles and precision devices. In the IFG, a conventional actuator could effectively generate the inertia force for narrow frequency range because it has only one mover. The aim of this study is to widen the frequency range. Accordingly, we proposed a novel linear oscillatory actuator with 4-poles and 8-poles movers for inertia force generators. An even-even pole combination could significantly reduce the undesirable attractive force between the movers, through simple theoretical analysis, static electromagnetic analysis using finite element method, and measurements on a prototype. Moreover, the proposed LOA could effectively generate the inertia force at two different frequency ranges by switching the phase of the current, through dynamic analysis and measurements.
SP  - NA
EP  - NA
JF  - 2021 IEEE International Magnetic Conference (INTERMAG)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/intermag42984.2021.9580068
ER  - 

TY  - NA
AU  - Hohmann, Matthias R.; Konieczny, Lisa; Hackl, Michelle; Wirth, Brian; Zaman, Talha; Enficiaud, Raffi; Grosse-Wentrup, Moritz; Schölkopf, Bernhard
TI  - UIST - MYND: Unsupervised Evaluation of Novel BCI Control Strategies on Consumer Hardware
PY  - 2020
AB  - Neurophysiological laboratory studies are often constraint to immediate geographical surroundings and access to equipment may be temporally restricted. Limitations of ecological validity, scalability, and generalizability of findings pose a significant challenge for the development of brain-computer interfaces (BCIs), which ultimately need to function in any context, on consumer-grade hardware. We introduce MYND: An open-source framework that couples consumer-grade recording hardware with an easy-to-use application for the unsupervised evaluation of BCI control strategies. Subjects are guided through experiment selection, hardware fitting, recording, and data upload in order to self-administer multi-day studies that include neurophysiological recordings and questionnaires at home. As a use case, thirty subjects evaluated two BCI control strategies "Positive memories" and "Music imagery" by using a four-channel electroencephalogram (EEG) with MYND. Neural activity in both control strategies could be decoded with an average offline accuracy of 68.5% and 64.0% across all days.
SP  - 1071
EP  - 1084
JF  - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3379337.3415844
ER  - 

TY  - NA
AU  - Devrio, Nathan; Harrison, Chris
TI  - DiscoBand: Multiview Depth-Sensing Smartwatch Strap for Hand, Body and Environment Tracking
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545634
ER  - 

TY  - NA
AU  - Fang, Likun; Malte, Reimann; Pescara, Erik; Beigl, Michael
TI  - Investigate the Piano Learning Rate with Haptic Actuators in Mixed Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Augmented Humans 2022
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3519391.3524174
ER  - 

TY  - NA
AU  - Chae, Joohwan; Kim, Donghan; Jeong, Wooseok; Jo, Eunchan; Jeong, Won-Ki; Choi, JunYoung; Kim, Seung-wook; Kim, Myoung Gon; Lee, Jae-Won; Lee, Hyechan; Han, JungHyun
TI  - Virtual Air Conditioner's Airflow Simulation and Visualization in AR
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 28th ACM Symposium on Virtual Reality Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3562939.3565615
ER  - 

TY  - BOOK
AU  - Fukusato, Tsukasa; Maejima, Akinobu
TI  - MIG - Interactive Viewpoint Exploration for Constructing View-Dependent Models
PY  - 2021
AB  - We introduce an interactive method to sequentially find viewpoints for constructing view-dependent models which represent view-specific deformations in classic 2D cartoons [Chaudhuri et al. 2004, 2007; Koyama and Igarashi 2013; Rademacher 1999]. As users design one view-specific model from a single-fixed viewpoint, the system searches successive viewpoints for subsequent modeling and instantly jumps to the next viewpoints. Thereby, the users can efficiently repeat the design process of view-specific deformations until they are satisfied. This method is simple enough to easily implement in an existing modeling system. We conduct a user study with novice and amateur users and confirm that the proposed system is effective for designing view-specific models envisioned by the users.
SP  - NA
EP  - NA
JF  - Motion, Interaction and Games
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3487983.3488287
ER  - 

TY  - NA
AU  - Figueiredo, Vanessa; Franceschi, Wilter
TI  - CHI Extended Abstracts - Tagbly: Enhanced Multimedia
PY  - 2021
AB  - Tagbly is an acronym for Text Audio Graphics Assem BLY. It is a method and system that synchronizes audio data with image data using an HTML control file. The HTML control file contains references to linked multimedia asset files and timestamps indicating when each of these multimedia assets will be displayed/played. Audiovisual content creators can incorporate interactive content, such as graphic elements (e.g., pictures, 360 images and 3D models), text-based annotations, clickable links and buttons, and zooming in/out of images. Viewers can interact with the interactive features while the multimedia content is being displayed/played. In the viewer's eye, Tagbly's audiovisual content looks like an “interactive video”.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451544
ER  - 

TY  - NA
AU  - Watanabe, Akira; Uchida, Takuya; Iwai, Daisuke; Sato, Kosuke
TI  - Hovering and Contact Representation of Laser Contour-Based Hand with Swinging Tablet PC for Distant Communication
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490149.3505566
ER  - 

TY  - NA
AU  - Ghandeharizadeh, Shahram
TI  - Holodeck: Immersive 3D Displays Using Swarms of Flying Light Specks.
PY  - 2021
AB  - Unmanned Aerial Vehicles (UAVs) have moved beyond a platform for hobbyists to enable environmental monitoring, journalism, film industry, search and rescue, package delivery, and entertainment. This paper describes 3D displays using swarms of flying light specks, FLSs. An FLS is a small (hundreds of micrometers in size) UAV with one or more light sources to generate different colors and textures with adjustable brightness. A synchronized swarm of FLSs renders an illumination in a pre-specified 3D volume, an FLS display. An FLS display provides true depth, enabling a user to perceive a scene more completely by analyzing its illumination from different angles. An FLS display may either be non-immersive or immersive. Both will support 3D acoustics. Non-immersive FLS displays may be the size of a 1980's computer monitor, enabling a surgical team to observe and control micro robots performing heart surgery inside a patient's body. Immersive FLS displays may be the size of a room, enabling users to interact with objects, e.g., a rock, a teapot. An object with behavior will be constructed using FLS-matters. FLS-matter will enable a user to touch and manipulate an object, e.g., a user may pick up a teapot or throw a rock. An immersive and interactive FLS display will approximate Star Trek's Holodeck. A successful realization of the research ideas presented in this paper will provide fundamental insights into implementing a Holodeck using swarms of FLSs. A Holodeck will transform the future of human communication and perception, and how we interact with information and data. It will revolutionize the future of how we work, learn, play and entertain, receive medical care, and socialize.
SP  - NA
EP  - NA
JF  - arXiv: Human-Computer Interaction
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Buruk, Oðuz 'Oz'; Hamari, Juho
TI  - CHI Extended Abstracts - Towards the Next Generation of Extended Reality Wearables
PY  - 2021
AB  - Extended reality (XR) systems are among the most prominent interactive environments of today’s entertainment. These systems are often complemented by supportive wearables such as haptic gloves or full–body suits. However, applications are usually limited to tactile feedback and gestural controls while other strong parts of wearables such as the performative, social and interactive features are neglected. To investigate the ways of designing wearables for playful XR environments by drawing upon these strong parts, we conducted five participatory design workshops with 25 participants. Our study resulted in 14 design concepts that were synthesized into three design themes that include 9 sub-themes, namely Virtual Costumes, Modification of Bodily Perception and Social Bioadaptivity. The knowledge created extends the design space of XR wearables and opens new paths for designers and researchers to explore.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451697
ER  - 

TY  - NA
AU  - Suzuki, Tomohito; Imai, Yuhei; Manabe, Hiroyuki
TI  - A bonding technique for electric circuit prototyping using conductive transfer foil and soldering iron
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The Adjunct Publication of the 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526114.3558670
ER  - 

TY  - JOUR
AU  - Coelho, Hugo; Monteiro, Pedro; Gonçalves, Guilherme; Melo, Miguel; Bessa, Maximino
TI  - Authoring tools for virtual reality experiences: a systematic review
PY  - 2022
AB  - NA
SP  - 28037
EP  - 28060
JF  - Multimedia Tools and Applications
VL  - 81
IS  - 19
PB  - 
DO  - 10.1007/s11042-022-12829-9
ER  - 

TY  - NA
AU  - Schneider, Oliver; Fruchard, Bruno; Wittchen, Dennis; Joshi, Bibhushan Raj; Freitag, Georg; Degraen, Donald; Strohmeier, Paul
TI  - Sustainable Haptic Design: Improving Collaboration, Sharing, and Reuse in Haptic Design Research
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3503734
ER  - 

TY  - NA
AU  - Lyu, Zhuoyue; Li, Jiannan; Wang, Bryan
TI  - AIive: Interactive Visualization and Sonification of Neural Networks in Virtual Reality
PY  - 2021
AB  - Artificial Intelligence (AI), especially Neural Networks (NNs), has become increasingly popular. However, people usually treat AI as a tool, focusing on improving outcome, accuracy, and performance while paying less attention to the representation of AI itself. We present AIive, an interactive visualization of AI in Virtual Reality (VR) that brings AI “alive”. AIive enables users to manipulate the parameters of NNs with virtual hands and provides auditory feedback for the real-time values of loss, accuracy, and hyperparameters. Thus, AIive contributes an artistic and intuitive way to represent AI by integrating visualization, sonification, and direct manipulation in VR, potentially targeting a wide range of audiences.
SP  - NA
EP  - NA
JF  - 2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/aivr52153.2021.00057
ER  - 

TY  - NA
AU  - Fatima, Noor
TI  - Human Skin as an Interface: Attitudes & Preconceptions
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - NA
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Wang, Jian; Liu, Lingjie; Xu, Weipeng; Sarkar, Kripasindhu; Theobalt, Christian
TI  - Estimating Egocentric 3D Human Pose in Global Space.
PY  - 2021
AB  - Egocentric 3D human pose estimation using a single fisheye camera has become popular recently as it allows capturing a wide range of daily activities in unconstrained environments, which is difficult for traditional outside-in motion capture with external cameras. However, existing methods have several limitations. A prominent problem is that the estimated poses lie in the local coordinate system of the fisheye camera, rather than in the world coordinate system, which is restrictive for many applications. Furthermore, these methods suffer from limited accuracy and temporal instability due to ambiguities caused by the monocular setup and the severe occlusion in a strongly distorted egocentric perspective. To tackle these limitations, we present a new method for egocentric global 3D body pose estimation using a single head-mounted fisheye camera. To achieve accurate and temporally stable global poses, a spatio-temporal optimization is performed over a sequence of frames by minimizing heatmap reprojection errors and enforcing local and global body motion priors learned from a mocap dataset. Experimental results show that our approach outperforms state-of-the-art methods both quantitatively and qualitatively.
SP  - NA
EP  - NA
JF  - arXiv: Computer Vision and Pattern Recognition
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - JOUR
AU  - Natalie, Rosiana; Inn, Jolene Loh Kar; Suen, Tan Huei; Hao, Joshua Tseng Shi; Kacorri, Hernisa; Hara, Kotaro
TI  - Uncovering Patterns in Reviewers' Feedback to Scene Description Authors.
PY  - 2021
AB  - Audio descriptions (ADs) can increase access to videos for blind people. Researchers have explored different mechanisms for generating ADs, with some of the most recent studies involving paid novices; to improve the quality of their ADs, novices receive feedback from reviewers. However, reviewer feedback is not instantaneous. To explore the potential for real-time feedback through automation, in this paper, we analyze 1, 120 comments that 40 sighted novices received from a sighted or a blind reviewer. We find that feedback patterns tend to fall under four themes: (i) <b>Quality</b>; commenting on different AD quality variables, (ii) <b>Speech Act</b>; the utterance or speech action that the reviewers used, (iii) <b>Required Action</b>; the recommended action that the authors should do to improve the AD, and (iv) <b>Guidance</b>; the additional help that the reviewers gave to help the authors. We discuss which of these patterns could be automated within the review process as design implications for future AD collaborative authoring systems.
SP  - NA
EP  - NA
JF  - ASSETS. Annual ACM Conference on Assistive Technologies
VL  - 93
IS  - NA
PB  - 
DO  - 10.1145/3441852.3476550
ER  - 

TY  - NA
AU  - Chi, Peggy; Dong, Tao; Frueh, Christian; Colonna, Brian; Kwatra, Vivek; Essa, Irfan
TI  - Synthesis-Assisted Video Prototyping From a Document
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545676
ER  - 

TY  - NA
AU  - Krauß, Veronika; Nebeling, Michael; Jasche, Florian; Boden, Alexander
TI  - Elements of XR Prototyping: Characterizing the Role and Use of Prototypes in Augmented and Virtual Reality Design
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517714
ER  - 

TY  - NA
AU  - Mandl, David; Roth, Peter M.; Langlotz, Tobias; Ebner, Christoph; Mori, Shohei; Zollmann, Stefanie; Mohr, Peter; Kalkofen, Denis
TI  - ISMAR - Neural Cameras: Learning Camera Characteristics for Coherent Mixed Reality Rendering
PY  - 2021
AB  - Coherent rendering is important for generating plausible Mixed Reality presentations of virtual objects within a user’s real-world environment. Besides photo-realistic rendering and correct lighting, visual coherence requires simulating the imaging system that is used to capture the real environment. While existing approaches either focus on a specific camera or a specific component of the imaging system, we introduce Neural Cameras, the first approach that jointly simulates all major components of an arbitrary modern camera using neural networks. Our system allows for adding new cameras to the framework by learning the visual properties from a database of images that has been captured using the physical camera. We present qualitative and quantitative results and discuss future direction for research that emerge from using Neural Cameras.
SP  - 508
EP  - 516
JF  - 2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar52148.2021.00068
ER  - 

TY  - NA
AU  - Bodi, Aditya; Fazli, Pooyan; Ihorn, Shasta; Siu, Yue-Ting; Scott, Andrew T; Narins, Lothar; Kant, Yash; Das, Abhishek; Yoon, Ilmi
TI  - CHI Extended Abstracts - Automated Video Description for Blind and Low Vision Users
PY  - 2021
AB  - Video accessibility is crucial for blind and low vision users for equitable engagements in education, employment, and entertainment. Despite the availability of professional description services and tools for amateur description, most human-generated descriptions are expensive and time consuming, and the rate of human-generated descriptions simply cannot match the speed of video production. To overcome the increasing gaps in video accessibility, we developed a system to automatically generate descriptions for videos and answer blind and low vision users’ queries on the videos. Results from a pilot study with eight blind video aficionados indicate the promise of this system for meeting needs for immediate access to videos and validate our efforts in developing tools in partnership with the individuals we aim to benefit. Though the results must be interpreted with caution due to the small sample size, participants overall reported high levels of satisfaction with the system, and all preferred use of the system over no support at all.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451810
ER  - 

TY  - JOUR
AU  - Stanescu, Ana; Mohr, Peter; Schmalstieg, Dieter; Kalkofen, Denis
TI  - Model-Free Authoring by Demonstration of Assembly Instructions in Augmented Reality.
PY  - 2022
AB  - Among the most compelling applications of Augmented Reality are spatially registered tutorials. The effort of creating such instructions remains one of the obstacles precluding a wider use. We propose a system that is capable of extracting 3D instructions in a completely model-free manner from demonstrations, based on volumetric changes. The instructions are visualised later in an interactive Augmented Reality guidance application, on a mobile head-mounted display. We enable a technology that can be used by anyone in an ad-hoc tabletop setup for assemblies with rigid components.
SP  - 3821
EP  - 3831
JF  - IEEE transactions on visualization and computer graphics
VL  - 28
IS  - 11
PB  - 
DO  - 10.1109/tvcg.2022.3203104
ER  - 

TY  - NA
AU  - Bhat, Shariq Farooq; Alhashim, Ibraheem; Wonka, Peter
TI  - AdaBins: Depth Estimation using Adaptive Bins
PY  - 2020
AB  - We address the problem of estimating a high quality dense depth map from a single RGB input image. We start out with a baseline encoder-decoder convolutional neural network architecture and pose the question of how the global processing of information can help improve overall depth estimation. To this end, we propose a transformer-based architecture block that divides the depth range into bins whose center value is estimated adaptively per image. The final depth values are estimated as linear combinations of the bin centers. We call our new building block AdaBins. Our results show a decisive improvement over the state-of-the-art on several popular depth datasets across all metrics. We also validate the effectiveness of the proposed block with an ablation study and provide the code and corresponding pre-trained weights of the new state-of-the-art model.
SP  - NA
EP  - NA
JF  - arXiv: Computer Vision and Pattern Recognition
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Zhao, Jing
TI  - "Core Strength" of Dance Lala Training Considering the Body Motion Tracking Video and Predictive Model
PY  - 2022
AB  - "Core Strength" of the dance Lala training considering the body motion tracking video and predictive model is studied in this paper. When constructing the training sample template, it is necessary to set the value of the number of poses in advance. Too small a value will increase the error of the training action behavior template and reduce the recognition accuracy; too large a value will also increase the complexity of model training, training and recognition execution time will also increase. The function of the pose estimation module is to complete the description and expression of the specific posture of the human body at the current moment according to the frame image. After processing by the pose estimation module, each frame in the sequence can be calculated to obtain a feature vector, so that the image sequence can be converted into a feature vector sequence for the next step of action recognition. With these models, the applications on the dance Lala training is tested.
SP  - NA
EP  - NA
JF  - 2022 International Conference on Electronics and Renewable Systems (ICEARS)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/icears53579.2022.9752197
ER  - 

TY  - JOUR
AU  - Xia, Chengshuo; Fang, Xinrui; Arakawa, Riku; Sugiura, Yuta
TI  - VoLearn
PY  - 2022
AB  - <jats:p>Conventional motion tutorials rely mainly on a predefined motion and vision-based feedback that normally limits the application scenario and requires professional devices. In this paper, we propose VoLearn, a cross-modal system that provides operability for user-defined motion learning. The system supports the ability to import a desired motion from RGB video and animates the motion in a 3D virtual environment. We built an interface to operate on the input motion, such as controlling the speed, and the amplitude of limbs for the respective directions. With exporting of virtual rotation data, a user can employ a daily device (i.e., smartphone) as a wearable device to train and practice the desired motion according to comprehensive auditory feedback, which is able to provide both temporal and amplitude assessment. The user study demonstrated that the system helps reduce the amplitude and time errors of motion learning. The developed motion-learning system maintains the characteristics of high user accessibility, flexibility, and ubiquity in its application.</jats:p>
SP  - 1
EP  - 26
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 2
PB  - 
DO  - 10.1145/3534576
ER  - 

TY  - NA
AU  - Ishii, Ayaka; Kato, Kunihiro; Ikematsu, Kaori; Kawahara, Yoshihiro; Siio, Itiro
TI  - CircWood: Laser Printed Circuit Boards and Sensors for Affordable DIY Woodworking
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490149.3501317
ER  - 

TY  - JOUR
AU  - Yan, Zihan; Zhou, Jiayi; Wu, Yufei; Liu, Guanhong; Luo, Danli; Zhou, Zihong; Mi, Haipeng; Sun, Lingyun; Chen, Xiang 'Anthony'; Tao, Ye; Zhang, Yang; Wang, Guanyun
TI  - Shoes++
PY  - 2022
AB  - <jats:p>Feet are the foundation of our bodies that not only perform locomotion but also participate in intent and emotion expression. Thus, foot gestures are an intuitive and natural form of expression for interpersonal interaction. Recent studies have mostly introduced smart shoes as personal gadgets, while foot gestures used in multi-person foot interactions in social scenarios remain largely unexplored. We present Shoes++, which includes an inertial measurement unit (IMU)-mounted sole and an input vocabulary of social foot-to-foot gestures to support foot-based interaction. The gesture vocabulary is derived and condensed by a set of gestures elicited from a participatory design session with 12 users. We implement a machine learning model in Shoes++ which can recognize two-person and three-person social foot-to-foot gestures with 94.3% and 96.6% accuracies (N=18). In addition, the sole is designed to easily attach to and detach from various daily shoes to support comfortable social foot interaction without taking off the shoes. Based on users' qualitative feedback, we also found that Shoes++ can support team collaboration and enhance emotion expression, thus making social interactions or interpersonal dynamics more engaging in an expanded design space.</jats:p>
SP  - 1
EP  - 29
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 2
PB  - 
DO  - 10.1145/3534620
ER  - 

TY  - NA
AU  - Nisser, Martin; Cheng, Leon; Makaram, Yashaswini; Suzuki, Ryo; Mueller, Stefanie
TI  - UIST (Adjunct Volume) - Programmable Polarities: Actuating Interactive Prototypes with Programmable Electromagnets
PY  - 2021
AB  - This demo introduces a framework that uses programmable electromagnets as a method to rapidly prototype interactive objects. Our approach allows users to to quickly and inexpensively embed actuation mechanisms into otherwise static prototypes in order to make them dynamic and interactive. Underpinning the technique is the insight of using electromagnets to interchangeably create attractive and repulsive forces between adjacent parts, and programmatically setting their polarities in a way that allows objects to translate rotationally and linearly, respond haptically, assemble, and locomote.
SP  - 121
EP  - 123
JF  - The Adjunct Publication of the 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3474349.3480198
ER  - 

TY  - NA
AU  - Dementyev, Artem; Getreuer, Pascal; Kanevsky, Dimitri; Slaney, Malcolm; Lyon, Richard F.
TI  - UIST - VHP: Vibrotactile Haptics Platform for On-body Applications
PY  - 2021
AB  - Wearable vibrotactile devices have many potential applications, including sensory substitution for accessibility and notifications. Currently, vibrotactile experimentation is done using large lab setups. However, most practical applications require standalone on-body devices and integration into small form factors. Such integration is time-consuming and requires expertise. With a goal to democratize wearable haptics we introduce VHP, a vibrotactile haptics platform. It includes a low-power miniature electronics board that can drive up to 12 independent channels of haptic signals with arbitrary waveforms at a 2 kHz sampling rate. The platform can drive vibrotactile actuators including linear resonant actuators and voice coils. The control hardware is battery-powered and programmable, and has multiple input options, including serial and Bluetooth, as well as the ability to synthesize haptic signals internally. We developed current-based loading sensing, thus allowing for unique features such as actuator auto-classification, and skin-contact quality sensing. Our technical evaluations showed that the system met all our initial design criteria and is an improvement over prior methods as it allows all-day wear, has low latency, has battery life between 3 and 25 hours, and can run 12 actuators simultaneously. We demonstrate unique applications that would be time-consuming to develop without the VHP platform. We show that VHP can be used as bracelet, sleeve and phone-case form factors. The bracelet was programmed with an audio-to-tactile interface and was successfully worn for multiple days over months by developers. To facilitate more use of this platform, we open-source our design and plan to make the hardware widely available. We hope this work will motivate the use and study of vibrotactile all-day wearable devices.
SP  - 598
EP  - 612
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474772
ER  - 

TY  - JOUR
AU  - Jin, Yincheng; Gao, Yang; Xu, Xuhai; Choi, Seokmin; Li, Jiyang; Liu, Feng; Li, Zhengxiong; Jin, Zhanpeng
TI  - EarCommand
PY  - 2022
AB  - <jats:p>Intelligent speech interfaces have been developing vastly to support the growing demands for convenient control and interaction with wearable/earable and portable devices. To avoid privacy leakage during speech interactions and strengthen the resistance to ambient noise, silent speech interfaces have been widely explored to enable people's interaction with mobile/wearable devices without audible sounds. However, most existing silent speech solutions require either restricted background illuminations or hand involvement to hold device or perform gestures. In this study, we propose a novel earphone-based, hand-free silent speech interaction approach, named EarCommand. Our technique discovers the relationship between the deformation of the ear canal and the movements of the articulator and takes advantage of this link to recognize different silent speech commands. Our system can achieve a WER (word error rate) of 10.02% for word-level recognition and 12.33% for sentence-level recognition, when tested in human subjects with 32 word-level commands and 25 sentence-level commands, which indicates the effectiveness of inferring silent speech commands. Moreover, EarCommand shows high reliability and robustness in a variety of configuration settings and environmental conditions. It is anticipated that EarCommand can serve as an efficient, intelligent speech interface for hand-free operation, which could significantly improve the quality and convenience of interactions.</jats:p>
SP  - 1
EP  - 28
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 2
PB  - 
DO  - 10.1145/3534613
ER  - 

TY  - NA
AU  - Karpov, Aleksei; Makarov, Ilya
TI  - Exploring Efficiency of Vision Transformers for Self-Supervised Monocular Depth Estimation
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar55827.2022.00089
ER  - 

TY  - NA
AU  - Henrichs, Curt; Zhao, Fangyun; Mutlu, Bilge
TI  - RO-MAN - Designing Interface Aids to Assist Collaborative Robot Operators in Attention Management
PY  - 2021
AB  - As collaborative robots become increasingly widespread in manufacturing settings, there is a greater need for tools and interfaces to support operators who integrate, supervise, and troubleshoot these systems. In this paper, we present an application of the Robot Attention Demand (RAD) metric for use in the design of user interfaces to support operators in collaborative manufacturing scenarios. Building on prior work that introduced RAD, we designed and implemented prototype timeline and countdown-timer interfaces to be used within a collaborative assembly-inspection task where an operator is also responsible for a separate sorting task. We performed a user evaluation to investigate the effects of displaying predictive RAD information on operator performance and perceptions of the task. Our results show lower perceived task load and increased usability scores compared to baseline condition without an interface. These findings suggest that predictive RAD should be used by designers and engineers developing operator interfaces for collaborative robot applications in manufacturing.
SP  - 264
EP  - 271
JF  - 2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ro-man50785.2021.9515519
ER  - 

TY  - CHAP
AU  - Krishna, Ranjay; Gordon, Mitchell; Fei-Fei, Li; Bernstein, Michael S.
TI  - Visual Intelligence through Human Interaction
PY  - 2021
AB  - Over the last decade, Computer Vision, the branch of Artificial Intelligence aimed at understanding the visual world, has evolved from simply recognizing objects in images to describing pictures, answering questions about images, aiding robots maneuver around physical spaces, and even generating novel visual content. As these tasks and applications have modernized, so too has the reliance on more data, either for model training or for evaluation. In this chapter, we demonstrate that novel interaction strategies can enable new forms of data collection and evaluation for Computer Vision. First, we present a crowdsourcing interface for speeding up paid data collection by an order of magnitude, feeding the data-hungry nature of modern vision models. Second, we explore a method to increase volunteer contributions using automated social interventions. Third, we develop a system to ensure human evaluation of generative vision models are reliable, affordable, and grounded in psychophysics theory. We conclude with future opportunities for Human–Computer Interaction to aid Computer Vision.
SP  - 257
EP  - 314
JF  - Human–Computer Interaction Series
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-82681-9_9
ER  - 

TY  - NA
AU  - Ngoon, Tricia J.; Kim, Joy O.; Klemmer, Scott R.
TI  - Conference on Designing Interactive Systems - Shöwn: Adaptive Conceptual Guidance Aids Example Use in Creative Tasks
PY  - 2021
AB  - Examples are powerful tools for creativity and can provide inspiration and structure. However, novices often don’t know when to seek examples or how to apply them. Showing real-time examples targeted to the current task (adaptive conceptual guidance) may help novices consider inspiration more often and better implement the ideas that examples illustrate. We explore this in a Wizard-of-Oz system, Shown, that presents examples based on the user’s current activity while drawing a comic strip. Shown’s design is informed by interviews with novice and expert comic artists (n=18). A between-subjects experiment (n=24) found that adaptive conceptual guidance improved the clarity and uniqueness of drawings and stories compared to non-adaptive examples. Users also found the examples more useful and inspirational than those without adaptive guidance. Our results present an initial exploration of the challenges and benefits of contextually showing examples in interactive creativity tools.
SP  - 1834
EP  - 1845
JF  - Designing Interactive Systems Conference 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3461778.3462072
ER  - 

TY  - NA
AU  - Probst, Alice; Perelman, Gary; Dubois, Emmanuel; Serrano, Marcos
TI  - Acquisition visuelle en réalité mixte, depuis et vers une table interactive : Analyse de la transition entre un écran virtuel et un écran physique
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - IHM '22: Proceedings of the 33rd Conference on l'Interaction Humain-Machine
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3500866.3516377
ER  - 

TY  - NA
AU  - Li, Jiannan; Sousa, Maurício; Li, Chu; Liu, Jessie; Chen, Yan; Balakrishnan, Ravin; Grossman, Tovi
TI  - ASTEROIDS: Exploring Swarms of Mini-Telepresence Robots for Physical Skill Demonstration
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501927
ER  - 

TY  - JOUR
AU  - Röddiger, Tobias; Clarke, Christopher; Breitling, Paula; Schneegans, Tim; Zhao, Haibin; Gellersen, Hans; Beigl, Michael
TI  - Sensing with Earables
PY  - 2022
AB  - <jats:p>Earables have emerged as a unique platform for ubiquitous computing by augmenting ear-worn devices with state-of-the-art sensing. This new platform has spurred a wealth of new research exploring what can be detected on a wearable, small form factor. As a sensing platform, the ears are less susceptible to motion artifacts and are located in close proximity to a number of important anatomical structures including the brain, blood vessels, and facial muscles which reveal a wealth of information. They can be easily reached by the hands and the ear canal itself is affected by mouth, face, and head movements. We have conducted a systematic literature review of 271 earable publications from the ACM and IEEE libraries. These were synthesized into an open-ended taxonomy of 47 different phenomena that can be sensed in, on, or around the ear. Through analysis, we identify 13 fundamental phenomena from which all other phenomena can be derived, and discuss the different sensors and sensing principles used to detect them. We comprehensively review the phenomena in four main areas of (i) physiological monitoring and health, (ii) movement and activity, (iii) interaction, and (iv) authentication and identification. This breadth highlights the potential that earables have to offer as a ubiquitous, general-purpose platform.</jats:p>
SP  - 1
EP  - 57
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 3
PB  - 
DO  - 10.1145/3550314
ER  - 

TY  - NA
AU  - Banville, Hubert; Wood, Sean U. N.; Aimone, Chris; Engemann, Denis-Alexander; Gramfort, Alexandre
TI  - Robust learning from corrupted EEG with dynamic spatial filtering
PY  - 2021
AB  - Building machine learning models using EEG recorded outside of the laboratory setting requires methods robust to noisy data and randomly missing channels. This need is particularly great when working with sparse EEG montages (1-6 channels), often encountered in consumergrade or mobile EEG devices. Neither classical machine learning models nor deep neural networks trained end-to-end on EEG are typically designed or tested for robustness to corruption, and especially to randomly missing channels. While some studies have proposed strategies for using data with missing channels, these approaches are not practical when sparse montages are used and computing power is limited (e.g., wearables, cell phones). To tackle this problem, we propose dynamic spatial filtering (DSF), a multi-head attention module that can be plugged in before the first layer of a neural network to handle missing EEG channels by learning to focus on good channels and to ignore bad ones. We tested DSF on public EEG data encompassing ∼4,000 recordings with simulated channel corruption and on a private dataset of ∼100 at-home recordings of mobile EEG with natural corruption. Our proposed approach achieves the same performance as baseline models when no noise is applied, but outperforms baselines by as much as 29.4% accuracy when significant channel corruption is present. Moreover, DSF outputs are interpretable, making it possible to monitor channel importance in real-time. This approach has the potential to enable the analysis of EEG in challenging settings where channel corruption hampers the reading of brain signals.
SP  - NA
EP  - NA
JF  - arXiv: Learning
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Ly, Duy-Nam; La, Thanh-Thai; Le, Khanh-Duy; Nguyen, Cuong; Fjeld, Morten; Tran, Thanh Ngoc-Dat; Tran, Minh-Triet
TI  - 360TourGuiding: Towards Virtual Reality Training for Tour Guiding
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Adjunct Publication of the 24th International Conference on Human-Computer Interaction with Mobile Devices and Services
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3528575.3551436
ER  - 

TY  - NA
AU  - Shimizu, Shuntaro; Hashimoto, Takeru; Yoshida, Shigeo; Matsumura, Reo; Narumi, Takuji; Kuzuoka, Hideaki
TI  - VR - Unident: Providing Impact Sensations on Handheld Objects via High-Speed Change of the Rotational Inertia
PY  - 2021
AB  - Several virtual reality (VR) proxies have been developed that can emulate impact sensations by generating actual forces on the hand. Although these proxies contribute to increasing the reality of VR, they still have some limitations, such as high latency, high power consumption, and low frequency to provide impact sensations. To overcome these limitations, we first propose a method to provide an impact sensation without actual force generation by quickly changing the rotational inertia of a handheld proxy while users are swinging it. Then, we developed Unident, a handheld proxy capable of changing its rotational inertia by moving a weight along one axis at a high speed. Two experiments were conducted to evaluate the ability of Unident to provide users with impact sensations. In the first experiment, we demonstrate that Unident can physically provide an impact sensation applied to a handheld object by analyzing the pressure on the user's palm. The second experiment shows that Unident can provide an impact sensation with various magnitudes depending on the amount of rotational inertia to be changed. Finally, we present an application that can be enabled by Unident.
SP  - 11
EP  - 20
JF  - 2021 IEEE Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr50410.2021.00021
ER  - 

TY  - JOUR
AU  - Jewitt, Carey; Price, Sara; Steimle, Jürgen; Huisman, Gijs; Golmohammadi, Lili; Pourjafarian, Narges; Frier, William; Howard, Thomas; Ipakchian Askari, Sima; Ornati, Michela; Panëels, Sabrina; Weda, Judith
TI  - Manifesto for Digital Social Touch in Crisis
PY  - 2021
AB  - <jats:p>This qualitative exploratory research paper presents a <jats:italic>Manifesto for Digital Social Touch in Crisis</jats:italic> - a provocative call to action to designers, developers and researchers to rethink and reimagine social touch through a deeper engagement with the social and sensory aspects of touch. This call is motivated by concerns that social touch is in a crisis signaled by a decline in social touch over the past 2 decades, the problematics of inappropriate social touch, and the well documented impact of a lack of social touch on communication, relationships, and well-being and health. These concerns shape how social touch enters the digital realm and raise questions for how and when the complex space of social touch is mediated by technologies, as well the societal implications. The paper situates the manifesto in the key challenges facing haptic designers and developers identified through a series of interdisciplinary collaborative workshops with participants from computer science, design, engineering, HCI and social science from both within industry and academia, and the research literature on haptics. The features and purpose of the manifesto form are described, along with our rationale for its use, and the method of the manifesto development. The starting points, opportunities and challenges, dominant themes and tensions that shaped the manifesto statements are then elaborated on. The paper shows the potential of the manifesto form to bridge between HCI, computer science and engineers, and social scientists on the topic of social touch.</jats:p>
SP  - NA
EP  - NA
JF  - Frontiers in Computer Science
VL  - 3
IS  - NA
PB  - 
DO  - 10.3389/fcomp.2021.754050
ER  - 

TY  - NA
AU  - Ipsita, Ananya; Li, Hao; Duan, Runlin; Cao, Yuanzhi; Chidambaram, Subramanian; Liu, Min; Ramani, Karthik
TI  - CHI Extended Abstracts - VRFromX: From Scanned Reality to Interactive Virtual Experience with Human-in-the-Loop
PY  - 2021
AB  - There is an increasing trend of Virtual-Reality (VR) applications found in education, entertainment, and industry. Many of them utilize real world tools, environments, and interactions as bases for creation. However, creating such applications is tedious, fragmented, and involves expertise in authoring VR using programming and 3D-modelling softwares. This hinders VR adoption by decoupling subject matter experts from the actual process of authoring while increasing cost and time. We present VRFromX, an in-situ Do-It-Yourself (DIY) platform for content creation in VR that allows users to create interactive virtual experiences. Using our system, users can select region(s) of interest (ROI) in scanned point cloud or sketch in mid-air using a brush tool to retrieve virtual models and then attach behavioral properties to them. We ran an exploratory study to evaluate usability of VRFromX and the results demonstrate feasibility of the framework as an authoring tool. Finally, we implemented three possible use-cases to showcase potential applications.
SP  - NA
EP  - NA
JF  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411763.3451747
ER  - 

TY  - JOUR
AU  - Fan, Neil Xu; Xiao, Robert
TI  - Reducing the Latency of Touch Tracking on Ad-hoc Surfaces
PY  - 2022
AB  - <jats:p>Touch sensing on ad-hoc surfaces has the potential to transform everyday surfaces in the environment - desks, tables and walls - into tactile, touch-interactive surfaces, creating large, comfortable interactive spaces without the cost of large touch sensors. Depth sensors are a promising way to provide touch sensing on arbitrary surfaces, but past systems have suffered from high latency and poor touch detection accuracy. We apply a novel state machine-based approach to analyzing touch events, combined with a machine-learning approach to predictively classify touch events from depth data with lower latency and higher touch accuracy than previous approaches. Our system can reduce end-to-end touch latency to under 70ms, comparable to conventional capacitive touchscreens. Additionally, we open-source our dataset of over 30,000 touch events recorded in depth, infrared and RGB for the benefit of future researchers.</jats:p>
SP  - 489
EP  - 499
JF  - Proceedings of the ACM on Human-Computer Interaction
VL  - 6
IS  - ISS
PB  - 
DO  - 10.1145/3567730
ER  - 

TY  - NA
AU  - Akin, Alper Tunga; Cömert, Çetin
TI  - Testing of a Deep Learning Model Providing Monocular Depth Estimation on Mobile Devices via Web Service
PY  - 2021
AB  - Augmented reality applications running on smartphones or tablets are becoming increasingly common. It is crucial to extract the physical structure of the scene perceived by the device camera in these applications. In such applications, employed in education, navigation and obstacle notification, the distance information between the device camera and the object must be derived and processed with sufficient accuracy and speed. In this study, the deep learning model, named "From Big To Small (BTS)", with superior performance metrics in depth extraction according to the literature reviews, was transformed into a web service and tested on an Android phone. Thus, a deep learning model with a high computational cost will be available on an Android device with average processing power. Test results were examined, and improvements were discussed.
SP  - NA
EP  - NA
JF  - 2021 5th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismsit52890.2021.9604645
ER  - 

TY  - JOUR
AU  - Paredes, Luis; Reddy, Sai Swarup; Chidambaram, Subramanian; Vagholkar, Devashri; Zhang, Yunbo; Benes, Bedrich; Ramani, Karthik
TI  - FabHandWear: An End-to-End Pipeline from Design to Fabrication of Customized Functional Hand Wearables
PY  - 2021
AB  - Current hand wearables have limited customizability, they are loose-fit to an individual's hand and lack comfort. The main barrier in customizing hand wearables is the geometric complexity and size variation in hands. Moreover, there are different functions that the users can be looking for; some may only want to detect hand's motion or orientation; others may be interested in tracking their vital signs. Current wearables usually fit multiple functions and are designed for a universal user with none or limited customization. There are no specialized tools that facilitate the creation of customized hand wearables for varying hand sizes and provide different functionalities. We envision an emerging generation of customizable hand wearables that supports hand differences and promotes hand exploration with additional functionality. We introduce FabHandWear, a novel system that allows end-to-end design and fabrication of customized functional self-contained hand wearables. FabHandWear is designed to work with off-the-shelf electronics, with the ability to connect them automatically and generate a printable pattern for fabrication. We validate our system by using illustrative applications, a durability test, and an empirical user evaluation. Overall, FabHandWear offers the freedom to create customized, functional, and manufacturable hand wearables.
SP  - 1
EP  - 22
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 2
PB  - 
DO  - 10.1145/3463518
ER  - 

TY  - CHAP
AU  - Bousba, Fadia Nouna; Elouali, Nadia; Benslimane, Sidi Mohammed
TI  - Smartphone-Based Input Multimodal Interactions for IoT Environments
PY  - 2022
AB  - NA
SP  - 491
EP  - 497
JF  - Communications in Computer and Information Science
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-19682-9_62
ER  - 

TY  - NA
AU  - Guo, Shunan; Jin, Zhuochen; Sun, Fuling; Li, Jingwen; Li, Zhaorui; Shi, Yang; Cao, Nan
TI  - CHI - Vinci: An Intelligent Graphic Design System for Generating Advertising Posters
PY  - 2021
AB  - Advertising posters are a commonly used form of information presentation to promote a product. Producing advertising posters often takes much time and effort of designers when confronted with abundant choices of design elements and layouts. This paper presents Vinci, an intelligent system that supports the automatic generation of advertising posters. Given the user-specified product image and taglines, Vinci uses a deep generative model to match the product image with a set of design elements and layouts for generating an aesthetic poster. The system also integrates online editing-feedback that supports users in editing the posters and updating the generated results with their design preference. Through a series of user studies and a Turing test, we found that Vinci can generate posters as good as human designers and that the online editing-feedback improves the efficiency in poster modification.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445117
ER  - 

TY  - NA
AU  - Tsukuda, Yuga; Tagami, Daichi; Sadasue, Masaaki; Suzuki, Shieru; Lu, Jun-Li; Ochiai, Yoichi
TI  - Calmbots: Exploring Possibilities of Multiple Insects with On-hand Devices and Flexible Controls as Creation Interfaces
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3516387
ER  - 

TY  - NA
AU  - He, Zhenyi; Wang, Keru; Feng, Brandon Yushan; Du, Ruofei; Perlin, Ken
TI  - UIST - GazeChat: Enhancing Virtual Conferences with Gaze-aware 3D Photos
PY  - 2021
AB  - Communication software such as Clubhouse and Zoom has evolved to be an integral part of many people’s daily lives. However, due to network bandwidth constraints and concerns about privacy, cameras in video conferencing are often turned off by participants. This leads to a situation in which people can only see each others’ profile images, which is essentially an audio-only experience. Even when switched on, video feeds do not provide accurate cues as to who is talking to whom. This paper introduces GazeChat, a remote communication system that visually represents users as gaze-aware 3D profile photos. This satisfies users’ privacy needs while keeping online conversations engaging and efficient. GazeChat uses a single webcam to track whom any participant is looking at, then uses neural rendering to animate all participants’ profile images so that participants appear to be looking at each other. We have conducted a remote user study (N=16) to evaluate GazeChat in three conditions: audio conferencing with profile photos, GazeChat, and video conferencing. Based on the results of our user study, we conclude that GazeChat maintains the feeling of presence while preserving more privacy and requiring lower bandwidth than video conferencing, provides a greater level of engagement than to audio conferencing, and helps people to better understand the structure of their conversation.
SP  - 769
EP  - 782
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474785
ER  - 

TY  - NA
AU  - Thoravi Kumaravel, Balasaravanan; Wilson, Andrew D
TI  - DreamStream: Immersive and Interactive Spectating in VR
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517508
ER  - 

TY  - NA
AU  - Schoen, Andrew; White, Nathan; Henrichs, Curt; Siebert-Evenstone, Amanda; Shaffer, David; Mutlu, Bilge
TI  - CoFrame: A System for Training Novice Cabot Programmers
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/hri53351.2022.9889345
ER  - 

TY  - NA
AU  - Vatavu, Radu-Daniel
TI  - Sensorimotor Realities: Formalizing Ability-Mediating Design for Computer-Mediated Reality Environments
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar55827.2022.00086
ER  - 

TY  - JOUR
AU  - Chen, Taizhou; Li, Tianpei; Yang, Xingyu; Zhu, Kening
TI  - EFRing
PY  - 2022
AB  - <jats:p>We present EFRing, an index-finger-worn ring-form device for detecting thumb-to-index-finger (T2I) microgestures through the approach of electric-field (EF) sensing. Based on the signal change induced by the T2I motions, we proposed two machine-learning-based data-processing pipelines: one for recognizing/classifying discrete T2I microgestures, and the other for tracking continuous 1D T2I movements. Our experiments on the EFRing microgesture classification showed an average within-user accuracy of 89.5% and an average cross-user accuracy of 85.2%, for 9 discrete T2I microgestures. For the continuous tracking of 1D T2I movements, our method can achieve the mean-square error of 3.5% for the generic model and 2.3% for the personalized model. Our 1D-Fitts'-Law target-selection study shows that the proposed tracking method with EFRing is intuitive and accurate for real-time usage. Lastly, we proposed and discussed the potential applications for EFRing.</jats:p>
SP  - 1
EP  - 31
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 4
PB  - 
DO  - 10.1145/3569478
ER  - 

TY  - JOUR
AU  - Han, Sangyoon; Lee, Jiwan; Yun, Gyeore; Han, Sung H; Choi, Seungmoon
TI  - Motion Effects: Perceptual Space and Synthesis for Specific Perceptual Properties.
PY  - 2022
AB  - A motion effect, the vestibular stimulus generated by a moving chair, is crucial in improving user experiences in many virtual reality (VR) and entertainment applications. However, the perceptual characteristics of motion effects remain unexplored to a great extent. This paper constructs a perceptual space that accounts for many motion effects based on their perceptual distances and then demonstrates smooth-rough and irregular-regular as its two primary perceptual dimensions. An authoring space is constructed with these two pairs as the axes. We also present methods for synthesizing new motion effects with a specific property in the authoring space. The contributions of this work are with new insights into the perceptual characteristics of motion effects and the first design methods of motion effects achieving desired perceptual properties.
SP  - 626
EP  - 637
JF  - IEEE transactions on haptics
VL  - 15
IS  - 3
PB  - 
DO  - 10.1109/toh.2022.3196950
ER  - 

TY  - NA
AU  - Wu, Yi; Kakaraparthi, Vimal; Li, Zhuohang; Pham, Tien; Liu, Jian; Nguyen, Phuc
TI  - BioFace-3D: continuous 3d facial reconstruction through lightweight single-ear biosensors
PY  - 2021
AB  - Over the last decade, facial landmark tracking and 3D reconstruction have gained considerable attention due to their numerous applications such as human-computer interactions, facial expression analysis, and emotion recognition, etc. Traditional approaches require users to be confined to a particular location and face a camera under constrained recording conditions (e.g., without occlusions and under good lighting conditions). This highly restricted setting prevents them from being deployed in many application scenarios involving human motions. In this paper, we propose the first single-earpiece lightweight biosensing system, BioFace-3D, that can unobtrusively, continuously, and reliably sense the entire facial movements, track 2D facial landmarks, and further render 3D facial animations. Our single-earpiece biosensing system takes advantage of the cross-modal transfer learning model to transfer the knowledge embodied in a high-grade visual facial landmark detection model to the low-grade biosignal domain. After training, our BioFace-3D can directly perform continuous 3D facial reconstruction from the biosignals, without any visual input. Without requiring a camera positioned in front of the user, this paradigm shift from visual sensing to biosensing would introduce new opportunities in many emerging mobile and IoT applications. Extensive experiments involving 16 participants under various settings demonstrate that BioFace-3D can accurately track 53 major facial landmarks with only 1.85 mm average error and 3.38% normalized mean error, which is comparable with most state-of-the-art camera-based solutions. The rendered 3D facial animations, which are in consistency with the real human facial movements, also validate the system's capability in continuous 3D facial reconstruction.
SP  - NA
EP  - NA
JF  - Proceedings of the 27th Annual International Conference on Mobile Computing and Networking
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3447993.3483252
ER  - 

TY  - NA
AU  - Zhao, Chunqi; Shen, I-Chao; Fukusato, Tsukasa; Kato, Jun; Igarashi, Takeo
TI  - ODEN: Live Programming for Neural Network Architecture Editing
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 27th International Conference on Intelligent User Interfaces
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490099.3511120
ER  - 

TY  - JOUR
AU  - Seong, Young ah
TI  - Design Research of Wearable Soft Avatar Robot for Interactive Social Presence
PY  - 2022
AB  - <jats:p>With the increase in online interaction between distant people, wearable avatar robots are expected to be used in a wide range of daily situations. Soft robotics is highly applicable as a method to achieve this. In this study, we define the design requirements for the daily use of wearable soft avatar robots based on design surveys and cross-field academic research. In addition, we implement prototypes using an inflatable robot and summarize the future issues.</jats:p>
SP  - 325
EP  - 327
JF  - Journal of Robotics and Mechatronics
VL  - 34
IS  - 2
PB  - 
DO  - 10.20965/jrm.2022.p0325
ER  - 

TY  - JOUR
AU  - Li, Tiemeng; Jin, Yanning; Wu, Songqian; Liu, Shiran
TI  - Multivariate Fence: Using Parallel Coordinates to Locate and Compare Attributes of Adjacency Matrix Nodes in Immersive Environment
PY  - 2022
AB  - <jats:p>Adjacency matrix visualization is a common method for presenting graph data, and the Focus+Context technique can be used to explore the details of the ROI (region of interest). Embedded views and multi-view approaches are usually applied when locating and comparing attributes among multiple nodes. However, the embedded view has an issue of edge occlusion, while the multi-view would cause repeated perspective switching. In this paper, we propose a Multivariate Fence (MVF) model as a focus view of the adjacency matrix to locate and compare attributes among nodes. An additional spatial parallel coordinate is added to the 2D adjacency matrix in an immersive environment so that the attribute information can be shown in a single view without blocking edge information. We also conduct a user study to evaluate the performance of the MVF. The results show that the MVF has better efficiency and accuracy in locating and comparing the multivariate adjacency matrix in the immersive environment against the existing focus model. Moreover, the MVF model is easier to understand and is preferred by users.</jats:p>
SP  - 12182
EP  - 12182
JF  - Applied Sciences
VL  - 12
IS  - 23
PB  - 
DO  - 10.3390/app122312182
ER  - 

TY  - NA
AU  - Tran, Thanh-Hai; Tran, Hoang-Nhat; Nguyen, Hong-Quan; Le, Trung-Hieu; Nguyen, Van-Thang; Tran, Trung-Kien; Pham, Cuong; Le, Thi-Lan; Vu, Hai; Nguyen, Thanh Phuong; Thanh, Nguyen Huu
TI  - A pilot study on hand posture recognition from wrist-worn camera for human machine interaction
PY  - 2021
AB  - Hand gestures have been shown to be an efficient way for human-machine interaction. Existing approaches usually utilize ambient or head/chest-mounted cameras to capture hand images. This paper presents a new way to capture hand gestures using the wrist-worn camera. The wrist-worn device is designed as a watch with an integrated camera that is much easier and comfortable to wear in daily life context. We then collect a dataset of ten hand postures using the designed prototype by ten subjects. In addition, we deploy state-of-the-art lite CNN models (YOLO family, Single Shot Detector-SSD) as posture detectors and classifiers. Experimental results show that with limited camera angles, the postures are highly distinctive and easily discriminated with the highest performance of 98.85% and 97.40% in terms of precision and recall, which motivates a wide range of applications and new research directions for human-machine interaction, wearables, the Internet of Things (IoT) and so on.
SP  - NA
EP  - NA
JF  - 2021 International Conference on Advanced Technologies for Communications (ATC)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/atc52653.2021.9598223
ER  - 

TY  - NA
AU  - van Oosterhout, Anke; Hoggan, Eve; Bruns, Miguel
TI  - Adjustable Graphical Notation and Accessible Hardware to Accommodate the Force Feedback Design Process
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Adjunct Proceedings of the 2022 Nordic Human-Computer Interaction Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3547522.3547683
ER  - 

TY  - JOUR
AU  - Verma, Dhruv; Bhalla, Sejal; Sahnan, Dhruv; Shukla, Jainendra; Parnami, Aman
TI  - ExpressEar: Sensing Fine-Grained Facial Expressions with Earables
PY  - 2021
AB  - Continuous and unobtrusive monitoring of facial expressions holds tremendous potential to enable compelling applications in a multitude of domains ranging from healthcare and education to interactive systems. Traditional, vision-based facial expression recognition (FER) methods, however, are vulnerable to external factors like occlusion and lighting, while also raising privacy concerns coupled with the impractical requirement of positioning the camera in front of the user at all times. To bridge this gap, we propose ExpressEar, a novel FER system that repurposes commercial earables augmented with inertial sensors to capture fine-grained facial muscle movements. Following the Facial Action Coding System (FACS), which encodes every possible expression in terms of constituent facial movements called Action Units (AUs), ExpressEar identifies facial expressions at the atomic level. We conducted a user study (N=12) to evaluate the performance of our approach and found that ExpressEar can detect and distinguish between 32 Facial AUs (including 2 variants of asymmetric AUs), with an average accuracy of 89.9% for any given user. We further quantify the performance across different mobile scenarios in presence of additional face-related activities. Our results demonstrate ExpressEar's applicability in the real world and open up research opportunities to advance its practical adoption.
SP  - 1
EP  - 28
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 3
PB  - 
DO  - 10.1145/3478085
ER  - 

TY  - JOUR
AU  - Messerschmidt, Moritz Alexander; Muthukumarana, Sachith; Hamdan, Nur Al-Huda; Wagner, Adrian; Zhang, Haimo; Borchers, Jan; Nanayakkara, Suranga Chandima
TI  - ANISMA: A Prototyping Toolkit to Explore Haptic Skin Deformation Applications Using Shape-Memory Alloys
PY  - 2022
AB  - <jats:p>We present ANISMA, a software and hardware toolkit to prototype on-skin haptic devices that generate skin deformation stimuli like pressure, stretch, and motion using shape-memory alloys (SMAs). Our toolkit embeds expert knowledge that makes SMA spring actuators more accessible to human–computer interaction (HCI) researchers. Using our software tool, users can design different actuator layouts, program their spatio-temporal actuation and preview the resulting deformation behavior to verify a design at an early stage. Our toolkit allows exporting the actuator layout and 3D printing it directly on skin adhesive. To test different actuation sequences on the skin, a user can connect the SMA actuators to our customized driver board and reprogram them using our visual programming interface. We report a technical analysis, verify the perceptibility of essential ANISMA skin deformation devices with 8 participants, and evaluate ANISMA regarding its usability and supported creativity with 12 HCI researchers in a creative design task.</jats:p>
SP  - 1
EP  - 34
JF  - ACM Transactions on Computer-Human Interaction
VL  - 29
IS  - 3
PB  - 
DO  - 10.1145/3490497
ER  - 

TY  - NA
AU  - Wang, Jian; Liu, Lingjie; Xu, Weipeng; Sarkar, Kripasindhu; Luvizon, Diogo; Theobalt, Christian
TI  - Estimating Egocentric 3D Human Pose in the Wild with External Weak Supervision
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/cvpr52688.2022.01281
ER  - 

TY  - NA
AU  - Lyu, Haohua; Vachha, Cyrus; Chen, Qianyi; Pyrinis, Odysseus; Liou, Avery; Thoravi Kumaravel, Balasaravanan; Hartmann, Bjoern
TI  - WebTransceiVR
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519816
ER  - 

TY  - NA
AU  - Lin, Richard; Ramesh, Rohit; Dutta, Prabal; Hartmann, Bjoern; Mehta, Ankur
TI  - Hierarchical Computational Design of Board-Level Electronics
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Symposium on Computational Fabrication
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3559400.3565588
ER  - 

TY  - JOUR
AU  - Kitagawa, Shingo; Hasegawa, Shun; Yamaguchi, Naoya; Okada, Kei; Inaba, Masayuki
TI  - Miniature Tangible Cube: Concept and Design of Target-Object-Oriented User Interface for Dual-Arm Telemanipulation
PY  - 2021
AB  - In recent years, there has been a great deal of research on teleoperation of robots, and many end-effector-oriented control systems have been proposed, but these systems have difficulties in performing manipulation tasks with physical contacts between the target object, the robot, and the environment, such as dual-arm manipulation, because these systems can only express the end-effectors’ pose and force commands. In this study, we propose Target-object-oriented User Interface (TOOUI) that focuses on the target object rather than the end effectors of the robot, and develop a tangible device called Miniature Tangible Cube as a TOOUI. Through this device, the pilot can express the target orientation and contact state of the target object, and the robot can be teleoperated to do dual-arm manipulation tasks with geometric and physical constraints. For dual-arm manipulation tasks, we also implement a dual-arm telemanipulation system with the Miniature Tangible Cube using the motion planner based on state machine. In the experiments, we evaluated our system with the Miniature Tangible Cube by conducting dual-arm manipulation tasks with the dual-arm robot PR2 in the real world.
SP  - 6977
EP  - 6984
JF  - IEEE Robotics and Automation Letters
VL  - 6
IS  - 4
PB  - 
DO  - 10.1109/lra.2021.3096475
ER  - 

TY  - JOUR
AU  - Wang, Baoqing; Adachi, Noboru; Fujishiro, Issei
TI  - FORSETI: A visual analysis environment enabling provenance awareness for the accountability of e-autopsy reports
PY  - 2022
AB  - Autopsy reports play a pivotal role in forensic science. Medical examiners (MEs) and diagnostic radiologists (DRs) cross-reference autopsy results in the form of autopsy reports, while judicial personnel derive legal documents from final autopsy reports. In our prior study, we presented a visual analysis system called the forensic autopsy system for e-court instruments (FORSETI) with an extended legal medicine markup language (x-LMML) that enables MEs and DRs to author and review e-autopsy reports. In this paper, we present our extended work to incorporate provenance infrastructure with authority management into FORSETI for forensic data accountability, which contains two features. The first is a novel provenance management mechanism that combines the forensic autopsy workflow management system (FAWfMS) and a version control system called lmmlgit for x-LMML files. This management mechanism allows much provenance data on e-autopsy reports and their documented autopsy processes to be individually parsed. The second is provenance-supported immersive analytics, which is intended to ensure that the DRs’ and MEs’ autopsy provenances can be viewed, listed, and analyzed so that a principal ME can author their own report through accountable autopsy referencing in an augmented reality setting. A fictitious case with a synthetic wounded body is used to demonstrate the effectiveness of the provenance-aware FORSETI system in terms of data accountability through the experience of experts in legal medicine. • A novel provenance management mechanism combining workflow- and script-based systems. • Provenance-supported immersive analytics achieving accountable autopsy referencing. • A fictitious case demonstrating the usefulness of the provenance-aware FORSETI system.
SP  - 69
EP  - 80
JF  - Visual Informatics
VL  - 6
IS  - 3
PB  - 
DO  - 10.1016/j.visinf.2022.05.005
ER  - 

TY  - NA
AU  - Yu, Jin; Sakhardande, Prabodh; Parmar, Ruchita; Oh, HyunJoo
TI  - Strawctures: A Modular Electronic Construction Kit for Human-Scale Interactive Structures
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490149.3501322
ER  - 

TY  - NA
AU  - Kari, Mohamed; Grosse-Puppendahl, Tobias; Coelho, Luis Falconeri; Fender, Andreas; Bethge, David; Schütte, Reinhard; Holz, Christian
TI  - ISMAR - TransforMR: Pose-Aware Object Substitution for Composing Alternate Mixed Realities
PY  - 2021
AB  - Despite the advances in machine perception, semantic scene understanding is still a limiting factor in mixed reality scene composition. In this paper, we present TransforMR, a video see-through mixed reality system for mobile devices that performs 3D-pose-aware object substitution to create meaningful mixed reality scenes. In real-time and for previously unseen and unprepared real-world environments, TransforMR composes mixed reality scenes so that virtual objects assume behavioral and environment-contextual properties of replaced real-world objects. This yields meaningful, coherent, and humaninterpretable scenes, not yet demonstrated by today’s augmentation techniques. TransforMR creates these experiences through our novel pose-aware object substitution method building on different 3D object pose estimators, instance segmentation, video inpainting, and pose-aware object rendering. TransforMR is designed for use in the real-world, supporting the substitution of humans and vehicles in everyday scenes, and runs on mobile devices using just their monocular RGB camera feed as input. We evaluated TransforMR with eight participants in an uncontrolled city environment employing different transformation themes. Applications of TransforMR include real-time character animation analogous to motion capturing in professional film making, however without the need for preparation of either the scene or the actor, as well as narrative-driven experiences that allow users to explore fictional parallel universes in mixed reality. We make all of our source code and assets available1.1TransforMR code release: https://github.com/MohamedKari/transformr
SP  - 69
EP  - 79
JF  - 2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar52148.2021.00021
ER  - 

TY  - JOUR
AU  - Agozie, Divine Q.; Nat, Muesser
TI  - Do communication content functions drive engagement among interest group audiences? An analysis of organizational communication on Twitter
PY  - 2022
AB  - <jats:title>Abstract</jats:title><jats:p>The value experience perceived by users and the extent of interactivity on social media show how engaging audiences are. Few studies have looked at what drives this value experience in organizational communication. This study explores the functional use of communications by interest group organizations (IGOs) and discerns their effect on user engagement with and without multimedia inclusion on Twitter. A bi-term topic modeling technique is used to analyze posts from 121 organizations, and a generalized linear regression model to assess the link between the content functions and user engagement. The results show that the information and communication content functions include event updates and people recognition. Further, <jats:italic>report</jats:italic>, <jats:italic>event, period</jats:italic>, and <jats:italic>people</jats:italic> communication functions drive a higher engagement with multimedia inclusion, while <jats:italic>unite, sign</jats:italic>, and <jats:italic>glean</jats:italic> communication functions are more likely to increase engagement without multimedia elements. This study bridges the gap in the service literature as it pertains to non-profit organizations (i.e., interest group organizations) by exploring organizational communication using communications content functions of Twitter posts. This study is the only one to investigate content functions beyond the categorizations of message functions and the relationship between content functions and user engagement.</jats:p>
SP  - NA
EP  - NA
JF  - Humanities and Social Sciences Communications
VL  - 9
IS  - 1
PB  - 
DO  - 10.1057/s41599-022-01275-5
ER  - 

TY  - NA
AU  - Song, Xingzhe; Huang, Kai; Gao, Wei
TI  - FaceListener: Recognizing Human Facial Expressions via Acoustic Sensing on Commodity Headphones
PY  - 2022
AB  - Facial expressions are important indicators of user needs that can be used in many interactive computing applications to adapt the system behaviors and settings. Current computing approaches to recognizing human facial expressions, however, either rely on con-tinuous camera recordings that are energy consuming, or require custom sensing hardware that are expensive and difficult to use on commodity systems. In this paper, we present FaceListener, a new sensing system that recognizes human facial expressions by only using commodity headphones. The basic idea of FaceListener is to transform the commodity headphone into an acoustic sensing device, which captures the face skin deformations caused by fa-cial muscle movements with different facial expressions. To ensure the recognition accuracy, FaceListener leverages the knowledge distillation technique to learn the subtle correlation between face skin deformation and the acoustic signal changes. Experiment re-sults over multiple human beings demonstrate that FaceListener can accurately recognize more than 80&#x0025; of different facial expressions. FaceListener is highly energy efficient, and can well adapt to different headphone models, host systems and user activities.
SP  - NA
EP  - NA
JF  - 2022 21st ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ipsn54338.2022.00019
ER  - 

TY  - JOUR
AU  - Ikeda, Masahiro; Niiyama, Ryuma; Kuniyoshi, Yasuo
TI  - Proposal of Manufacturing Method for New Passive Elastic Joint and Prototype of Human Phantom
PY  - 2022
AB  - <jats:p>Fabricating a soft robot using conventional molding methods is difficult and time-consuming. Moreover, the types of materials used in the process are limited, and the elasticity cannot be changed incrementally. In this paper, we explain the detailed process of manufacturing molds for silicone joints. We construct a prototype molded silicone joint. We measure the elastic modulus of this joint and confirm that the elastic modulus and anisotropy change depending on the density, size, and arrangement of the surface grooves in the mold. We also develop a prototype human phantom using the proposed joint. We aim to contribute to the medical field by applying new techniques made possible by soft robotics.</jats:p>
SP  - 402
EP  - 412
JF  - Journal of Robotics and Mechatronics
VL  - 34
IS  - 2
PB  - 
DO  - 10.20965/jrm.2022.p0402
ER  - 

TY  - JOUR
AU  - Peleg, Hila; Gabay, Roi; Itzhaky, Shachar; Yahav, Eran
TI  - Programming with a read-eval-synth loop
PY  - 2020
AB  - A frequent programming pattern for small tasks, especially expressions, is to repeatedly evaluate the program on an input as its editing progresses. The Read-Eval-Print Loop (REPL) interaction model has been a successful model for this programming pattern. We present the new notion of Read-Eval-Synth Loop (RESL) that extends REPL by providing in-place synthesis on parts of the expression marked by the user. RESL eases programming by synthesizing parts of a required solution. The underlying synthesizer relies on a partial solution from the programmer and a few examples. RESL hinges on bottom-up synthesis with general predicates and sketching, generalizing programming by example. To make RESL practical, we present a formal framework that extends observational equivalence to non-example specifications. We evaluate RESL by conducting a controlled within-subjects user-study on 19 programmers from 8 companies, where programmers are asked to solve a small but challenging set of competitive programming problems. We find that programmers using RESL solve these problems with far less need to edit the code themselves and by browsing documentation far less. In addition, they are less likely to leave a task unfinished and more likely to be correct.
SP  - 1
EP  - 30
JF  - Proceedings of the ACM on Programming Languages
VL  - 4
IS  - OOPSLA
PB  - 
DO  - 10.1145/3428227
ER  - 

TY  - NA
AU  - Joshi, Nikhita; Irudayaraj, Antony Albert Raj; Hartmann, Jeremy; Vogel, Daniel
TI  - An Instrumented Office Chair with a Steerable Projector for Personal Spatial Augmented Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 2022 ACM Symposium on Spatial User Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3565970.3567705
ER  - 

TY  - CHAP
AU  - Regal, Georg; Schrom-Feiertag, Helmut; Migliorini, Massimo; Guarneri, Massimiliano; Di Giovanni, Daniele; D'Angelo, Andrea; Murtinger, Markus
TI  - Challenges in Virtual Reality Training for CRBN Events
PY  - 2022
AB  - AbstractThe re-emergence of chemical, biological, radioactive, and nuclear (CBRN) threats as a key area of focus for military (as well as civilian) actors, paired with the early stage of CBRN VR training, create a strong opportunity for future research. Improvement in-game engine technology and Virtual Reality hard and software can improve CBRN training and simulation for military and civilian responders to CBRN events. Therefore, in this work, we discussed the challenges of developing a European virtual reality-based CBRN training. By standardizing CBRN training on a European Level interoperability between different actors (military and civilian) and European nationalities shall be increased. We presented the main cornerstones for a VR CBRN training that shall be tackled in the VERTIgO project: (1) the Exercise Simulation Platform (2) Scenario Creator, and (3) a CBRN VR Mask.KeywordsCBRNVirtual RealityVirtual environmentTraining
SP  - 79
EP  - 88
JF  - Extended Reality
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-15553-6_6
ER  - 

TY  - NA
AU  - Cambre, Julia; Williams, Alex C.; Razi, Afsaneh; Bicking, Ian; Wallin, Abraham; Tsai, Janice; Kulkarni, Chinmay; Kaye, Jofish
TI  - CHI - Firefox Voice: An Open and Extensible Voice Assistant Built Upon the Web
PY  - 2021
AB  - Voice assistants are fundamentally changing the way we access information. However, voice assistants still leverage little about the web beyond simple search results. We introduce Firefox Voice, a novel voice assistant built on the open web ecosystem with an aim to expand access to information available via voice. Firefox Voice is a browser extension that enables users to use their voice to perform actions such as setting timers, navigating the web, and reading a webpage’s content aloud. Through an iterative development process and use by over 12,000 active users, we find that users see voice as a way to accomplish certain browsing tasks efficiently, but struggle with discovering functionality and frequently discontinue use. We conclude by describing how Firefox Voice enables the development of novel, open web-powered voice-driven experiences.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445409
ER  - 

TY  - JOUR
AU  - Ferdowsifard, Kasra; Barke, Shraddha; Peleg, Hila; Lerner, Sorin; Polikarpova, Nadia
TI  - LooPy: interactive program synthesis with control structures
PY  - 2021
AB  - One vision for program synthesis, and specifically for programming by example (PBE), is an interactive programmer's assistant, integrated into the development environment. To make program synthesis practical for interactive use, prior work on Small-Step Live PBE has proposed to limit the scope of synthesis to small code snippets, and enable the users to provide local specifications for those snippets. This paradigm, however, does not work well in the presence of loops. We present LooPy, a synthesizer integrated into a live programming environment, which extends Small-Step Live PBE to work inside loops and scales it up to synthesize larger code snippets, while remaining fast enough for interactive use. To allow users to effectively provide examples at various loop iterations, even when the loop body is incomplete, LooPy makes use of live execution, a technique that leverages the programmer as an oracle to step over incomplete parts of the loop. To enable synthesis of loop bodies at interactive speeds, LooPy introduces Intermediate State Graph, a new data structure, which compactly represents a large space of code snippets composed of multiple assignment statements and conditionals. We evaluate LooPy empirically using benchmarks from competitive programming and previous synthesizers, and show that it can solve a wide variety of synthesis tasks at interactive speeds. We also perform a small qualitative user study which shows that LooPy's block-level specifications are easy for programmers to provide.
SP  - 1
EP  - 29
JF  - Proceedings of the ACM on Programming Languages
VL  - 5
IS  - OOPSLA
PB  - 
DO  - 10.1145/3485530
ER  - 

TY  - NA
AU  - Degraen, Donald; Fruchard, Bruno; Smolders, Frederik; Potetsianakis, Emmanouil; Güngör, Seref; Krüger, Antonio; Steimle, Jürgen
TI  - UIST - Weirding Haptics: In-Situ Prototyping of Vibrotactile Feedback in Virtual Reality through Vocalization
PY  - 2021
AB  - Effective haptic feedback in virtual reality (VR) is an essential element for creating convincing immersive experiences. To design such feedback, state-of-the-art VR setups provide APIs for programmatically generating controller vibration patterns. While tools for designing vibrotactile feedback keep evolving, they often require expert knowledge and rarely support direct manipulation methods for mapping feedback to user interactions within the VR environment. To address these challenges, we contribute a novel concept called Weirding Haptics, that supports fast-prototyping by leveraging the user’s voice to design such feedback while manipulating virtual objects in-situ. Through a pilot study (N = 9) focusing on how tactile experiences are vocalized during object manipulation, we identify spatio-temporal mappings and supporting features needed to produce intended vocalizations. To study our concept, we built a VR design tool informed by the results of the pilot study. This tool enables users to design tactile experiences using their voice while manipulating objects, provides a set of modifiers for fine-tuning the created experiences in VR, and allows to rapidly compare various experiences by feeling them. Results from a validation study (N = 8) show that novice hapticians can vocalize experiences and refine their designs with the fine-tuning modifiers to match their intentions. We conclude our work by discussing uncovered design implications for direct manipulation and vocalization of vibrotactile feedback in immersive virtual environments.
SP  - 936
EP  - 953
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474797
ER  - 

TY  - JOUR
AU  - Ahn, Jiseon; Kim, Sungmin
TI  - Automated Textile Circuit Generation using Machine Vision and Embroidery Technique
PY  - 2022
AB  - <jats:p> An automated textile circuit generation method was developed using machine vision and embroidery technique. For this, an image acquisition device was designed to capture the physical layout image of electronic devices on the fabric. A series of image analysis algorithms were developed to calibrate the image and recognize the type, location, and orientation of each device from the image. Dedicated computer-aided design software was developed that can design a circuit and modify it according to the actual device layout on the fabric. It can also convert the circuit elements such as conductive path and insulation layer into data for a computerized embroidery machine. An example circuit consisting of seven electronic devices was designed and repeatedly produced to verify the developed method. The method has shown promising results. </jats:p>
SP  - 1977
EP  - 1986
JF  - Textile Research Journal
VL  - 92
IS  - 11-12
PB  - 
DO  - 10.1177/00405175221075062
ER  - 

TY  - JOUR
AU  - Zhang, Yahui; You, Shaodi; Karaoglu, Sezer; Gevers, Theo
TI  - Multi-person 3D pose estimation from a single image captured by a fisheye camera
PY  - 2022
AB  - Multi-person 3D pose estimation with absolute depths for a fisheye camera is a challenging task but with valuable applications in daily life, especially for video surveillance. However, to the best of our knowledge, such problem has not been explored so far, leaving a gap in practical applications. In this work, we first propose a method for multi-person 3D pose estimation from a single image taken by a fisheye camera. Our method consists of two branches to estimate absolute 3D human poses: (1) a 2D-to-3D lifting module to predict root-relative 3D human poses (HPoseNet); (2) a root regression module to estimate absolute root locations in the camera coordinate (HRootNet). Finally, we propose a fisheye re-projection module without using ground-truth camera parameters to connect two branches, alleviating the impact of image distortions on 3D pose estimation and further regularizing prediction absolute 3D poses. Experimental results demonstrate that our method achieves the state-of-the-art performance on two public multi-person 3D pose datasets with synthetic fisheye images and our newly collected dataset with real fisheye images. The code and new dataset will be made publicly available. • We propose a novel method for multi-person 3D pose estimation from a fisheye image. • A re-projection module is introduced to alleviate the negative impact of distortions. • Absolute 3D poses are obtained by our method without using ground-truth camera parameters. • We collect a new dataset taken by fisheye cameras for multi-person 3D pose estimation.
SP  - 103505
EP  - 103505
JF  - Computer Vision and Image Understanding
VL  - 222
IS  - NA
PB  - 
DO  - 10.1016/j.cviu.2022.103505
ER  - 

TY  - JOUR
AU  - Hodges, Steve; Fraser, Mike
TI  - Citizen Manufacturing: Unlocking a New Era of Digital Innovation
PY  - 2022
AB  - We have all come to expect—if not depend upon—the steady march of technology. All manner of pervasive computing devices, applications, and services increasingly support us at home and work. Thankfully, for those tasked with creating future generations of innovative digital technologies, the design and prototyping process continues to get easier. But for hardware, the transition from device prototype to production presents a bottleneck that is restricting the rate and nature of innovation. Imagine instead a world of citizen manufacturing, where individuals are empowered to turn their ideas not only into working prototypes, but also to evolve them organically and seamlessly into viable products. Such an approach could increase consumer choice, grow local and national economies, and facilitate more socially conscious production. We call on the community to join us in pursuit of this goal! We believe that overcoming the many challenges of transitioning from device prototyping to production will unlock a new era of digital innovation that allows more people to explore and benefit from pervasive computing.
SP  - 42
EP  - 51
JF  - IEEE Pervasive Computing
VL  - 21
IS  - 3
PB  - 
DO  - 10.1109/mprv.2022.3187574
ER  - 

TY  - NA
AU  - Chang, Ruei-Che; Ting, Chao-Hsien; Hung, Chia-Sheng; Lee, Wan-Chen; Chen, Liang-Jin; Chao, Yu-Tzu; Chen, Bing-Yu; Guo, Anhong
TI  - OmniScribe: Authoring Immersive Audio Descriptions for 360° Videos
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545613
ER  - 

TY  - NA
AU  - Qamar, Isabel P. S.; Chen, Sabina W; Tskhovrebadze, Dimitri; Boni, Paolo; Faruqi, Faraz; Wessely, Michael; Mueller, Stefanie
TI  - ChromoPrint: A Multi-Color 3D Printer Based on a Reprogrammable Photochromic Resin
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519784
ER  - 

TY  - NA
AU  - Nazarova, Elena; Sautenkov, Oleg; Altamirano Cabrera, Miguel; Tirado, Jonathan; Serpiva, Valerii; Rakhmatulin, Viktor; Tsetserukou, Dzmitry
TI  - CobotAR: Interaction with Robots using Omnidirectionally Projected Image and DNN-based Gesture Recognition
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - 2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/smc52423.2021.9658827
ER  - 

TY  - NA
AU  - Miyatake, Yamato; Punpongsanon, Parinya; Iwai, Daisuke; Sato, Kosuke
TI  - interiqr: Unobtrusive Edible Tags using Food 3D Printing
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545669
ER  - 

TY  - BOOK
AU  - Piyavichayanon, Chanapol; Koga, Masanobu
TI  - ACIRS - Validation of Robot Model with Mobile Augmented Reality
PY  - 2021
AB  - Augmented Reality has excellent potential for many robotic applications, including the validation of robot models in working environments. However, a dedicated depth sensor is only available on a high-end mobile device. Hence, the realistic AR experience for robotic applications is not available for a wide range of mobile phones. This paper presents a way to use a robot control algorithm on a virtual robot model in AR without the need for a depth sensor while keeping the depth required feature such as an occlusion. The connection between the AR and the robot operating system allows the exiting control algorithm to be applied to the augmented robot model. The navigation of a mobile robot with the AR interface was used as an example of robot validation in real-world spaces. Despite some communication delays, the virtual robot can be controlled and navigated in the real world with a certain degree of accuracy. It has been shown that visualizing and controlling a robot in an AR scene can be done with this method. Future work on the interaction between the virtual robot and the real environment should be conducted to expand the application of robot validation with AR.
SP  - 1
EP  - 5
JF  - 2021 6th Asia-Pacific Conference on Intelligent Robot Systems (ACIRS)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/acirs52449.2021.9519362
ER  - 

TY  - JOUR
AU  - Gindin, Irene Lis; Cingolani, Gastón; Rodriguez-Amat, Joan Ramon
TI  - Autoridades interpretativas: una perspectiva teórica sobre datificación y producción de sentido
PY  - 2021
AB  - Este articulo emerge en el espacio de contacto entre la literatura actual –de corte mayormente anglosajon– sobre datificacion, y la perspectiva de Eliseo Veron como un aporte latinoamericano que abre oportunidades teoricas y empiricas para la discusion critica de los procesos de datificacion. Siguiendo la perspectiva de veroniana, la reflexion sobre los procesos de produccion, circulacion, y reconocimiento de los datos ayuda a desnaturalizar la idea de que el dato es neutral o compacto, para visibilizar, en cambio, las condiciones desde las que esos datos son provistos de sentido en tanto que constructos discursivos social y culturalmente situados. Frente a otras perspectivas anglosajonas que parecen mas populares en la academia –i.e., el modelo Encoding/decoding de Hall–, este articulo propone revisitar la descripcion de la articulacion entre sentido y circulacion por parte de Veron como una alternativa para describir los procesos de interpretacion que consolidan los datos como discursos. Se trata, pues, de un punto de partida para posteriores desarrollos teoricos e investigaciones empiricas,y de una apertura de la perspectiva de Eliseo Veron para contribuir y enriquecer los debates abiertos sobre datificacion y sus formas de discriminacion.
SP  - 1
EP  - 27
JF  - Palabra Clave
VL  - 24
IS  - 3
PB  - 
DO  - 10.5294/pacla.2021.24.3.6
ER  - 

TY  - JOUR
AU  - Teng, Shan-Yuan; Lopes, Pedro
TI  - XR needs "mixed feelings"
PY  - 2022
AB  - <jats:p>Haptic devices allow us to feel virtual worlds through touch and forces; yet they are incompatible with haptics present in our everyday life. This urges us to re-think how to engineer a wave of new haptic devices for extended reality.</jats:p>
SP  - 44
EP  - 47
JF  - XRDS: Crossroads, The ACM Magazine for Students
VL  - 29
IS  - 1
PB  - 
DO  - 10.1145/3558194
ER  - 

TY  - JOUR
AU  - Ku, Pin-Sung; Molla, Md. Tahmidul Islam; Huang, Kunpeng; Kattappurath, Priya; Ranjan, Krithik; Kao, Hsin-Liu Cindy
TI  - SkinKit
PY  - 2021
AB  - <jats:p>The emergence of on-skin interfaces has created an opportunity for seamless, always-available on-body interactions. However, developing a new fabrication process for on-skin interfaces can be time-consuming, challenging to incorporate new features, and not available for quick form-factor preview through prototyping. We introduce SkinKit, the first construction toolkit for on-skin interfaces, which enables fast, low-fidelity prototyping with a slim form factor directly applicable to the skin. SkinKit comprises modules consisting of skin-conformable base substrates and reusable Flexible Printed Circuits Board (FPCB) blocks. They are easy to attach and remove under tangible plug-and-play construction but still offer robust conductive connections in a slim form. Further, SkinKit aims to lower the barrier to entry in building on-skin interfaces without demanding technical expertise. It leverages a variety of preprogrammed modules connected in unique sequences to achieve various function customizations. We describe our iterative design and development process of SkinKit, comparing materials, connection mechanisms, and modules reflecting on its capability. We report results from single- and multi- session workshops with 34 maker participants spanning STEM and design backgrounds. Our findings reveal how diverse maker populations engage in on-skin interface design, what types of applications they choose to build, and what challenges they faced.</jats:p>
SP  - 1
EP  - 23
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 4
PB  - 
DO  - 10.1145/3494989
ER  - 

TY  - JOUR
AU  - Kraus, Matthias; Fuchs, Johannes; Sommer, Björn; Klein, Karsten; Engelke, Ulrich; Keim, Daniel; Schreiber, Falk
TI  - Immersive Analytics with Abstract 3D Visualizations: A Survey
PY  - 2021
AB  - After a long period of scepticism, more and more publications describe basic research but also practical approaches to how abstract data can be presented in immersive environments for effective and efficient data understanding. Central aspects of this important research question in immersive analytics research are concerned with the use of 3D for visualization, the embedding in the immersive space, the combination with spatial data, suitable interaction paradigms and the evaluation of use cases. We provide a characterization that facilitates the comparison and categorization of published works and present a survey of publications that gives an overview of the state of the art, current trends, and gaps and challenges in current research.
SP  - 201
EP  - 229
JF  - Computer Graphics Forum
VL  - 41
IS  - 1
PB  - 
DO  - 10.1111/cgf.14430
ER  - 

TY  - JOUR
AU  - Burova, Alisa; Opas, Viveka; Mäkelä, John; Hakulinen, Jaakko; Lindqvist, Timo; Siltanen, Sanni; Raisamo, Roope; Turunen, Markku
TI  - Enhancing Remote Industrial Training Experiences with Asymmetric Virtual Reality: Experiences, Tools and Guidelines
PY  - 2022
AB  - <jats:p>Training in virtual reality (VR) is a valuable supplementing tool for advancing knowledge transfer that results in increased efficiency and accuracy of technicians in fieldwork. However, COVID-19 pandemic restrictions made it impossible for VR training centers to operate on a full scale, forcing traditional face-to-face learning sessions to become remote. In this article, we investigate the asymmetric use of a VR training solution—among devices with different levels of immersion and control—to enrich the content of remote training sessions. The VR in this case can be seen as a source of visual and other contextual information to advance the effects of situated learning and enhance knowledge transfer. To evaluate this approach, we conducted a remote user study with ten industrial maintenance and installation experts. We also introduce the “Research Panel” tool to gather reactions of learners during the remote training session. The expert user study results demonstrate the usefulness and relevance of asymmetric VR to improve remote training sessions and other application industrial scenarios, while the “Research Panel” data provided detailed insight into the session flow. Building on the qualitative findings, we present design guidelines to aid the adoption of asymmetric VR in the industrial context.</jats:p>
SP  - 7745
EP  - 7745
JF  - Applied Sciences
VL  - 12
IS  - 15
PB  - 
DO  - 10.3390/app12157745
ER  - 

TY  - NA
AU  - Li, Franklin Mingzhe; Spektor, Franchesca; Xia, Meng; Huh, Mina; Cederberg, Peter; Gong, Yuqi; Shinohara, Kristen; Carrington, Patrick
TI  - "It Feels Like Taking a Gamble": Exploring Perceptions, Practices, and Challenges of Using Makeup and Cosmetics for People with Visual Impairments
PY  - 2022
AB  - Makeup and cosmetics offer the potential for self-expression and the reshaping of social roles for visually impaired people. However, there exist barriers to conducting a beauty regime because of the reliance on visual information and color variances in makeup. We present a content analysis of 145 YouTube videos to demonstrate visually impaired individuals' unique practices before, during, and after doing makeup. Based on the makeup practices, we then conducted semi-structured interviews with 12 visually impaired people to discuss their perceptions of and challenges with the makeup process in more depth. Overall, through our findings and discussion, we present novel perceptions of makeup from visually impaired individuals (e.g., broader representations of blindness and beauty). The existing challenges provide opportunities for future research to address learning barriers, insufficient feedback, and physical and environmental barriers, making the experience of doing makeup more accessible to people with visual impairments.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517490
ER  - 

TY  - CHAP
AU  - De Pra, Yuri; Fontana, Federico; Papetti, Stefano
TI  - INTERACT (4) - Endless Knob with Programmable Resistive Force Feedback
PY  - 2021
AB  - Touchscreens today represent the most versatile solution for configuring user interfaces. A toll for this versatility is the intangibility of the displayed virtual controls. The addition of haptic feedback can improve their manipulation by reinforcing or even substituting visual information. While haptic rendering of virtual buttons is advancing, tangible knobs seem yet to come, possibly due to the inherent difficulty to conceptualize rotation as an interaction primitive in absence of a physical control. To address this issue, we propose a hybrid solution consisting in an endless knob with programmable resistance to rotation. Compared to existing related devices, it minimizes costs, encumbrance and power consumption, making its installation also possible on portable equipment. After describing its design and main features, we present a test which assessed how haptic feedback rendered by the knob affects performance in a visual target-matching task: users had to select targets placed on a horizontal slider by dragging its cursor through knob rotation. Results show that haptic augmentation significantly improved target acquisition.
SP  - 580
EP  - 589
JF  - Human-Computer Interaction – INTERACT 2021
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-85610-6_32
ER  - 

TY  - JOUR
AU  - Park, H.; Lee, Youngki; Ko, JeongGil
TI  - Enabling Real-time Sign Language Translation on Mobile Platforms with On-board Depth Cameras
PY  - 2021
AB  - In this work we present SUGO, a depth video-based system for translating sign language to text using a smartphone's front camera. While exploiting depth-only videos offer benefits such as being less privacy-invasive compared to using RGB videos, it introduces new challenges which include dealing with low video resolutions and the sensors' sensitiveness towards user motion. We overcome these challenges by diversifying our sign language video dataset to be robust to various usage scenarios via data augmentation and design a set of schemes to emphasize human gestures from the input images for effective sign detection. The inference engine of SUGO is based on a 3-dimensional convolutional neural network (3DCNN) to classify a sequence of video frames as a pre-trained word. Furthermore, the overall operations are designed to be light-weight so that sign language translation takes place in real-time using only the resources available on a smartphone, with no help from cloud servers nor external sensing components. Specifically, to train and test SUGO, we collect sign language data from 20 individuals for 50 Korean Sign Language words, summing up to a dataset of ~5,000 sign gestures and collect additional in-the-wild data to evaluate the performance of SUGO in real-world usage scenarios with different lighting conditions and daily activities. Comprehensively, our extensive evaluations show that SUGO can properly classify sign words with an accuracy of up to 91% and also suggest that the system is suitable (in terms of resource usage, latency, and environmental robustness) to enable a fully mobile solution for sign language translation.
SP  - 3463498
EP  - 30
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 2
PB  - 
DO  - 10.1145/3463498
ER  - 

TY  - JOUR
AU  - Duggal, Angel Swastik; Singh, Rajesh; Gehlot, Anita; Rashid, Mamoon; Alshamrani, Sultan S.; AlGhamdi, Ahmed Saeed
TI  - Digital Taste in Mulsemedia Augmented Reality: Perspective on Developments and Challenges
PY  - 2022
AB  - <jats:p>Digitalization of human taste has been on the back burners of multi-sensory media until the beginning of the decade, with audio, video, and haptic input/output(I/O) taking over as the major sensory mechanisms. This article reviews the consolidated literature on augmented reality (AR) in the modulation and stimulation of the sensation of taste in humans using low-amplitude electrical signals. Describing multiple factors that combine to produce a single taste, various techniques to stimulate/modulate taste artificially are described. The article explores techniques from prominent research pools with an inclination towards taste modulation. The goal is to seamlessly integrate gustatory augmentation into the commercial market. It highlights core benefits and limitations and proposes feasible extensions to the already established technological architecture for taste stimulation and modulation, namely, from the Internet of Things, artificial intelligence, and machine learning. Past research on taste has had a more software-oriented approach, with a few trends getting exceptions presented as taste modulation hardware. Using modern technological extensions, the medium of taste has the potential to merge with audio and video data streams as a viable multichannel medium for the transfer of sensory information.</jats:p>
SP  - 1315
EP  - 1315
JF  - Electronics
VL  - 11
IS  - 9
PB  - 
DO  - 10.3390/electronics11091315
ER  - 

TY  - NA
AU  - Williams, Candace; de Greef, Lilian; Harris, Ed; Findlater, Leah; Pavel, Amy; Bennett, Cynthia
TI  - Toward supporting quality alt text in computing publications
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 19th International Web for All Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3493612.3520449
ER  - 

TY  - JOUR
AU  - Fletcher, Mark D.; Zgheib, Jana; Perry, Samuel W.
TI  - Sensitivity to Haptic Sound-Localization Cues at Different Body Locations.
PY  - 2021
AB  - Cochlear implants (CIs) recover hearing in severely to profoundly hearing-impaired people by electrically stimulating the cochlea. While they are extremely effective, spatial hearing is typically severely limited. Recent studies have shown that haptic stimulation can supplement the electrical CI signal (electro-haptic stimulation) and substantially improve sound localization. In haptic sound-localization studies, the signal is extracted from the audio received by behind-the-ear devices and delivered to each wrist. Localization is achieved using tactile intensity differences (TIDs) across the wrists, which match sound intensity differences across the ears (a key sound localization cue). The current study established sensitivity to across-limb TIDs at three candidate locations for a wearable haptic device, namely: the lower tricep and the palmar and dorsal wrist. At all locations, TID sensitivity was similar to the sensitivity to across-ear intensity differences for normal-hearing listeners. This suggests that greater haptic sound-localization accuracy than previously shown can be achieved. The dynamic range was also measured and far exceeded that available through electrical CI stimulation for all of the locations, suggesting that haptic stimulation could provide additional sound-intensity information. These results indicate that an effective haptic aid could be deployed for any of the candidate locations, and could offer a low-cost, non-invasive means of improving outcomes for hearing-impaired listeners.
SP  - 3770
EP  - NA
JF  - Sensors (Basel, Switzerland)
VL  - 21
IS  - 11
PB  - 
DO  - 10.3390/s21113770
ER  - 

TY  - NA
AU  - Du, Ruofei; Turner, Eric; Dzitsiuk, Max; Prasso, Luca; Duarte, Ivo; Dourgarian, Jason; Afonso, Joao; Pascoal, Jose; Gladstone, Josh; Cruces, Nuno; Izadi, Shahram; Kowdle, Adarsh; Tsotsos, Konstantine; Kim, David
TI  - UIST (Adjunct Volume) - Experiencing Real-time 3D Interaction with Depth Maps for Mobile Augmented Reality in DepthLab
PY  - 2020
AB  - We demonstrate DepthLab, a playground for interactive augmented reality experiences leveraging the shape and depth of the physical environment on a mobile phone. Based on the ARCore Depth API, DepthLab encapsulates a variety of depth-based UI/UX paradigms, including geometry-aware rendering (occlusion, shadows, texture decals), surface interaction behaviors (physics, collision detection, avatar path planning), and visual effects (relighting, 3D-anchored focus and aperture effects, 3D photos). We have open-sourced our software at https://github.com/googlesamples/arcore-depth-lab to facilitate future research and development in depth-aware mobile AR experiences. With DepthLab, we aim to help mobile developers to effortlessly integrate depth into their AR experiences and amplify the expression of their creative vision.
SP  - 108
EP  - 110
JF  - Adjunct Publication of the 33rd Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3379350.3416136
ER  - 

TY  - NA
AU  - Yan, Zihan; Wu, Yufei; Zhang, Yang; Chen, Xiang 'Anthony'
TI  - EmoGlass: an End-to-End AI-Enabled Wearable Platform for Enhancing Self-Awareness of Emotional Health
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501925
ER  - 

TY  - NA
AU  - Natalie, Rosiana
TI  - Cost-effective and Collaborative Methods to Author Video's Scene Description for Blind People.
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3503814
ER  - 

TY  - NA
AU  - Zhu, Jingwen; Kao, Hsin-Liu (Cindy)
TI  - Scaling E-Textile Production: Understanding the Challenges of Soft Wearable Production for Individual Creators
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Proceedings of the 2022 ACM International Symposium on Wearable Computers
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3544794.3558475
ER  - 

TY  - NA
AU  - Jiang, Hao; Ithapu, Vamsi Krishna
TI  - Egocentric Pose Estimation from Human Vision Span
PY  - 2021
AB  - Estimating camera wearer's body pose from an egocentric view (egopose) is a vital task in augmented and virtual reality. Existing approaches either use a narrow field of view front facing camera that barely captures the wearer, or an extended head-mounted top-down camera for maximal wearer visibility. In this paper, we tackle the egopose estimation from a more natural human vision span, where camera wearer can be seen in the peripheral view and depending on the head pose the wearer may become invisible or has a limited partial view. This is a realistic visual field for user-centric wearable devices like glasses which have front facing wide angle cameras. Existing solutions are not appropriate for this setting, and so, we propose a novel deep learning system taking advantage of both the dynamic features from camera SLAM and the body shape imagery. We compute 3D head pose, 3D body pose, the figure/ground separation, all at the same time while explicitly enforcing a certain geometric consistency across pose attributes. We further show that this system can be trained robustly with lots of existing mocap data so we do not have to collect and annotate large new datasets. Lastly, our system estimates egopose in real time and on the fly while maintaining high accuracy.
SP  - NA
EP  - NA
JF  - 2021 IEEE/CVF International Conference on Computer Vision (ICCV)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/iccv48922.2021.01082
ER  - 

TY  - NA
AU  - Ryu, Neung; Kim, Myung Jin; Bianchi, Andrea
TI  - SIGGRAPH ASIA Emerging Technologies - Demonstration of ElaStick: A Variable Stiffness Display for Rendering Handheld Flexible Object
PY  - 2020
AB  - We present ElaStick, a handheld variable stiffness controller capable of simulating the kinesthetic sensation of deformable and flexible objects when swung or shaken. ElaStick is capable of rendering gradual changes of stiffness along two independent axes over a wide continuous range. Two trackers on the controller enable a closed-loop feedback that allows to accurately map the device’s deformations to the visuals of a Virtual Reality application.
SP  - NA
EP  - NA
JF  - SIGGRAPH Asia 2020 Emerging Technologies
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3415255.3422894
ER  - 

TY  - NA
AU  - Yang, Saelyne; Yim, Jisu; Kim, Juho; Shin, Hijung Valentina
TI  - CatchLive: Real-time Summarization of Live Streams with Stream Content and Interaction Data
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517461
ER  - 

TY  - NA
AU  - Zhou, Qiushi; Irlitti, Andrew; Yu, Difeng; Goncalves, Jorge; Velloso, Eduardo
TI  - Movement Guidance using a Mixed Reality Mirror
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Designing Interactive Systems Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532106.3533466
ER  - 

TY  - NA
AU  - Zhang, Yidan; Ens, Barrett; Satriadi, Kadek Ananta; Prouzeau, Arnaud; Goodwin, Sarah
TI  - TimeTables: Embodied Exploration of Immersive Spatio-Temporal Data
PY  - 2022
AB  - We propose TimeTables, a novel prototype system that aims to support data exploration, using embodiment with space-time cubes in virtual reality. TimeTables uses multiple space-time cubes on virtual tabletops, which users can manipulate by extracting time layers or individual buildings to create new tabletop views. The surrounding environment includes a large space for multiple linked tabletops and a storage wall. TimeTables presents information at different time scales by stretching layers to drill down in time. Users can also jump into tabletops to inspect data from an egocentric perspective. We present a use case scenario of energy consumption displayed on a university campus to demonstrate how our system could support data exploration and analysis over space and time. From our experience and analysis we believe the system has a high potential in assisting spatio-temporal data exploration and analysis.
SP  - NA
EP  - NA
JF  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr51125.2022.00080
ER  - 

TY  - NA
AU  - Shim, Youngbo Aram; Kim, Taejun; Lee, Geehyuk
TI  - QuadStretch: A Forearm-wearable Multi-dimensional Skin Stretch Display for Immersive VR Haptic Feedback
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519908
ER  - 

TY  - NA
AU  - Cools, Robbe; Simeone, Adalberto
TI  - Mobile Displays for Cross-Reality Interactions between Virtual and Physical Realities
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - 20th International Conference on Mobile and Ubiquitous Multimedia
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490632.3497838
ER  - 

TY  - JOUR
AU  - Alhejri, Aisha; Bian, Naizheng; Alyafeai, Entesar; Alsharabi, Mousa
TI  - Reconstructing real object appearance with virtual materials using mobile augmented reality
PY  - 2022
AB  - NA
SP  - 1
EP  - 10
JF  - Computers & Graphics
VL  - 108
IS  - NA
PB  - 
DO  - 10.1016/j.cag.2022.08.001
ER  - 

TY  - NA
AU  - Yang, John; Bhalgat, Yash; Chang, Simyung; Porikli, Fatih; Kwak, Nojun
TI  - Dynamic Iterative Refinement for Efficient 3D Hand Pose Estimation
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/wacv51458.2022.00276
ER  - 

TY  - NA
AU  - Du, Ruofei; Olwal, Alex; Le Goc, Mathieu; Wu, Shengzhi; Tang, Danhang; Zhang, Yinda; Zhang, Jun; Tan, David Joseph; Tombari, Federico; Kim, David
TI  - Opportunistic Interfaces for Augmented Reality: Transforming Everyday Objects into Tangible 6DoF Interfaces Using Ad hoc UI
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519911
ER  - 

TY  - JOUR
AU  - Adilkhanov, Adilzhan; Rubagotti, Matteo; Kappassov, Zhanat
TI  - Haptic Devices: Wearability-Based Taxonomy and Literature Review
PY  - 2022
AB  - In the last decade, several new haptic devices have been developed, contributing to the definition of more realistic virtual environments. An overview on this topic requires a description of the various technologies employed in building such devices, and of their application domains. This survey describes the current technology underlying haptic devices, based on the concept of &#x201C;wearability level&#x201D;. More than 90 devices, newly developed and described in scientific papers published in the period 2010-2021, are reviewed, which provide either haptic illusions or novel haptic feedback for teleoperation, entertainment, training, education, guidance and notification. As a result, the analyzed systems are divided into grounded, hand-held and wearable devices; the latter are further split into exoskeletons and gloves, finger-worn devices, and arm-worn devices. For the systems in each of these categories, descriptions and tables are provided that analyze their structure, including device mass and employed actuators, their applications, and other characteristics such as type of haptic feedback and tactile illusions. The paper also provides an overview of devices worn in parts of the human body other than arms and hands, and precisely haptic vests, jackets and belts, and haptic devices for head, legs and feet. Based on this analysis, the survey also provides a discussion on research gaps and challenges, and potential future directions.
SP  - 91923
EP  - 91947
JF  - IEEE Access
VL  - 10
IS  - NA
PB  - 
DO  - 10.1109/access.2022.3202986
ER  - 

TY  - CHAP
AU  - Liu, Xin; Shao, Xiaofei; Wang, Bo; Li, Yali; Wang, Shengjin
TI  - GraphCSPN: Geometry-Aware Depth Completion via Dynamic GCNs
PY  - 2022
AB  - NA
SP  - 90
EP  - 107
JF  - Lecture Notes in Computer Science
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-19827-4_6
ER  - 

TY  - NA
AU  - Olaosebikan, Monsurat; Aranda Barrios, Claudia; Kolawole, Blessing; Cowen, Lenore; Shaer, Orit
TI  - Identifying Cognitive and Creative Support Needs for Remote Scientific Collaboration using VR: Practices, Affordances, and Design Implications
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Creativity and Cognition
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3527927.3532797
ER  - 

TY  - NA
AU  - Nebeling, Michael; Rajaram, Shwetha; Wu, Liwei; Cheng, Yifei; Herskovitz, Jaylin
TI  - CHI - XRStudio: A Virtual Production and Live Streaming System for Immersive Instructional Experiences
PY  - 2021
AB  - There is increased interest in using virtual reality in education, but it often remains an isolated experience that is difficult to integrate into current instructional experiences. In this work, we adapt virtual production techniques from filmmaking to enable mixed reality capture of instructors so that they appear to be standing directly in the virtual scene. We also capitalize on the growing popularity of live streaming software for video conferencing and live production. With XRStudio, we develop a pipeline for giving lectures in VR, enabling live compositing using a variety of presets and real-time output to traditional video and more immersive formats. We present interviews with media designers experienced in film and MOOC production that informed our design. Through walkthrough demonstrations of XRStudio with instructors experienced with VR, we learn how it could be used in a variety of domains. In end-to-end evaluations with students, we analyze and compare differences of traditional video vs. more immersive lectures with XRStudio.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445323
ER  - 

TY  - JOUR
AU  - Li, Chuxuan; Yi, Ran; Ali, Saba Ghazanfar; Ma, Lizhuang; Wu, Enhua; Wang, Jihong; Mao, Lijuan; Sheng, Bin
TI  - RADepthNet: Reflectance-Aware Monocular Depth Estimation
PY  - 2022
AB  - Monocular depth estimation aims to predict the dense depth map from a single RGB image, which has important applications in 3D reconstruction, automatic driving, and augmented reality. However, existing methods directly feed the original RGB image into the model to extract depth features without avoiding the interference of depth-irrelevant information on depth estimation accuracy, which leads to inferior performance. To remove the influence of depth-irrelevant information and improve depth prediction accuracy, we propose RADepthNet, a novel reflectance-guided network fusing boundary features. Specifically, our method predicts depth maps using three steps: 1) Intrinsic Image Decomposition. We propose a Reflectance extraction module consisting of an encoder-decoder structure to extract depth-related reflectance. We demonstrate that the module can reduce the influence of illumination on depth estimation through an ablation study. 2) Boundary Detection. Boundary extraction module, consisting of an encoder, a refinement block, and an upsample block, is proposed to better predict depth at object boundaries utilizing gradient constraints. 3) Depth Prediction Module. Use a different encoder from 2) to obtain depth features from the reflectance map and fuse boundary features to predict depth. Besides, we proposed FIFADataset, a depth estimation dataset applied in soccer scenarios. Extensive experiments on the public dataset and our proposed FIFADataset show that our method achieves state-of-the-art performance.
SP  - 418
EP  - 431
JF  - Virtual Reality & Intelligent Hardware
VL  - 4
IS  - 5
PB  - 
DO  - 10.1016/j.vrih.2022.08.005
ER  - 

TY  - JOUR
AU  - Hori, Ryosuke; Hachiuma, Ryo; Isogawa, Mariko; Mikami, Dan; Saito, Hideo
TI  - Silhouette-Based 3D Human Pose Estimation Using a Single Wrist-Mounted 360° Camera
PY  - 2022
AB  - NA
SP  - 54957
EP  - 54968
JF  - IEEE Access
VL  - 10
IS  - NA
PB  - 
DO  - 10.1109/access.2022.3177623
ER  - 

TY  - NA
AU  - Peng, Yi-Hao; Bigham, Jeffrey P.; Pavel, Amy
TI  - ASSETS - Slidecho: Flexible Non-Visual Exploration of Presentation Videos
PY  - 2021
AB  - We present Slidecho, a system that enables non-visual access of the slide content in a presentation video on-demand. Slidecho automatically extracts slides and their text and image elements from the presentation video and aligns these elements to the presenter’s speech. When listening to the video, Slidecho provides learners with audio notifications about slide changes and slide elements that are not described by the presenter. The learner can pause the video and browse the entire slide, or only the undescribed slide elements, to gain information. A technical evaluation with presentation videos in-the-wild shows that compared to the presenter’s speech alone, Slidecho provides access to an additional 20% of total text elements and 30% of total image elements that were previously not described. Blind and visually impaired participants in our user study reported that it was easier to locate undescribed slide elements with Slidecho’s synchronized interface than when browsing the video and extracted slides separately, and using Slidecho they read fewer slides that were fully redundant with the speech.
SP  - NA
EP  - NA
JF  - The 23rd International ACM SIGACCESS Conference on Computers and Accessibility
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3441852.3471234
ER  - 

TY  - NA
AU  - Chen, Yu-Wen; Lin, Wei-Ju; Chen, Yi; Cheng, Lung-Pan
TI  - UIST - PneuSeries: 3D Shape Forming with Modularized Serial-Connected Inflatables
PY  - 2021
AB  - We present PneuSeries, a series of modularized inflatables where their inflation and deflation are propagated in-between stage by stage to form various shapes. The key component of PneuSeries is the bidirectional check valve that passively regulates the air flowing in/out from/to adjacent inflatables, allowing each of the inflatables to be inflated/deflated one by one through serial propagation. The form of the inflatable series thus is programmed by the sequential operations of a pump that push/pull the air in/out. In this paper, we explored the design of PneuSeries and implemented working prototypes as a proof of concept. In particular, we built PneuSeries with (1) modularized cubical, cuboidal, tetrahedral, prismatic, and custom inflatables to examine their shape forming, (2) fast assembly connectors to allow quick reconfiguration of the series, and (3) folding mechanism to reduce irregularity of the shrunken inflatables. We also evaluated the inflating and deflating time and the flow rate of the valve for simulating the inflating and deflating process and display the steps and time required to transform in our software. Finally, we demonstrate example objects that show the capability of PneuSeries and its potential applications.
SP  - 431
EP  - 440
JF  - The 34th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3472749.3474760
ER  - 

TY  - CHAP
AU  - Matulic, Fabrice; Vogel, Daniel
TI  - Deep Learning-Based Hand Posture Recognition for Pen Interaction Enhancement
PY  - 2021
AB  - This chapter examines how digital pen interaction can be expanded by detecting different hand postures formed primarily by the hand while it grips the pen. Three systems using different types of sensors are considered: an EMG armband, the raw capacitive image of the touchscreen, and a pen-top fisheye camera. In each case, deep neural networks are used to perform classification or regression to detect hand postures and gestures. Additional analyses are provided to demonstrate the benefit of deep learning over conventional machine-learning methods, as well as explore the impact on model accuracy resulting from the number of postures to be recognised, user-dependent versus user-independent models, and the amount of training data. Examples of posture-based pen interaction in applications are discussed and a number of usability aspects resulting from user evaluations are identified. The chapter concludes with perspectives on the recognition and design of posture-based pen interaction for future systems.
SP  - 193
EP  - 225
JF  - Human–Computer Interaction Series
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-82681-9_7
ER  - 

TY  - NA
AU  - Zhou, Yuqi; Popescu, Voicu
TI  - Tapping with a Handheld Stick in VR: Redirection Detection Thresholds for Passive Haptic Feedback
PY  - 2022
AB  - This paper investigates providing grounded passive haptic feedback to a user of a VR application through a handheld stick with which the user taps virtual objects. Such an investigation benefits VR applications beyond those where the stick interaction is actually an integral part of the narrative. Providing passive haptic feedback through a handheld stick as opposed to directly through the user&#x2019;s hand has the potential for more believable and more frequent feedback opportunities. The stick is likely to dull the user&#x2019;s haptics perception and proprioception, potentially avoiding a haptics perception uncanny valley and increasing the redirection detection thresholds. Two haptics redirection methods are proposed: the DriftingHand method, which alters the position of the user&#x2019;s virtual hand, and the Vari-Stick method, which alters the length of the virtual stick. Detection thresholds were measured in a user study (N = 60) by testing the two methods for a range of offsets between the virtual and the real object, for multiple stick lengths, and multiple distances from the user to the real object. Overall, the study reveals that VariStick and DriftingHand provide an undetectable range of offsets of [-20cm, +13cm] and [-11cm, +11cm], respectively.
SP  - NA
EP  - NA
JF  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vr51125.2022.00026
ER  - 

TY  - NA
AU  - Wittchen, Dennis; Spiel, Katta; Fruchard, Bruno; Degraen, Donald; Schneider, Oliver; Freitag, Georg; Strohmeier, Paul
TI  - TactJam: An End-to-End Prototyping Suite for Collaborative Design of On-Body Vibrotactile Feedback
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490149.3501307
ER  - 

TY  - NA
AU  - Pourjafarian, Narjes; Koelle, Marion; Fruchard, Bruno; Mavali, Sahar; Klamka, Konstantin; Groeger, Daniel; Strohmeier, Paul; Steimle, Jürgen
TI  - CHI - BodyStylus: Freehand On-Body Design and Fabrication of Epidermal Interfaces
PY  - 2021
AB  - In traditional body-art, designs are adjusted to the body as they are applied, enabling creative improvisation and exploration. Conventional design and fabrication methods of epidermal interfaces, however, separate these steps. With BodyStylus we present the first computer-assisted approach for on-body design and fabrication of epidermal interfaces. Inspired by traditional techniques, we propose a hand-held tool that augments freehand inking with digital support: projected in-situ guidance assists creating valid on-body circuits and aesthetic ornaments that align with the human bodyscape, while pro-active switching between inking and non-inking creates error preventing constraints. We contribute BodyStylus’s design rationale and interaction concept along with an interactive prototype that uses self-sintering conductive ink. Results of two focus group explorations showed that guidance was more appreciated by artists, while constraints appeared more useful to engineers, and that working on the body inspired critical reflection on the relationship between bodyscape, interaction, and designs.
SP  - NA
EP  - NA
JF  - Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3411764.3445475
ER  - 

TY  - NA
AU  - Xu, Xuhai; Gong, Jun; Brum, Carolina; Liang, Lilian; Suh, Bongsoo; Gupta, Shivam Kumar; Agarwal, Yash; Lindsey, Laurence; Kang, Runchang; Shahsavari, Behrooz; Nguyen, Tu; Nieto, Heriberto; Hudson, Scott E; Maalouf, Charlie; Mousavi, Jax Seyed; Laput, Gierad
TI  - Enabling Hand Gesture Customization on Wrist-Worn Devices
PY  - 2022
AB  - We present a framework for gesture customization requiring minimal examples from users, all without degrading the performance of existing gesture sets. To achieve this, we first deployed a large-scale study (N=500+) to collect data and train an accelerometer-gyroscope recognition model with a cross-user accuracy of 95.7% and a false-positive rate of 0.6 per hour when tested on everyday non-gesture data. Next, we design a few-shot learning framework which derives a lightweight model from our pre-trained model, enabling knowledge transfer without performance degradation. We validate our approach through a user study (N=20) examining on-device customization from 12 new gestures, resulting in an average accuracy of 55.3%, 83.1%, and 87.2% on using one, three, or five shots when adding a new gesture, while maintaining the same recognition accuracy and false-positive rate from the pre-existing gesture set. We further evaluate the usability of our real-time implementation with a user experience study (N=20). Our results highlight the effectiveness, learnability, and usability of our customization framework. Our approach paves the way for a future where users are no longer bound to pre-existing gestures, freeing them to creatively introduce new gestures tailored to their preferences and abilities.
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3501904
ER  - 

TY  - NA
AU  - Yu, Geoffrey X.; Gao, Yubo; Golikov, Pavel; Pekhimenko, Gennady
TI  - A Runtime-Based Computational Performance Predictor for Deep Neural Network Training.
PY  - 2021
AB  - Deep learning researchers and practitioners usually leverage GPUs to help train their deep neural networks (DNNs) faster. However, choosing which GPU to use is challenging both because (i) there are many options, and (ii) users grapple with competing concerns: maximizing compute performance while minimizing costs. In this work, we present a new practical technique to help users make informed and cost-efficient GPU selections: make performance predictions with the help of a GPU that the user already has. Our technique exploits the observation that, because DNN training consists of repetitive compute steps, predicting the execution time of a single iteration is usually enough to characterize the performance of an entire training process. We make predictions by scaling the execution time of each operation in a training iteration from one GPU to another using either (i) wave scaling, a technique based on a GPU's execution model, or (ii) pre-trained multilayer perceptrons. We implement our technique into a Python library called Habitat and find that it makes accurate iteration execution time predictions (with an average error of 11.8%) on ResNet-50, Inception v3, the Transformer, GNMT, and DCGAN across six different GPU architectures. Habitat supports PyTorch, is easy to use, and is open source.
SP  - NA
EP  - NA
JF  - arXiv: Learning
VL  - NA
IS  - NA
PB  - 
DO  - NA
ER  - 

TY  - NA
AU  - Takahashi, Ryo; Yukita, Wakako; Yokota, Tomoyuki; Someya, Takao; Kawahara, Yoshihiro
TI  - Meander Coil++: A Body-scale Wireless Power Transmission Using Safe-to-body and Energy-efficient Transmitter Coil
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3502119
ER  - 

TY  - JOUR
AU  - Yu, Yuxuan; Qian, Kuanren; Yang, Humphrey; Yao, Lining; Zhang, Yongjie Jessica
TI  - Hybrid IGA-FEA of fiber reinforced thermoplastic composites for forward design of AI-enabled 4D printing
PY  - 2022
AB  - Fused deposition modeling (FDM)-based 4D printing uses thermoplastics to produce artifacts and requires computational analysis to assist its design processes of complex geometries. Previously, finite element analysis (FEA) has been used to simulate 4D printing deformations, and its accuracy has been computationally and experimentally verified. However, using FEA also leads to several limitations, such as geometric approximation error and the computational time-cost due to the high degrees of freedom. To address these issues, this paper introduces isogeometric analysis (IGA) into the deformation simulations and propounds a composite design by hybridizing FEA and IGA elements to reduce the number of degrees of freedom while maintaining the simulation accuracy. Moreover, since the hybrid IGA-FEA method used for modeling 4D printing structure deformation excludes real-time interactivity, we develop a polycube-based random forest regressor machine learning (ML) model to learn the IGA-FEA-based structural mechanics simulations and provide fast deformation predictions. Given the input actuator block distribution and geometry configurations, our well-trained model can predict the residual stress-induced deformation behaviors of mesh-like thermoplastic composite structures. With an error less than 0.11% and computation speed 20 times faster than hybrid IGA-FEA simulations, our model can create real-time (0.93 s) and truthful (99.89% accuracy) results. The effectiveness of the proposed model is demonstrated with several complex design examples. We believe the presented workflow effectively combines IGA, FEA, ML, and 4D printing to provide a powerful computational tool that enriches the 4D printing design tool box, and brings huge application potentials.
SP  - 117497
EP  - 117497
JF  - Journal of Materials Processing Technology
VL  - 302
IS  - NA
PB  - 
DO  - 10.1016/j.jmatprotec.2022.117497
ER  - 

TY  - JOUR
AU  - Zhu, Lifeng; Jiang, Xudong; Shen, Jiangwei; Zhang, Heng; Mo, Yiting; Song, Aiguo
TI  - TapeTouch: A Handheld Shape-changing Device for Haptic Display of Soft Objects.
PY  - 2022
AB  - Haptic feedback is widely used to enhance realism in virtual reality (VR). Shape and softness are two common factors perceived by the users in the haptic rendering of soft objects. To integrate these factors, we propose a new handheld shape-changing device, TapeTouch, to provide various shapes and softness in real time. TapeTouch is based on a controllable shape-changing tape, which is mainly composed of four motors and a section of brass tape. We design a structure of the components to fit a portable controller and allow to flexibly adjust the shape of the brass tape. After decoding desired shapes into the signals to control the motor, we automatically reproduce varying shapes and levels of softness to the finger or palm touching the shape-changing tape. We conducted two user studies to understand the capability of TapeTouch to render shape and softness, and the results showed that TapeTouch could provide a variety of distinguishable shapes as well as multiple levels of softness. Based on the results, we performed two VR experience studies to verify that the haptic feedback from TapeTouch enhances VR realism.
SP  - 3928
EP  - 3938
JF  - IEEE transactions on visualization and computer graphics
VL  - 28
IS  - 11
PB  - 
DO  - 10.1109/tvcg.2022.3203087
ER  - 

TY  - JOUR
AU  - Yang, Qiang; Zheng, Yuanqing
TI  - Model-based Head Orientation Estimation for Smart Devices
PY  - 2021
AB  - Voice interaction is friendly and convenient for users. Smart devices such as Amazon Echo allow users to interact with them by voice commands and become increasingly popular in our daily life. In recent years, research works focus on using the microphone array built in smart devices to localize the user's position, which adds additional context information to voice commands. In contrast, few works explore the user's head orientation, which also contains useful context information. For example, when a user says, "turn on the light", the head orientation could infer which light the user is referring to. Existing model-based works require a large number of microphone arrays to form an array network, while machine learning-based approaches need laborious data collection and training workload. The high deployment/usage cost of these methods is unfriendly to users. In this paper, we propose HOE, a model-based system that enables Head Orientation Estimation for smart devices with only two microphone arrays, which requires a lower training overhead than previous approaches. HOE first estimates the user's head orientation candidates by measuring the voice energy radiation pattern. Then, the voice frequency radiation pattern is leveraged to obtain the final result. Real-world experiments are conducted, and the results show that HOE can achieve a median estimation error of 23 degrees. To the best of our knowledge, HOE is the first model-based attempt to estimate the head orientation by only two microphone arrays without the arduous data training overhead.
SP  - 1
EP  - 24
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 5
IS  - 3
PB  - 
DO  - 10.1145/3478089
ER  - 

TY  - JOUR
AU  - Urakami, Jacqueline; Seaborn, Katie
TI  - Nonverbal Cues in Human-robot Interaction: A Communication Studies Perspective
PY  - 2022
AB  - <jats:p>Communication between people is characterized by a broad range of nonverbal cues. Transferring these cues into the design of robots and other artificial agents that interact with people may foster more natural, inviting, and accessible experiences. In this position paper, we offer a series of definitive nonverbal codes for human-robot interaction (HRI) that address the five human sensory systems (visual, auditory, haptic, olfactory, gustatory) drawn from the field of communication studies. We discuss how these codes can be translated into design patterns for HRI using a curated sample of the communication studies and HRI literatures. As nonverbal codes are an essential mode in human communication, we argue that integrating robotic nonverbal codes in HRI will afford robots a feeling of “aliveness” or “social agency” that would otherwise be missing. We end with suggestions for research directions to stimulate work on nonverbal communication within the field of HRI and improve communication between human and robots.</jats:p>
SP  - NA
EP  - NA
JF  - ACM Transactions on Human-Robot Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3570169
ER  - 

TY  - CHAP
AU  - Hedlund, Martin; Bogdan, Cristian; Meixner, Gerrit
TI  - Creating a Post-sedentary Work Context for Software Engineering
PY  - 2022
AB  - AbstractSoftware engineers are sedentary and need technological help for a more healthy life. Current software engineering tasks are mostly confined to the standard sedentary desktop user interface. We believe that software engineering should be restructured so that it offers a non-sedentary alternative. In this paper, we describe a new research approach, called Post-sedentary Software Engineering. Our ambition with this approach is to provide an alternative, healthier work context without decreasing productivity. We take a spatial approach to post-sedentary tool design, starting from the assumption an interactive 3D environment with appropriate metaphors is necessary for full body movement. We discuss available technologies for achieving this goal and outline four studies that incorporate the software engineering phases of code comprehension, code creation and debugging in a non-sedentary context.KeywordsSedentaryPost-sedentarySpatialMetaphorSoftware engineering
SP  - 123
EP  - 138
JF  - Lecture Notes in Computer Science
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-030-98388-8_12
ER  - 

TY  - NA
AU  - Jiang, Yue; Lu, Yuwen; Nichols, Jeffrey; Stuerzlinger, Wolfgang; Yu, Chun; Lutteroth, Christof; Li, Yang; Kumar, Ranjitha; Li, Toby Jia-Jun
TI  - Computational Approaches for Understanding, Generating, and Adapting User Interfaces
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3504030
ER  - 

TY  - CHAP
AU  - Zhou, Yunwen; Kar, Abhishek; Turner, Eric; Kowdle, Adarsh; Guo, Chao X.; DuToit, Ryan C.; Tsotsos, Konstantine
TI  - Learned Monocular Depth Priors in Visual-Inertial Initialization
PY  - 2022
AB  - NA
SP  - 552
EP  - 570
JF  - Lecture Notes in Computer Science
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-20047-2_32
ER  - 

TY  - NA
AU  - Nittala, Aditya Shekhar; Steimle, Jürgen
TI  - Next Steps in Epidermal Computing: Opportunities and Challenges for Soft On-Skin Devices
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517668
ER  - 

TY  - NA
AU  - Nabil, Sara; Jones, Lee; Girouard, Audrey
TI  - TEI - Soft Speakers: Digital Embroidering of DIY Customizable Fabric Actuators
PY  - 2021
AB  - We introduce Soft Speakers, a systematic approach for designing custom fabric actuators that can be used as audio speakers and vibro-haptic actuators. Digitally-embroidered with e-textiles, we implement Soft Speakers as tactile, malleable and aesthetic designs to be part of wearables, soft furnishing and fabric objects. We present a rapid technique for the DIY fabrication of audio feedback into soft interfaces. We also discuss and evaluate 7 factors for their parametric design in additive and constructive methods. To demonstrate the feasibility of our approach and the breadth of new designs that it enables, we developed 5 prototypes: 3 wearables, a piece of furniture and a soft toy. Studying Soft Speakers with maker-users expanded the design space, empowering users and supporting inclusive design. Our study includes insights on user experience of real-world interactive applications for remote communication, e-learning, entertainment, navigation and gaming, enabled by Soft Speakers’ customizable and scalable form factor.
SP  - NA
EP  - NA
JF  - Proceedings of the Fifteenth International Conference on Tangible, Embedded, and Embodied Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3430524.3440630
ER  - 

TY  - NA
AU  - Zhang, Xinlei; Su, Zixiong; Rekimoto, Jun
TI  - Aware: Intuitive Device Activation Using Prosody for Natural Voice Interactions
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491102.3517687
ER  - 

TY  - JOUR
AU  - Lim, Hyunchul; Li, Yaxuan; Dressa, Matthew; Hu, Fang; Kim, Jae Hoon; Zhang, Ruidong; Zhang, Cheng
TI  - BodyTrak
PY  - 2022
AB  - <jats:p>In this paper, we present BodyTrak, an intelligent sensing technology that can estimate full body poses on a wristband. It only requires one miniature RGB camera to capture the body silhouettes, which are learned by a customized deep learning model to estimate the 3D positions of 14 joints on arms, legs, torso, and head. We conducted a user study with 9 participants in which each participant performed 12 daily activities such as walking, sitting, or exercising, in varying scenarios (wearing different clothes, outdoors/indoors) with a different number of camera settings on the wrist. The results show that our system can infer the full body pose (3D positions of 14 joints) with an average error of 6.9 cm using only one miniature RGB camera (11.5mm x 9.5mm) on the wrist pointing towards the body. Based on the results, we disscuss the possible application, challenges, and limitations to deploy our system in real-world scenarios.</jats:p>
SP  - 1
EP  - 21
JF  - Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies
VL  - 6
IS  - 3
PB  - 
DO  - 10.1145/3552312
ER  - 

TY  - NA
AU  - Daeijavad, Parisa; Maurer, Frank
TI  - Layouts of 3D Data Visualizations Small Multiples around Users in Immersive Environments
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar-adjunct57072.2022.00057
ER  - 

TY  - NA
AU  - Parizi, Farshid Salemi; Kienzle, Wolf; Whitmire, Eric; Gupta, Aakar; Benko, Hrvoje
TI  - RotoWrist: Continuous Infrared Wrist Angle Tracking using a Wristband
PY  - 2021
AB  - We introduce RotoWrist, an infrared (IR) light based solution for continuously and reliably tracking 2-degree-of-freedom (DoF) relative angle of the wrist with respect to the forearm using a wristband. The tracking system consists of eight time-of-flight (ToF) IR light modules distributed around a wristband. We developed a computationally simple tracking approach to reconstruct the orientation of the wrist without any runtime training, ensuring user independence. An evaluation study demonstrated that RotoWrist achieves a cross-user median tracking error of 5.9° in flexion/extension and 6.8° in radial and ulnar deviation with no calibration required as measured with optical ground truth. We further demonstrate the performance of RotoWrist for a pointing task and compare it against ground truth tracking.
SP  - NA
EP  - NA
JF  - Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3489849.3489886
ER  - 

TY  - NA
AU  - Hashimoto, Takeru; Yoshida, Shigeo; Narumi, Takuji
TI  - MetamorphX: An Ungrounded 3-DoF Moment Display that Changes its Physical Properties through Rotational Impedance Control
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545650
ER  - 

TY  - NA
AU  - Littler, Eammon; Zhu, Bo; Jarosz, Wojciech
TI  - Automated Filament Inking for Multi-color FFF 3D Printing
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545654
ER  - 

TY  - NA
AU  - Rodrigues, Rui; Neves Madeira, Rui; Correia, Nuno
TI  - Studying Natural User Interfaces for Smart Video Annotation towards Ubiquitous Environments
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - 20th International Conference on Mobile and Ubiquitous Multimedia
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490632.3490672
ER  - 

TY  - NA
AU  - Chen, Yanjun; Liang, Xuewei; Chen, Si; Chen, Yuwen; Lin, Hongnan; Zhang, Hechuan; Jiang, Chutian; Tian, Feng; Zhang, Yu; Yao, Shanshan; Han, Teng
TI  - HapTag: A Compact Actuator for Rendering Push-Button Tactility on Soft Surfaces
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545644
ER  - 

TY  - NA
AU  - Zhou, Xiangyu; Bodik, Rastislav; Cheung, Alvin; Wang, Chenglong
TI  - Synthesizing analytical SQL queries from computation demonstration
PY  - 2022
AB  - Analytical SQL is widely used in modern database applications and data analysis. However, its partitioning and grouping operators are challenging for novice users. Unfortunately, programming by example, shown effective on standard SQL, are less attractive because examples for analytical queries are more laborious to solve by hand. To make demonstrations easier to create, we designed a new end-user specification, programming by computation demonstration, that allows the user to demonstrate the task using a (possibly incomplete) cell-level computation trace. This specification is exploited in a new abstraction-based synthesis algorithm to prove that a partially formed query cannot be completed to satisfy the specification, allowing us to prune the search space. We implemented our approach in a tool named Sickle and tested it on 80 real-world analytical SQL tasks. Results show that even from small demonstrations, Sickle can solve 76 tasks, in 12.8 seconds on average, while the prior approaches can solve only 60 tasks and are on average 22.5x slower. Our user study with 13 participants reveals that our specification increases user efficiency and confidence on challenging tasks.
SP  - NA
EP  - NA
JF  - Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3519939.3523712
ER  - 

TY  - NA
AU  - Miyashita, Homei
TI  - Integrating Taste Technology with Audiovisual Media
PY  - 2021
AB  - This paper describes a mechanism for recording and reproducing taste similarly as humans record and reproduce audiovisual perception. The ion-phoretic and spray mixing methods are described for presenting taste; these methods are compared, and their prospects are discussed.
SP  - NA
EP  - NA
JF  - 2021 IEEE International Electron Devices Meeting (IEDM)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/iedm19574.2021.9720549
ER  - 

TY  - NA
AU  - Cools, Robbe; Gottsacker, Matt; Simeone, Adalberto; Bruder, Gerd; Welch, Greg; Feiner, Steven
TI  - Towards a Desktop-AR Prototyping Framework: Prototyping Cross-Reality Between Desktops and Augmented Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/ismar-adjunct57072.2022.00040
ER  - 

TY  - NA
AU  - Rao, Anyi; Xu, Linning; Lin, Dahua
TI  - Shoot360: Normal View Video Creation from City Panorama Footage
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3528233.3530702
ER  - 

TY  - JOUR
AU  - Quintana, David; Rodriguez, Antonio; Boada, Imma
TI  - Authoring Tools for Procedural Modeling of Virtual Reality-Based Rehabilitation Exercises
PY  - 2022
AB  - NA
SP  - 131567
EP  - 131578
JF  - IEEE Access
VL  - 10
IS  - NA
PB  - 
DO  - 10.1109/access.2022.3229210
ER  - 

TY  - NA
AU  - Makhsadov, Akhmajon; Degraen, Donald; Zenner, André; Kosmalla, Felix; Mushkina, Kamila; Krüger, Antonio
TI  - VRySmart: a Framework for Embedding Smart Devices in Virtual Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - CHI Conference on Human Factors in Computing Systems Extended Abstracts
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3491101.3519717
ER  - 

TY  - NA
AU  - Liu, Xingyu "Bruce"; Wang, Ruolin; Li, Dingzeyu; Chen, Xiang Anthony; Pavel, Amy
TI  - CrossA11y: Identifying Video Accessibility Issues via Cross-modal Grounding
PY  - 2022
AB  - Authors make their videos visually accessible by adding audio descriptions (AD), and auditorily accessible by adding closed captions (CC). However, creating AD and CC is challenging and tedious, especially for non-professional describers and captioners, due to the difficulty of identifying accessibility problems in videos. A video author will have to watch the video through and manually check for inaccessible information frame-by-frame, for both visual and auditory modalities. In this paper, we present CrossA11y, a system that helps authors efficiently detect and address visual and auditory accessibility issues in videos. Using cross-modal grounding analysis, CrossA11y automatically measures accessibility of visual and audio segments in a video by checking for modality asymmetries. CrossA11y then displays these segments and surfaces visual and audio accessibility issues in a unified interface, making it intuitive to locate, review, script AD/CC in-place, and preview the described and captioned video immediately. We demonstrate the effectiveness of CrossA11y through a lab study with 11 participants, comparing to existing baseline.
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545703
ER  - 

TY  - NA
AU  - Sehli, Mariem; Sebai, Dorsaf; Ghorbel, Faouzi
TI  - WeLDCFNet: Convolutional Neural Network based on Wedgelet Filters and Learnt Deep Correlation Features for depth maps features extraction
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - 2022 IEEE 24th International Workshop on Multimedia Signal Processing (MMSP)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/mmsp55362.2022.9949185
ER  - 

TY  - NA
AU  - Li, Zhipeng; Cui, Yikai; Zhou, Tianze; Jiang, Yu; Wang, Yuntao; Yan, Yukang; Nebeling, Michael; Shi, Yuanchun
TI  - Color-to-Depth Mappings as Depth Cues in Virtual Reality
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545646
ER  - 

TY  - JOUR
AU  - Talhan, Aishwari; Kumar, Sanjeet; Kim, Hwangil; Hassan, Waseem; Jeon, Seokhee
TI  - Multi-mode soft haptic thimble for haptic augmented reality based application of texture overlaying
PY  - 2022
AB  - NA
SP  - 102272
EP  - 102272
JF  - Displays
VL  - 74
IS  - NA
PB  - 
DO  - 10.1016/j.displa.2022.102272
ER  - 

TY  - JOUR
AU  - Yi, Chunzhi; Wei, Baichun; Zhu, Jianfei; Rho, Seungmin; Chen, Zhiyuan; Jiang, Feng
TI  - <i>Mordo</i>: Silent Command Recognition Through Lightweight Around-Ear Biosensors
PY  - 2023
AB  - NA
SP  - 763
EP  - 773
JF  - IEEE Internet of Things Journal
VL  - 10
IS  - 1
PB  - 
DO  - 10.1109/jiot.2022.3204336
ER  - 

TY  - NA
AU  - Zheng, Jingxiao; Shi, Xinwei; Gorban, Alexander; Mao, Junhua; Song, Yang; Qi, Charles R.; Liu, Ting; Chari, Visesh; Cornman, Andre; Zhou, Yin; Li, Congcong; Anguelov, Dragomir
TI  - Multi-modal 3D Human Pose Estimation with 2D Weak Supervision in Autonomous Driving
PY  - 2022
AB  - 3D human pose estimation (HPE) in autonomous vehicles (AV) differs from other use cases in many factors, including the 3D resolution and range of data, absence of dense depth maps, failure modes for LiDAR, relative location between the camera and LiDAR, and a high bar for estimation accuracy. Data collected for other use cases (such as virtual reality, gaming, and animation) may therefore not be usable for AV applications. This necessitates the collection and annotation of a large amount of 3D data for HPE in AV, which is time-consuming and expensive. In this paper, we propose one of the first approaches to alleviate this problem in the AV setting. Specifically, we propose a multi-modal approach which uses 2D labels on RGB images as weak supervision to perform 3D HPE. The proposed multi-modal architecture incorporates LiDAR and camera inputs with an auxiliary segmentation branch. On the Waymo Open Dataset, our approach achieves a 22% relative improvement over camera-only 2D HPE baseline, and 6% improvement over LiDAR-only model. Finally, careful ablation studies and parts based analysis illustrate the advantages of each of our contributions.
SP  - NA
EP  - NA
JF  - 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/cvprw56347.2022.00494
ER  - 

TY  - JOUR
AU  - Ajaykumar, Gopika; Stiber, Maia; Huang, Chien-Ming
TI  - Designing user-centric programming aids for kinesthetic teaching of collaborative robots
PY  - 2021
AB  - NA
SP  - 103845
EP  - NA
JF  - Robotics and Autonomous Systems
VL  - 145
IS  - NA
PB  - 
DO  - 10.1016/j.robot.2021.103845
ER  - 

TY  - NA
AU  - Kim, Daehwa; Harrison, Chris
TI  - EtherPose: Continuous Hand Pose Tracking with Wrist-Worn Antenna Impedance Characteristic Sensing
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - The 35th Annual ACM Symposium on User Interface Software and Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3526113.3545665
ER  - 

TY  - JOUR
AU  - Raeburn, Gideon; Welton, Martin; Tokarchuk, Laurissa
TI  - Developing a play-anywhere handheld AR storytelling app using remote data collection
PY  - 2022
AB  - <jats:p>Immersive story experiences like immersive theater productions and escape rooms have grown in popularity in recent years, offering the audience a more active role in the events portrayed. However, many of these activities were forced to close at the start of the COVID-19 pandemic, arising from restrictions placed on group activities and travel. This created an opportunity for a story experience that users could take part in around their local neighborhoods. Five mobile applications (apps) were developed toward this goal, aiming to make effective use of available local map data, alongside virtual content overlaid on users' surroundings through Augmented Reality (AR), to offer additional story features not present in the real environment. The first two apps investigated the feasibility of such an approach, including the remote field testing of the apps, where participants used their own devices across a variety of locations. Two follow-up apps further aimed to offer an improved user experience, also adopting a more standardized testing procedure, to better ensure each app was completed in an intended manner by those participating remotely. Participants rated their experience through immersion and engagement questionnaire factors that tested for their appropriateness to rate such experiences, in addition to providing their feedback. A final app applied the same AR story implementation to a curated site-specific study, once pandemic restrictions had eased. This combination of remote studies and subsequent curated study offered a reverse methodology to much previous research in this field, but was found to offer advantages in corroborating the results of the remote studies, and also in offering new insights to further improve such an AR story app, that is designed to be used at an outdoor location of the user's choosing. Such an app offers benefits to those who may prefer the opportunity to take part in such an activity solo or close to home, as well as for storytellers to develop an outside story for use at a variety of locations, making it available to a larger audience, without the challenges and costs in migrating it to different locations.</jats:p>
SP  - NA
EP  - NA
JF  - Frontiers in Computer Science
VL  - 4
IS  - NA
PB  - 
DO  - 10.3389/fcomp.2022.927177
ER  - 

TY  - CHAP
AU  - Vatavu, Radu-Daniel; Schipor, Ovidiu-Andrei
TI  - Formalizing Digital Proprioception for Devices, Environments, and Users
PY  - 2022
AB  - AbstractWe discuss the concept of digital proprioception for smart devices and smart environments, which we formalize and operationalize in the context of Ambient Intelligence with a dedicated event-driven software architecture. We also propose extended digital proprioception, by means of which devices and environments can access supplementary information about themselves from other sources, beyond their internal sensing capabilities. We use the latter concept to propose extended human proprioception enabled by the conjoint operation of smart devices and environments. Our contributions enable a new way to conceptualize interactions in smart environments by designing user experiences mediated by spatial communication interfaces where physical space integrates interaction.
SP  - 1
EP  - 10
JF  - Ambient Intelligence – Software and Applications – 12th International Symposium on Ambient Intelligence
VL  - NA
IS  - NA
PB  - 
DO  - 10.1007/978-3-031-06894-2_1
ER  - 

TY  - JOUR
AU  - Moral-Sanchez, Silvia-Natividad; Siller, Hans-Stefan
TI  - Learning Geometry by Using Virtual Reality
PY  - 2022
AB  - <jats:p> With the rapid change in the society, education must evolve to adapt to the digital native students of the 21st century. A change in the current educational paradigm is thus necessary. Information and Communication Technology (ICT) is a vehicle to achieve this objective of paradigm shift in education [ 2 ]. In this paper, we propose gamification approach [ 3 ] via a virtual reality (VR) through a report of a didactic experience. A mixed method research design was adopted for this study in which students’ classification of polyhedral will be reported for the two different learning experiences using either wooden polyhedral or a VR tool within an immersive learning environment. The VR environment allows the learning of geometry in three-dimensional with a friendly interface that offers a multitude of options. It is worth highlighting the benefits of this VR tool in the teaching-learning process of geometry, making explicit the fundamental role played by ICT in meaningful learning of mathematics. </jats:p>
SP  - 61
EP  - 70
JF  - Proceedings of the Singapore National Academy of Science
VL  - 16
IS  - 1
PB  - 
DO  - 10.1142/s2591722622400051
ER  - 

TY  - JOUR
AU  - Agnès, Aurélien; Sylvain, Fleury; Vanukuru, Rishi; Richir, Simon
TI  - Studying the effect of symmetry in team structures on collaborative tasks in virtual reality
PY  - 2022
AB  - NA
SP  - 1
EP  - 9
JF  - Behaviour & Information Technology
VL  - NA
IS  - NA
PB  - 
DO  - 10.1080/0144929x.2022.2127375
ER  - 

TY  - NA
AU  - Rudolph, Julius Cosmo Romeo; Holman, David; De Araujo, Bruno; Jota, Ricardo; Wigdor, Daniel; Savage, Valkyrie
TI  - Sensing Hand Interactions with Everyday Objects by Profiling Wrist Topography
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3490149.3501320
ER  - 

TY  - NA
AU  - Zhao, Yuetong; Yan, Shuo; Shen, Xukun
TI  - Cohand VR: Towards A Shareable Immersive Experience via Wearable Gesture Interface between VR Audiences and External Audiences
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - SIGGRAPH Asia 2022 Posters
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3550082.3564176
ER  - 

TY  - NA
AU  - Murray, John T.
TI  - RealityFlow: Open-Source Multi-User Immersive Authoring
PY  - 2022
AB  - Immersive Authoring remains primarily driven by user-generated content on social VR applications. This paper introduces and motivates an open-source tool, RealityFlow, implemented on top of the Unity engine, and which supports studying immersive authoring paradigms through visual programming languages. This paper describes the context of visual programming environments as well as the requirements, technical implementation, and overall motivations and goals for future iterations.
SP  - NA
EP  - NA
JF  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
VL  - NA
IS  - NA
PB  - 
DO  - 10.1109/vrw55335.2022.00024
ER  - 

TY  - NA
AU  - De Greve, Teis; Malliet, Steven; Hendriks, Niels; Zaman, Bieke
TI  - The Air Quality Lens: Ambiguity as Opportunity to Reactivate Environmental Data
PY  - 2022
AB  - NA
SP  - NA
EP  - NA
JF  - Designing Interactive Systems Conference
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3532106.3533530
ER  - 

TY  - NA
AU  - Ghandeharizadeh, Shahram
TI  - Holodeck: Immersive 3D Displays Using Swarms of Flying Light Specks [Extended Abstract]
PY  - 2021
AB  - NA
SP  - NA
EP  - NA
JF  - ACM Multimedia Asia
VL  - NA
IS  - NA
PB  - 
DO  - 10.1145/3469877.3493698
ER  - 
